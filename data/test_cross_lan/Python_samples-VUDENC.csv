function,label
"[""def FUNC_0(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return database_utilities.execute_query('select * from users')\n""]",0
"[""def __repr__(self):...\n"", ""return self.get_name()\n""]",0
"[""def FUNC_6(self):...\n"", ""c.get(url_for('oauthclient.login', remote_app='test'))\n"", ""self.mock_response(VAR_5='test')\n"", ""self.mock_response(VAR_5='test_invalid')\n"", ""VAR_1 = c.get(url_for('oauthclient.authorized', remote_app='test', code='test')\n    )\n"", ""assert VAR_1.data == 'TEST'\n"", ""assert self.handled_remote.name == 'test'\n"", ""assert not self.handled_args\n"", ""assert not self.handled_kwargs\n"", ""assert self.handled_resp['access_token'] == 'test_access_token'\n"", ""VAR_1 = self.assertRaises(TypeError, c.get, url_for(\n    'oauthclient.authorized', remote_app='test_invalid', code='test'))\n""]",1
"[""def FUNC_3(VAR_1):...\n"", ""return frappe.db.get_value('Blog Category', {'name': VAR_1}, 'title') or VAR_1\n""]",0
"[""def FUNC_16(self, VAR_12):...\n"", ""VAR_32 = []\n"", ""print(VAR_12)\n"", ""VAR_27 = VAR_12.name.split('->')[1].strip()\n"", ""print(VAR_27)\n"", ""VAR_31 = self.get_links_to_file(VAR_27)\n"", ""for VAR_39 in VAR_31:\n"", ""print(VAR_39)\n"", ""if VAR_39 in self.visited_files:\n"", ""VAR_40 = CLASS_1(os.path.join(self.path, VAR_39))\n"", ""self.backward_visited_files.append(VAR_39)\n"", ""VAR_41 = Node(' ... ' + VAR_40.get_tag('title')[0] + ' -> ' + VAR_39,\n    VAR_12=parent)\n"", ""self.visited_files.append(VAR_39)\n"", ""VAR_39 = VAR_39.split('/')[-1]\n"", ""VAR_40 = CLASS_1(os.path.join(self.path, VAR_39))\n"", ""VAR_41 = Node(VAR_40.get_tag('title')[0] + ' -> ' + VAR_39, VAR_12=parent)\n"", ""self.add_backward_children(VAR_41)\n""]",1
"[""def FUNC_9(self):...\n"", ""VAR_7 = BokChoyTestSuite('', VAR_3=True)\n"", ""VAR_1 = 'tests'\n"", ""self.assertEqual(VAR_7.cmd, self._expected_command(VAR_1=name, VAR_3=True))\n""]",1
"[""def FUNC_21(self):...\n"", ""\""\""\""docstring\""\""\""\n""]",0
"[""def FUNC_7(self, VAR_9):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_8 = VAR_9.args.get('csessid')[0]\n"", ""VAR_18 = VAR_9.getClientIP()\n"", ""VAR_19 = '%s (%s:%s)' % (VAR_2, VAR_9.getRequestHostname(), VAR_9.getHost()\n    .port)\n"", ""VAR_20 = CLASS_2()\n"", ""VAR_20.client = self\n"", ""VAR_20.init_session('ajax/comet', VAR_18, self.sessionhandler)\n"", ""VAR_20.csessid = VAR_8\n"", ""VAR_21 = VAR_0(session_key=sess.csessid)\n"", ""VAR_22 = VAR_21 and VAR_21.get('webclient_authenticated_uid', False)\n"", ""if VAR_22:\n"", ""VAR_20.uid = VAR_22\n"", ""VAR_20.sessionhandler.connect(VAR_20)\n"", ""VAR_20.logged_in = True\n"", ""self.last_alive[VAR_8] = time.time(), False\n"", ""if not self.keep_alive:\n"", ""self.keep_alive = LoopingCall(self._keepalive)\n"", ""return FUNC_0({'msg': VAR_19, 'csessid': VAR_8})\n"", ""self.keep_alive.start(VAR_3, VAR_15=False)\n""]",1
"[""import logging\n"", ""import os\n"", ""import sys\n"", ""import threading\n"", ""VAR_0 = os.path.dirname(os.path.abspath(__file__))\n"", ""VAR_1 = os.path.dirname(VAR_0)\n"", ""sys.path.insert(0, VAR_1)\n"", ""sys.path.insert(0, os.path.join(VAR_1, 'third_party'))\n"", ""from depot_tools import auto_stub\n"", ""from utils import net\n"", ""def FUNC_0(VAR_2, VAR_3, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_4 = dict(VAR_4 or {})\n"", ""VAR_4['Content-Length'] = len(VAR_2)\n"", ""def __init__(self):...\n"", ""self.content = VAR_2\n"", ""def FUNC_6(self, VAR_7):...\n"", ""VAR_8 = self.content\n"", ""while VAR_8:\n"", ""yield VAR_8[:VAR_7]\n"", ""def FUNC_7(self):...\n"", ""VAR_8 = VAR_8[VAR_7:]\n"", ""return self.content\n""]",0
"[""def FUNC_3(VAR_5, VAR_6=''):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_18 = urllib2.Request(VAR_5)\n"", ""if VAR_6:\n"", ""VAR_18.add_header('User-Agent', VAR_6)\n"", ""VAR_20 = VAR_8(VAR_18)\n"", ""VAR_0.error('Unable to read from URL %s.' % VAR_5)\n"", ""VAR_11 = FUNC_1(VAR_21, VAR_3=True)\n"", ""VAR_21 = tempfile.mkstemp(prefix='bibclassify.')[1]\n"", ""return None\n"", ""os.remove(VAR_21)\n"", ""VAR_22 = open(VAR_21, 'w')\n"", ""VAR_12 = len(VAR_11)\n"", ""VAR_22.write(VAR_20.read())\n"", ""VAR_13 = 0\n"", ""VAR_22.close()\n"", ""for line in VAR_11:\n"", ""VAR_13 += len(re.findall('\\\\S+', line))\n"", ""VAR_0.info('Remote file has %d lines and %d words.' % (VAR_12, VAR_13))\n"", ""return VAR_11\n""]",1
"[""def FUNC_5(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_4 = '/api/apps'\n"", ""VAR_5 = self.client.post(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""VAR_6 = VAR_5.data['id']\n"", ""VAR_14 = {'username': 'autotest', 'app': VAR_6}\n"", ""VAR_4 = '/api/hooks/builds'.format(**locals())\n"", ""VAR_15 = {'web': 'node server.js', 'worker': 'node worker.js'}\n"", ""VAR_16 = 'ecdff91c57a0b9ab82e89634df87e293d259a3aa'\n"", ""VAR_7 = {'receive_user': 'autotest', 'receive_repo': VAR_6, 'image':\n    '{app_id}:v2'.format(**locals()), 'sha': VAR_16, 'procfile': VAR_15}\n"", ""self.assertIsNone(self.client.logout())\n"", ""VAR_5 = self.client.post(VAR_4, json.dumps(VAR_7), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_5.status_code, 403)\n"", ""VAR_5 = self.client.post(VAR_4, json.dumps(VAR_7), content_type=\n    'application/json', HTTP_X_DEIS_BUILDER_AUTH=settings.BUILDER_KEY)\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""self.assertIn('release', VAR_5.data)\n"", ""self.assertIn('version', VAR_5.data['release'])\n"", ""self.assertIn('domains', VAR_5.data)\n"", ""self.assertTrue(self.client.login(VAR_8='autotest', VAR_9='password'))\n"", ""VAR_4 = '/api/apps/{app_id}/builds'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""self.assertIn('results', VAR_5.data)\n"", ""VAR_14 = VAR_5.data['results'][0]\n"", ""self.assertEqual(VAR_14['sha'], VAR_16)\n"", ""self.assertEqual(VAR_14['procfile'], VAR_15)\n"", ""VAR_4 = '/api/apps/{app_id}/containers/web'.format(**locals())\n"", ""VAR_5 = self.client.get(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 200)\n"", ""self.assertEqual(len(VAR_5.data['results']), 1)\n"", ""VAR_17 = VAR_5.data['results'][0]\n"", ""self.assertEqual(VAR_17['type'], 'web')\n"", ""self.assertEqual(VAR_17['num'], 1)\n""]",1
"[""@app.route('/achievements/<achievement_id>/reveal', methods=['POST'])...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = int(request.form.get('player_id'))\n"", ""return flask.jsonify(FUNC_12(VAR_1, VAR_2))\n""]",0
"[""def FUNC_12(self, VAR_15):...\n"", ""VAR_30 = FUNC_4()\n"", ""VAR_31 = VAR_51.getSettingsFilename()\n"", ""self.write('string'.format('<p><b>Settings updated</b></p>' if VAR_15 else\n    '', VAR_31, VAR_30))\n""]",1
"[""import pymysql.cursors\n"", ""from config import create_connection\n"", ""VAR_0 = 'product_types'\n"", ""def FUNC_0():...\n"", ""VAR_1 = f\""\""\""\n            SELECT name\n            FROM {VAR_0}\n            \""\""\""\n"", ""VAR_2 = create_connection()\n"", ""VAR_2.close()\n"", ""VAR_3 = VAR_2.cursor()\n"", ""VAR_3.execute(VAR_1)\n"", ""return VAR_3.fetchall()\n""]",1
"[""def FUNC_0(VAR_4, VAR_5, VAR_6, VAR_7):...\n"", ""VAR_9 = FUNC_2()\n"", ""VAR_10 = VAR_9.cursor()\n"", ""VAR_10.execute('string'.format(VAR_4=playlist_id, VAR_5=title, VAR_6=\n    thumbnail, VAR_7=position))\n"", ""VAR_9.commit()\n"", ""VAR_9.close()\n""]",1
"[""def FUNC_0(VAR_0='_Test Event', VAR_1=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""from frappe.utils import get_datetime\n"", ""VAR_2 = frappe.get_doc({'doctype': 'Event', 'subject': VAR_0, 'event_type':\n    'Public', 'starts_on': get_datetime(VAR_1)}).insert(ignore_permissions=True\n    )\n"", ""return VAR_2\n""]",1
"[""def FUNC_16(self):...\n"", ""VAR_7 = Pa11yCrawler('')\n"", ""VAR_7.get_test_course()\n"", ""self._mock_sh.assert_has_calls([call(\n    'wget {targz} -O {dir}demo_course.tar.gz'.format(targz=suite.\n    tar_gz_file, dir=suite.imports_dir)), call(\n    'tar zxf {dir}demo_course.tar.gz -C {dir}'.format(dir=suite.imports_dir))])\n""]",0
"[""def FUNC_24(self, VAR_17):...\n"", ""VAR_35, VAR_9, VAR_36 = sys.exc_info()\n"", ""VAR_16, VAR_37 = str(VAR_17).split(\""'\"")[-2], None\n"", ""if 'unique_' in VAR_16:\n"", ""VAR_16 = VAR_16.split('_', 1)[1]\n"", ""VAR_25 = self.meta.get_field(VAR_16)\n"", ""if VAR_25:\n"", ""VAR_37 = VAR_25.label\n"", ""VAR_54.msgprint(_('{0} must be unique'.format(VAR_37 or VAR_16)))\n""]",0
"[""def __init__(self):...\n"", ""self.content = VAR_2\n""]",0
"[""def FUNC_11(self, VAR_9, *VAR_13, **VAR_14):...\n"", ""VAR_14['partial'] = True\n"", ""return self.update(VAR_9, *VAR_13, **kwargs)\n""]",0
"[""def FUNC_16(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7, VAR_12 = self.make_xsrf_handling_app(VAR_2=('PUT',))\n"", ""VAR_17 = VAR_7.get('/request').body\n"", ""VAR_7.post('/request', {'xsrf_token': VAR_17})\n"", ""VAR_7.put('/request', {'xsrf_token': VAR_17})\n"", ""self.assertEqual([('POST', True), ('PUT', True)], VAR_12)\n"", ""self.assertEqual(200, VAR_7.post('/request').status_int)\n"", ""self.assertEqual(403, VAR_7.put('/request', expect_errors=True).status_int)\n"", ""VAR_18 = {'xsrf_token': 'boo'}\n"", ""self.assertEqual(403, VAR_7.post('/request', VAR_18, expect_errors=True).\n    status_int)\n"", ""self.assertEqual(403, VAR_7.put('/request', VAR_18, expect_errors=True).\n    status_int)\n""]",1
"[""def FUNC_18(self, VAR_26, VAR_18):...\n"", ""VAR_31 = VAR_18.target.sources_snapshot(scheduler=self.context._scheduler)\n"", ""VAR_32 = tuple(os.path.relpath(f.path.replace('.java', '.class'), VAR_18.\n    target.target_base) for f in VAR_31.files if f.path.endswith('.java'))\n"", ""VAR_33 = ExecuteProcessRequest(argv=tuple(cmd), input_files=input_snapshot.\n    directory_digest, VAR_32=output_files, description=\n    'Compiling {} with javac'.format(ctx.target.address.spec))\n"", ""VAR_34 = self.context.execute_process_synchronously(VAR_33, 'javac', (\n    WorkUnitLabel.TASK, WorkUnitLabel.JVM))\n"", ""VAR_35 = VAR_18.classes_dir\n"", ""self.context._scheduler.materialize_directories((DirectoryToMaterialize(\n    text_type(VAR_35), VAR_34.output_directory_digest),))\n""]",1
"[""def FUNC_15(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7 = BokChoyTestSuite('', num_processes=2, verbosity=3)\n"", ""BokChoyTestSuite.verbosity_processes_string(VAR_7)\n""]",0
"[""import os\n"", ""import time\n"", ""from cauldron.render import texts as render_texts\n"", ""from cauldron.session.buffering import RedirectBuffer\n"", ""from cauldron.session.caching import SharedCache\n"", ""\""\""\""string\""\""\""\n"", ""def __init__(self, VAR_0=None):...\n"", ""self.step = VAR_0\n"", ""self.body = []\n"", ""self.css = []\n"", ""self.data = SharedCache()\n"", ""self.files = SharedCache()\n"", ""self.title = self.definition.get('title')\n"", ""self.subtitle = self.definition.get('subtitle')\n"", ""self.summary = self.definition.get('summary')\n"", ""self.library_includes = []\n"", ""self.stdout_interceptor = None\n"", ""self.stderr_interceptor = None\n"", ""self._last_update_time = 0\n"", ""@property...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = self.stdout_interceptor\n"", ""VAR_3 = self.stderr_interceptor\n"", ""return max([self._last_update_time, VAR_2.last_write_time if VAR_2 else 0, \n    VAR_3.last_write_time if VAR_3 else 0])\n""]",0
"[""def FUNC_7(self, VAR_3):...\n"", ""VAR_3 = VAR_3.lower()\n"", ""VAR_8 = sqlite3.connect('data/ed.db').cursor()\n"", ""VAR_7 = VAR_8.execute(f\""select * from bodies where lower(name) = '{VAR_3}'\"")\n"", ""VAR_10 = VAR_7.fetchone()\n"", ""if VAR_10:\n"", ""VAR_12 = tuple(i[0] for i in VAR_7.description)\n"", ""return 'No bodies found.'\n"", ""return '\\n'.join(f\""{key.replace('_', ' ').title()}: {field}\"" for key, field in\n    zip(VAR_12[2:], VAR_10[2:]) if field)\n""]",1
"[""def FUNC_14(VAR_24=sys.argv):...\n"", ""VAR_39 = FUNC_12(VAR_24)\n"", ""if VAR_39.print_templates:\n"", ""print(VAR_39.templates)\n"", ""if not VAR_39.metadata:\n"", ""return 0\n"", ""if 'OS_CONFIG_FILES' in os.environ:\n"", ""if VAR_39.templates is None:\n"", ""VAR_28.error(e)\n"", ""return 0\n"", ""VAR_39.metadata = os.environ['OS_CONFIG_FILES'].split(':')\n"", ""VAR_39.metadata = FUNC_13(VAR_39.os_config_files)\n"", ""if VAR_39.key:\n"", ""return 1\n"", ""if not VAR_39.metadata and VAR_39.os_config_files == VAR_2:\n"", ""FUNC_2(VAR_39.metadata, VAR_39.key, VAR_39.type, VAR_39.key_default, VAR_39\n    .fallback_metadata)\n"", ""FUNC_1(VAR_39.metadata, VAR_39.templates, VAR_39.output, VAR_39.validate,\n    VAR_39.subhash, VAR_39.fallback_metadata)\n"", ""VAR_28.warning('DEPRECATED: falling back to %s' % VAR_3)\n"", ""VAR_28.info('success')\n"", ""VAR_39.metadata = FUNC_13(VAR_3)\n""]",0
"[""def FUNC_13(VAR_9, VAR_7, VAR_11, VAR_10):...\n"", ""if VAR_11 == 'POST':\n"", ""return CLASS_0.session.post(FUNC_2(VAR_7), VAR_9=ToUtf8Json(data), headers=\n    _HEADERS, VAR_10=timeout)\n"", ""if VAR_11 == 'GET':\n"", ""return CLASS_0.session.get(FUNC_2(VAR_7), headers=_HEADERS, VAR_10=timeout)\n""]",1
"[""def FUNC_0(self, VAR_1, VAR_2, VAR_3, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_4 is None:\n"", ""VAR_4 = {}\n"", ""VAR_17 = self.pool.get('product.product').browse(VAR_1, VAR_2, VAR_3, VAR_4\n    =context)\n"", ""VAR_18 = (VAR_17.property_stock_account_input and VAR_17.\n    property_stock_account_input.id or False)\n"", ""if not VAR_18:\n"", ""VAR_18 = (VAR_17.categ_id.property_stock_account_input_categ and VAR_17.\n    categ_id.property_stock_account_input_categ.id or False)\n"", ""VAR_19 = (VAR_17.property_stock_account_output and VAR_17.\n    property_stock_account_output.id or False)\n"", ""if not VAR_19:\n"", ""VAR_19 = (VAR_17.categ_id.property_stock_account_output_categ and VAR_17.\n    categ_id.property_stock_account_output_categ.id or False)\n"", ""VAR_20 = (VAR_17.categ_id.property_stock_journal and VAR_17.categ_id.\n    property_stock_journal.id or False)\n"", ""VAR_21 = (VAR_17.categ_id.property_stock_variation and VAR_17.categ_id.\n    property_stock_variation.id or False)\n"", ""return {'stock_account_input': VAR_18, 'stock_account_output': VAR_19,\n    'stock_journal': VAR_20, 'property_stock_variation': VAR_21}\n""]",0
"[""def FUNC_0(VAR_0, VAR_1):...\n"", ""VAR_5 = {constraint for target_adaptor in VAR_1 for constraint in VAR_0.\n    compatibility_or_constraints(getattr(target_adaptor, 'compatibility',\n    None))}\n"", ""VAR_6 = []\n"", ""for constraint in sorted(VAR_5):\n"", ""VAR_6.extend(['--interpreter-constraint', text_type(constraint)])\n"", ""return VAR_6\n""]",0
"[""def FUNC_7(self):...\n"", ""self.__use_lb_name = 'katotest-lb-' + self.test_id\n"", ""self.__use_lb_hc_name = '%s-hc' % self.__use_lb_name\n"", ""self.__use_lb_tp_name = '%s-tp' % self.__use_lb_name\n"", ""self.__use_lb_target = '{0}/targetPools/{1}'.format(self.bindings[\n    'TEST_GCE_REGION'], self.__use_lb_tp_name)\n"", ""VAR_25 = 123\n"", ""VAR_26 = 4\n"", ""VAR_27 = 5\n"", ""VAR_28 = 78\n"", ""VAR_29 = '/' + self.__use_lb_target\n"", ""VAR_31 = {'checkIntervalSec': VAR_25, 'healthyThreshold': VAR_26,\n    'unhealthyThreshold': VAR_27, 'timeoutSec': VAR_28, 'requestPath': VAR_29}\n"", ""VAR_21 = self.agent.type_to_payload('upsertGoogleLoadBalancerDescription',\n    {'healthCheck': VAR_31, 'region': self.bindings['TEST_GCE_REGION'],\n    'credentials': self.bindings['GCE_CREDENTIALS'], 'loadBalancerName':\n    self.__use_lb_name})\n"", ""VAR_20 = gcp.GceContractBuilder(self.gce_observer)\n"", ""VAR_20.new_clause_builder('Forwarding Rules Added', retryable_for_secs=30\n    ).list_resources('forwarding-rules').contains_path_value('name', self.\n    __use_lb_name).contains_path_value('target', self.__use_lb_target)\n"", ""VAR_20.new_clause_builder('Target Pool Added', retryable_for_secs=15\n    ).list_resources('target-pools').contains_path_value('name', self.\n    __use_lb_tp_name)\n"", ""VAR_20.new_clause_builder('Health Check Added', retryable_for_secs=15\n    ).list_resources('http-health-checks').contains_pred_list([jc.\n    PathContainsPredicate('name', self.__use_lb_hc_name), jc.\n    PathContainsPredicate(None, VAR_31)])\n"", ""return st.OperationContract(self.new_post_operation(title=\n    'upsert_load_balancer', data=payload, VAR_29='ops'), contract=builder.\n    build())\n""]",1
"[""@property...\n"", ""VAR_65 = '.' if self._workdir is None else self._workdir\n"", ""if not os.path.isabs(VAR_65):\n"", ""return os.path.abspath(os.path.join(self.workflow.basedir, VAR_65))\n"", ""return VAR_65\n""]",0
"[""def FUNC_2(VAR_0, VAR_1):...\n"", ""VAR_5 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) +\n    '\\\\users\\\\' + VAR_0 + '.db')\n"", ""VAR_6 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n"", ""VAR_7 = VAR_5.cursor()\n"", ""VAR_8 = VAR_6.cursor()\n"", ""VAR_7.execute(\n    'CREATE TABLE result (problem INTEGER, diff STRING, verdict STRING)')\n"", ""VAR_8.execute('SELECT * FROM problems')\n"", ""VAR_9 = VAR_8.fetchone()\n"", ""while VAR_9 != None:\n"", ""VAR_7.execute('insert into result values (?, ?, ? )', (VAR_9[0], VAR_9[1],\n    'NULL'))\n"", ""VAR_10 = 'http://codeforces.com/submissions/' + VAR_0\n"", ""VAR_9 = VAR_8.fetchone()\n"", ""VAR_2 = requests.get(VAR_10)\n"", ""VAR_11 = 1\n"", ""VAR_3 = BeautifulSoup(VAR_2.text, 'lxml')\n"", ""for link in VAR_3.find_all(attrs={'class': 'page-index'}):\n"", ""VAR_16 = link.find('a')\n"", ""VAR_12 = ''\n"", ""VAR_17 = VAR_16.get('href').split('/')\n"", ""VAR_2 = requests.get('http://codeforces.com/submissions/' + VAR_0 + '/page/0')\n"", ""VAR_11 = max(VAR_11, int(VAR_17[4]))\n"", ""VAR_3 = BeautifulSoup(VAR_2.text, 'lxml')\n"", ""VAR_13 = VAR_3.find(attrs={'class': 'status-small'})\n"", ""if not VAR_13 == None:\n"", ""VAR_13 = str(VAR_13).split()\n"", ""for i in range(1, VAR_11 + 1):\n"", ""VAR_13 = str(VAR_13[2]) + str(VAR_13[3])\n"", ""VAR_2 = requests.get('http://codeforces.com/submissions/' + VAR_0 +\n    '/page/' + str(i))\n"", ""VAR_5.commit()\n"", ""VAR_3 = BeautifulSoup(VAR_2.text, 'lxml')\n"", ""VAR_5.close()\n"", ""VAR_18 = 0\n"", ""VAR_6.close()\n"", ""VAR_19 = VAR_3.find_all(attrs={'class': 'submissionVerdictWrapper'})\n"", ""VAR_14 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) +\n    '\\\\settings.db')\n"", ""for link in VAR_3.find_all('a'):\n"", ""VAR_5 = VAR_14.cursor()\n"", ""VAR_16 = link.get('href')\n"", ""VAR_5.execute('select * from last_update_problemset')\n"", ""if VAR_16 != None and VAR_16.find('/problemset') != -1:\n"", ""VAR_15 = VAR_5.fetchone()\n"", ""VAR_16 = VAR_16.split('/')\n"", ""VAR_5.execute(\""select * from users where chat_id = '\"" + str(VAR_1) + \""'\"")\n"", ""if len(VAR_16) == 5:\n"", ""VAR_9 = VAR_5.fetchone()\n"", ""VAR_17 = str(VAR_19[VAR_18]).split()\n"", ""if VAR_9 == None:\n"", ""VAR_17 = VAR_17[5].split('\""')\n"", ""VAR_5.execute('insert into users values (?, ?, ?, ?, ?)', (VAR_1, VAR_0,\n    str(VAR_13), str(VAR_15[0]), 1))\n"", ""VAR_5.execute(\""update users set username = '\"" + str(VAR_0) +\n    \""' where chat_id = '\"" + str(VAR_1) + \""'\"")\n"", ""VAR_18 += 1\n"", ""VAR_14.commit()\n"", ""VAR_5.execute(\""update users set last_update = '\"" + str(VAR_13) +\n    \""' where chat_id = '\"" + str(VAR_1) + \""'\"")\n"", ""VAR_7.execute(\""select * from result where problem = '\"" + VAR_16[3] +\n    \""'and diff = '\"" + VAR_16[4] + \""'\"")\n"", ""VAR_14.close()\n"", ""VAR_5.execute(\""update users set last_problem = '\"" + str(VAR_15[0]) +\n    \""' where chat_id = '\"" + str(VAR_1) + \""'\"")\n"", ""VAR_9 = VAR_7.fetchone()\n"", ""VAR_5.execute(\""update users set state = '\"" + str(1) + \""' where chat_id = '\"" +\n    str(VAR_1) + \""'\"")\n"", ""if VAR_17[1] == 'OK' and VAR_9 != None:\n"", ""VAR_7.execute(\""update result set verdict = '\"" + VAR_17[1] +\n    \""' where problem = '\"" + VAR_16[3] + \""' and diff = '\"" + VAR_16[4] + \""'\"")\n"", ""if VAR_9 != None and VAR_9[2] != 'OK':\n"", ""VAR_7.execute(\""update result set verdict = '\"" + VAR_17[1] +\n    \""' where problem = '\"" + VAR_16[3] + \""' and diff = '\"" + VAR_16[4] + \""'\"")\n""]",1
"[""def FUNC_3(self, VAR_8):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_19 = self._cliq_get_cluster_info(VAR_8)\n"", ""VAR_20 = []\n"", ""for vip in VAR_19.findall('response/cluster/vip'):\n"", ""VAR_20.append(vip.attrib.get('ipAddress'))\n"", ""if len(VAR_20) == 1:\n"", ""return VAR_20[0]\n"", ""VAR_21 = etree.tostring(VAR_19)\n"", ""VAR_22 = _(\n    'Unexpected number of virtual ips for cluster  %(cluster_name)s. Result=%(_xml)s'\n    ) % {'cluster_name': VAR_8, '_xml': VAR_21}\n""]",0
"[""from __future__ import absolute_import\n"", ""from __future__ import division\n"", ""from __future__ import print_function\n"", ""import argparse\n"", ""import logging\n"", ""import os\n"", ""import redis\n"", ""import time\n"", ""import ray.ray_constants as ray_constants\n"", ""from ray.services import get_ip_address\n"", ""from ray.services import get_port\n"", ""import ray.utils\n"", ""VAR_0 = logging.getLogger(__name__)\n"", ""\""\""\""string\""\""\""\n"", ""def __init__(self, VAR_1, VAR_2, VAR_3, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.node_ip_address = VAR_3\n"", ""self.redis_client = redis.StrictRedis(host=redis_ip_address, port=\n    redis_port, password=redis_password)\n"", ""self.log_files = {}\n"", ""self.log_file_handles = {}\n"", ""self.files_to_ignore = set()\n"", ""def FUNC_0(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_8 = len(self.log_files)\n"", ""VAR_9 = self.redis_client.lrange('LOG_FILENAMES:{}'.format(self.\n    node_ip_address), VAR_8, -1)\n"", ""for VAR_10 in VAR_9:\n"", ""VAR_0.info('Beginning to track file {}'.format(VAR_10))\n"", ""def FUNC_1(self):...\n"", ""assert VAR_10 not in self.log_files\n"", ""\""\""\""docstring\""\""\""\n"", ""self.log_files[VAR_10] = []\n"", ""for VAR_10 in self.log_files:\n"", ""if VAR_10 in self.log_file_handles:\n"", ""def FUNC_2(self):...\n"", ""VAR_11 = []\n"", ""if VAR_10 in self.files_to_ignore:\n"", ""\""\""\""docstring\""\""\""\n"", ""while True:\n"", ""self.log_file_handles[VAR_10] = open(VAR_10, 'r')\n"", ""if e.errno == os.errno.EMFILE:\n"", ""while True:\n"", ""VAR_12 = self.log_file_handles[VAR_10].tell()\n"", ""VAR_0.warning('Warning: Ignoring {} because there are too many open files.'\n    .format(VAR_10))\n"", ""if e.errno == os.errno.ENOENT:\n"", ""self.update_log_filenames()\n"", ""VAR_13 = self.log_file_handles[VAR_10].readline()\n"", ""self.files_to_ignore.add(VAR_10)\n"", ""VAR_0.warning('Warning: The file {} was not found.'.format(VAR_10))\n"", ""self.check_log_files_and_push_updates()\n"", ""if VAR_13 != '':\n"", ""time.sleep(1)\n"", ""VAR_11.append(VAR_13)\n"", ""self.log_file_handles[VAR_10].seek(VAR_12)\n"", ""if len(VAR_11) > 0:\n"", ""self.log_files[VAR_10] += VAR_11\n"", ""VAR_14 = 'LOGFILE:{}:{}'.format(self.node_ip_address, ray.utils.decode(VAR_10))\n"", ""self.redis_client.rpush(VAR_14, *VAR_11)\n""]",1
"[""def FUNC_15(self, VAR_0, VAR_1, VAR_10, VAR_3=None):...\n"", ""if not VAR_3:\n"", ""VAR_3 = self.make_reqid()\n"", ""VAR_8 = [VAR_0, VAR_1, make_auth_hash(VAR_0, VAR_1, VAR_3, VAR_10)]\n"", ""return b'Router', b'auth-request', VAR_8, VAR_3\n""]",0
"[""def FUNC_8(VAR_7):...\n"", ""VAR_11 = f\""\""\""\n            SELECT COUNT(r.id) AS total\n            FROM {VAR_2} AS r\n            WHERE r.product_id={VAR_7}\n            \""\""\""\n"", ""VAR_12 = create_connection()\n"", ""VAR_12.close()\n"", ""VAR_13 = VAR_12.cursor()\n"", ""VAR_13.execute(VAR_11)\n"", ""return int(VAR_13.fetchone()['total'])\n""]",1
"[""def FUNC_4(self):...\n"", ""self.init()\n"", ""VAR_14 = []\n"", ""VAR_15 = [{'name': 'ID', 'value': self.params.facility_name}]\n"", ""VAR_2 = model.Report.all().ancestor(self.version).filter('facility_name =',\n    self.params.facility_name).order('-timestamp').get()\n"", ""for VAR_6 in self.facility_type.attribute_names:\n"", ""VAR_3 = self.attributes[VAR_6]\n"", ""self.render('templates/edit.html', facility=self.facility, VAR_14=fields,\n    VAR_15=readonly_fields, params=self.params, authorization=self.auth and\n    self.auth.description or 'anonymous', logout_url=users.\n    create_logout_url('/'))\n"", ""if VAR_6 in self.readonly_attribute_names:\n"", ""VAR_15.append({'name': get_message(self.version, 'attribute_name', VAR_6),\n    'value': getattr(VAR_2, VAR_6, None)})\n"", ""VAR_14.append({'name': get_message(self.version, 'attribute_name', VAR_6),\n    'type': VAR_3.type, 'input': FUNC_0(self.version, VAR_2, VAR_3)})\n""]",1
"[""def __gt__(self, VAR_11):...\n"", ""return self.rule.__gt__(VAR_11.rule)\n""]",0
"[""def FUNC_2(self, VAR_9, VAR_10='user_db'):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_14, VAR_18, VAR_24, VAR_25 = VAR_9\n"", ""VAR_26 = 'string' % {'database': VAR_10, 'user_freq': VAR_25, 'mlen': len(\n    VAR_14), 'clen': len(VAR_18), 'input_phrase': VAR_14, 'phrase': VAR_18}\n"", ""self.db.execute(VAR_26)\n"", ""self.db.commit()\n""]",1
"[""def FUNC_1():...\n"", ""VAR_0 = DisclosureExporter(TEST_BW_PROJECT_NAME, TEST_BW_DB_NAME,\n    folder_path=TEST_FOLDER, filename=TEST_FILENAME)\n"", ""VAR_1 = VAR_0.write_json()\n"", ""print(VAR_1)\n"", ""assert os.path.isfile(VAR_1)\n""]",1
"[""def FUNC_1(self):...\n"", ""self.client.login(username=self.user.username, password='testing')\n"", ""VAR_1 = self.client.get(reverse('iframe-navigation'))\n"", ""self.assertContains(VAR_1, urlencode({'people': self.user.email}))\n"", ""self.assertContains(VAR_1, urlencode({'author__email__startswith': self.\n    user.email}))\n""]",0
"[""from django.http import HttpResponse, HttpResponseRedirect\n"", ""from django.shortcuts import get_object_or_404, render\n"", ""from django.views.generic import TemplateView, DetailView\n"", ""from .forms import SearchForm\n"", ""from lib.geoip import GeoIP\n"", ""from lib.vt import VT\n"", ""from lib.threatminer import ThreatMiner\n"", ""import socket\n"", ""from django.db.models import Q\n"", ""from apps.threat.models import Event, Attribute\n"", ""from apps.reputation.models import blacklist\n"", ""from apps.twitter.models import tweet\n"", ""from apps.exploit.models import Exploit\n"", ""VAR_0 = 'domain/index.html'\n"", ""def FUNC_0(self, **VAR_1):...\n"", ""VAR_3 = super().get_context_data(**kwargs)\n"", ""VAR_3['search_form'] = SearchForm()\n"", ""return VAR_3\n""]",1
"[""def FUNC_2(VAR_6, VAR_7):...\n"", ""VAR_8 = VAR_1 and VAR_2\n"", ""VAR_9 = 'SELECT COALESCE(COUNT(' + VAR_0 + '.' + VAR_3 + '), 0) FROM ' + VAR_0\n"", ""if VAR_8:\n"", ""VAR_9 += ' LEFT JOIN ' + VAR_1\n"", ""VAR_9 += ' WHERE (' + VAR_0 + '.' + VAR_3 + ' = :x'\n"", ""if VAR_8:\n"", ""VAR_9 += ' AND ' + VAR_1 + '.id = ' + str(VAR_6[VAR_2].data)\n"", ""VAR_9 += ');'\n"", ""VAR_10 = text(VAR_9)\n"", ""VAR_11 = db.engine.execute(VAR_10, x=field.data)\n"", ""for row in VAR_11:\n"", ""if row[0] > 0:\n""]",1
"[""from aputils.trainee_utils import is_trainee\n"", ""from .models import GospelTrip\n"", ""def FUNC_0(VAR_0):...\n"", ""VAR_1 = VAR_0.user\n"", ""if not hasattr(VAR_1, 'type') or not is_trainee(VAR_1):\n"", ""return {'gospel_trips_available': False}\n"", ""VAR_2 = next((gt for gt in GospelTrip.objects.order_by('-open_time') if gt.\n    is_open), None)\n"", ""return {'gospel_trips_available': False}\n"", ""if VAR_2:\n"", ""if VAR_2.is_open:\n"", ""return {'gospel_trips_available': False}\n"", ""return {'gospel_trips_available': True}\n""]",1
"[""\""\""\""Networks plugin - allows you to manipulate connections to various configured networks.\""\""\""\n"", ""import importlib\n"", ""import types\n"", ""from pylinkirc import utils, world, conf, classes\n"", ""from pylinkirc.log import log\n"", ""from pylinkirc.coremods import control, permissions\n"", ""@utils.add_cmd...\n"", ""\""\""\""docstring\""\""\""\n"", ""permissions.checkPermissions(VAR_0, VAR_1, ['networks.disconnect'])\n"", ""VAR_5 = VAR_2[0]\n"", ""VAR_0.error('Not enough arguments (needs 1: network name (case sensitive)).')\n"", ""VAR_0.reply(\n    \""Done. If you want to reconnect this network, use the 'rehash' command.\"")\n"", ""VAR_4 = world.networkobjects[VAR_5]\n"", ""return\n"", ""control.remove_network(VAR_4)\n"", ""@utils.add_cmd...\n"", ""\""\""\""docstring\""\""\""\n"", ""permissions.checkPermissions(VAR_0, VAR_1, ['networks.autoconnect'])\n"", ""VAR_5 = VAR_2[0]\n"", ""VAR_0.error(\n    'Not enough arguments (needs 2: network name (case sensitive), autoconnect time (in seconds)).'\n    )\n"", ""VAR_4.serverdata['autoconnect'] = VAR_11\n"", ""VAR_11 = float(VAR_2[1])\n"", ""return\n"", ""VAR_0.reply('Done.')\n"", ""VAR_4 = world.networkobjects[VAR_5]\n"", ""VAR_3 = utils.IRCParser()\n"", ""VAR_3.add_argument('network')\n"", ""VAR_3.add_argument('--service', type=str, default='pylink')\n"", ""VAR_3.add_argument('command', nargs=utils.IRCParser.REMAINDER)\n"", ""@utils.add_cmd...\n"", ""\""\""\""docstring\""\""\""\n"", ""permissions.checkPermissions(VAR_0, VAR_1, ['networks.remote'])\n"", ""VAR_2 = VAR_3.parse_args(VAR_2)\n"", ""VAR_5 = VAR_2.network\n"", ""if VAR_5 == VAR_0.name:\n"", ""VAR_0.error(\n    'Cannot remote-send a command to the local network; use a normal command!')\n"", ""VAR_12 = world.networkobjects[VAR_5]\n"", ""VAR_0.error('No such network \""%s\"" (case sensitive).' % VAR_5)\n"", ""if VAR_2.service not in world.services:\n"", ""return\n"", ""return\n"", ""VAR_0.error('Unknown service %r.' % VAR_2.service)\n"", ""VAR_12.called_in = VAR_12.called_by = VAR_12.pseudoclient.uid\n"", ""return\n"", ""VAR_12.pseudoclient.account = VAR_0.users[VAR_1].account\n"", ""def FUNC_4(VAR_6, VAR_7, **VAR_8):...\n"", ""\""\""\""docstring\""\""\""\n"", ""assert VAR_0.name != VAR_6.name, 'Refusing to route reply back to the same network, as this would cause a recursive loop'\n"", ""log.debug('(%s) networks.remote: re-routing reply %r from network %s',\n    VAR_0.name, VAR_7, VAR_6.name)\n"", ""if 'source' in VAR_8:\n"", ""VAR_0.reply(VAR_7, VAR_1=irc.pseudoclient.uid, **kwargs)\n"", ""VAR_9 = VAR_12.reply\n"", ""log.debug('(%s) networks.remote: overriding reply() of IRC object %s',\n    VAR_0.name, VAR_5)\n"", ""log.debug('(%s) networks.remote: restoring reply() of IRC object %s', VAR_0\n    .name, VAR_5)\n"", ""@utils.add_cmd...\n"", ""VAR_12.reply = types.MethodType(FUNC_4, VAR_12)\n"", ""VAR_12.reply = VAR_9\n"", ""\""\""\""docstring\""\""\""\n"", ""world.services[VAR_2.service].call_cmd(VAR_12, VAR_12.pseudoclient.uid, ' '\n    .join(VAR_2.command))\n"", ""VAR_12.pseudoclient.account = ''\n"", ""permissions.checkPermissions(VAR_0, VAR_1, ['networks.reloadproto'])\n"", ""VAR_13 = VAR_2[0]\n"", ""VAR_0.error('Not enough arguments (needs 1: protocol module name)')\n"", ""VAR_10 = utils.getProtocolModule(VAR_13)\n"", ""return\n"", ""importlib.reload(VAR_10)\n"", ""VAR_0.reply('string' % VAR_13)\n""]",1
"[""def FUNC_5(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'MEDIUM': 11}, 'CONFIDENCE': {'HIGH': 11}}\n"", ""self.check_example('crypto-md5.py', VAR_2)\n""]",0
"[""def FUNC_2():...\n"", ""bw2.projects.set_current(IMPORT_PROJECT_NAME)\n"", ""VAR_2 = DisclosureImporter(os.path.join(os.path.dirname(os.path.realpath(\n    __file__)), TEST_FOLDER, '{}.json'.format(TEST_FILENAME)))\n"", ""VAR_2.apply_strategies()\n"", ""assert VAR_2.statistics()[2] == 0\n"", ""VAR_2.write_database()\n"", ""assert len(bw2.Database(VAR_2.db_name)) != 0\n""]",1
"[""from soscollector.clusters import Cluster\n"", ""VAR_0 = 'kubernetes-master',\n"", ""VAR_1 = ['kubernetes']\n"", ""VAR_2 = {'kubernetes.all': 'on'}\n"", ""VAR_3 = 'kubectl'\n"", ""VAR_4 = [('label', '', 'Filter node list to those with matching label'), (\n    'role', '', 'Filter node list to those with matching role')]\n"", ""def FUNC_0(self):...\n"", ""self.cmd += ' get nodes'\n"", ""if self.get_option('label'):\n"", ""self.cmd += ' -l %s ' % self.get_option('label')\n"", ""VAR_6 = self.exec_master_cmd(self.cmd)\n"", ""if VAR_6['status'] == 0:\n"", ""VAR_7 = []\n"", ""VAR_0 = 'atomic-openshift',\n"", ""VAR_8 = [x for x in self.get_option('role').split(',') if x]\n"", ""VAR_5 = 'ocp'\n"", ""for nodeln in VAR_6['stdout'].splitlines()[1:]:\n"", ""VAR_3 = 'oc'\n"", ""VAR_9 = nodeln.split()\n"", ""return VAR_7\n"", ""if not VAR_8:\n"", ""VAR_7.append(VAR_9[0])\n"", ""if VAR_9[2] in VAR_8:\n"", ""VAR_7.append(VAR_9[0])\n""]",1
"[""def FUNC_27(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if not self.exists and FUNC_0(self.file):\n""]",1
"[""@require_http_methods(['GET'])...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7 = get_next_url_for_login_page(VAR_3)\n"", ""if VAR_3.user.is_authenticated():\n"", ""return redirect(VAR_7)\n"", ""VAR_13 = FUNC_6(VAR_3)\n"", ""VAR_14 = None\n"", ""if '?' in VAR_7:\n"", ""if is_request_in_themed_site() and not configuration_helpers.get_value(\n"", ""VAR_43 = urlparse.parse_qs(urlparse.urlparse(VAR_7).query)\n"", ""if VAR_4 == 'login':\n"", ""VAR_15 = FUNC_8(VAR_3, VAR_4)\n"", ""VAR_44 = VAR_43['tpa_hint'][0]\n"", ""return old_login_view(VAR_3)\n"", ""if VAR_4 == 'register':\n"", ""if VAR_15 is not None:\n"", ""VAR_45 = third_party_auth.provider.Registry.get(VAR_44=provider_id)\n"", ""return old_register_view(VAR_3)\n"", ""return VAR_15\n"", ""VAR_16 = [{'message': message.message, 'tags': message.tags} for message in\n    messages.get_messages(VAR_3) if 'account-activation' in message.tags]\n"", ""if VAR_45:\n"", ""VAR_5 = {'data': {'login_redirect_url': VAR_7, 'initial_mode': VAR_4,\n    'third_party_auth': FUNC_5(VAR_3, VAR_7, VAR_14),\n    'third_party_auth_hint': VAR_14 or '', 'platform_name':\n    configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME\n    ), 'support_link': configuration_helpers.get_value('SUPPORT_SITE_LINK',\n    settings.SUPPORT_SITE_LINK), 'password_reset_support_link': \n    configuration_helpers.get_value('PASSWORD_RESET_SUPPORT_LINK', settings\n    .PASSWORD_RESET_SUPPORT_LINK) or settings.SUPPORT_SITE_LINK,\n    'account_activation_messages': VAR_16, 'login_form_desc': json.loads(\n    VAR_13['login']), 'registration_form_desc': json.loads(VAR_13[\n    'registration']), 'password_reset_form_desc': json.loads(VAR_13[\n    'password_reset']), 'account_creation_allowed': configuration_helpers.\n    get_value('ALLOW_PUBLIC_ACCOUNT_CREATION', settings.FEATURES.get(\n    'ALLOW_PUBLIC_ACCOUNT_CREATION', True))}, 'login_redirect_url': VAR_7,\n    'responsive': True, 'allow_iframing': True, 'disable_courseware_js': \n    True, 'combined_login_and_register': True, 'disable_footer': not\n    configuration_helpers.get_value(\n    'ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER', settings.FEATURES[\n    'ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER'])}\n"", ""if VAR_45.skip_hinted_login_dialog:\n"", ""VAR_5 = FUNC_2(VAR_3, VAR_5)\n"", ""return redirect(pipeline.get_login_url(VAR_44, pipeline.AUTH_ENTRY_LOGIN,\n    redirect_url=redirect_to))\n"", ""VAR_14 = VAR_44\n"", ""return render_to_response('student_account/login_and_register.html', VAR_5)\n"", ""VAR_4 = 'hinted_login'\n""]",1
"[""def FUNC_0(VAR_0, VAR_1):...\n"", ""if VAR_0.exception != 'None':\n"", ""return False\n"", ""VAR_2 = VAR_0.answer.split('.')[3]\n"", ""return VAR_2 in VAR_1\n""]",1
"[""def FUNC_0(VAR_0):...\n"", ""VAR_3 = VAR_0.lower()\n"", ""if VAR_3 in ('yes', 'true', 't', '1', 'y'):\n"", ""return True\n"", ""if VAR_3 in ('no', 'false', 'f', 'n', '0'):\n"", ""return False\n""]",0
"[""from pylons import c, request, g\n"", ""from pylons.i18n import _\n"", ""from pylons.controllers.util import abort\n"", ""from r2.lib import utils, captcha\n"", ""from r2.lib.filters import unkeep_space, websafe, _force_utf8, _force_ascii\n"", ""from r2.lib.db.operators import asc, desc\n"", ""from r2.config import cache\n"", ""from r2.lib.template_helpers import add_sr\n"", ""from r2.lib.jsonresponse import json_respond\n"", ""from r2.models import *\n"", ""from r2.controllers.errors import errors, UserRequiredException\n"", ""from copy import copy\n"", ""from datetime import datetime, timedelta\n"", ""import re\n"", ""VAR_6 = None\n"", ""def __init__(self, VAR_7=None, VAR_8=None, VAR_9=True, VAR_10=True, VAR_11=True...\n"", ""if VAR_7:\n"", ""self.param = VAR_7\n"", ""self.param = self.default_param\n"", ""self.default = VAR_8\n"", ""self.post, self.get, self.url = VAR_9, VAR_10, VAR_11\n"", ""def __call__(self, VAR_11):...\n"", ""VAR_15 = []\n"", ""if self.param:\n"", ""for p in utils.tup(self.param):\n"", ""return self.run(*VAR_15)\n"", ""if self.post and VAR_102.post.get(p):\n"", ""VAR_33 = VAR_102.post[p]\n"", ""if self.get and VAR_102.get.get(p):\n"", ""VAR_15.append(VAR_33)\n"", ""VAR_33 = VAR_102.get[p]\n"", ""if self.url and VAR_11.get(p):\n"", ""VAR_33 = VAR_11[p]\n"", ""VAR_33 = self.default\n""]",0
"[""def FUNC_0(VAR_2):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if not FUNC_4('pdftotext'):\n"", ""VAR_0.warning(\n    'GNU file was not found on the system. Switching to a weak file extension test.'\n    )\n"", ""VAR_9 = os.popen('file ' + re.escape(VAR_2)).read()\n"", ""if VAR_2.lower().endswith('.pdf'):\n"", ""VAR_19 = VAR_9.split(':')[1]\n"", ""VAR_0.error('string')\n"", ""VAR_10 = VAR_19.find('PDF') > -1\n"", ""return True\n"", ""return False\n"", ""return VAR_10\n""]",1
"[""def FUNC_7(self, VAR_0, VAR_1, VAR_2, VAR_3, VAR_4, VAR_8=True):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7 = CLASS_0(VAR_0, VAR_1, VAR_2, VAR_3, VAR_4)\n"", ""self.users[VAR_0] = VAR_7\n"", ""if VAR_8:\n"", ""self._add_to_db(VAR_7)\n"", ""return VAR_7\n""]",0
"[""def FUNC_29(VAR_16, VAR_22, VAR_28):...\n"", ""VAR_53 = (\""SELECT date, rank FROM ranks WHERE scene='{}' AND player='{}'\"".\n    format(VAR_22, VAR_28))\n"", ""VAR_54 = VAR_16.exec(VAR_53)\n"", ""VAR_54 = [VAR_41 for VAR_41 in VAR_54 if FUNC_34(VAR_16, VAR_22, VAR_28,\n    FUNC_23(VAR_41[0]))]\n"", ""VAR_78 = {}\n"", ""for VAR_41 in VAR_54:\n"", ""VAR_78[VAR_41[0]] = VAR_41[1]\n"", ""return VAR_78\n""]",1
"[""def FUNC_0(VAR_0):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = VAR_0.copy()\n"", ""VAR_2['QUERY_STRING'] = ''\n"", ""VAR_3 = cgi.FieldStorage(fp=environ['wsgi.input'], VAR_0=data_env,\n    keep_blank_values=True)\n"", ""return VAR_3\n""]",0
"[""def FUNC_3(self, VAR_14):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_19 = self.__con.cursor()\n"", ""VAR_19.execute(\""INSERT INTO tags(name) VALUE('%s')\"" % VAR_14)\n"", ""return CLASS_0.DUPLICATE\n"", ""return CLASS_0.SUCCESS\n""]",1
"[""def FUNC_1(self, VAR_3):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_4 = '/api/keys'\n"", ""VAR_5 = {'id': 'mykey@box.local', 'public': VAR_3}\n"", ""VAR_6 = self.client.post(VAR_4, json.dumps(VAR_5), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_6.status_code, 201)\n"", ""VAR_7 = VAR_6.data['id']\n"", ""VAR_6 = self.client.get(VAR_4)\n"", ""self.assertEqual(VAR_6.status_code, 200)\n"", ""self.assertEqual(len(VAR_6.data['results']), 1)\n"", ""VAR_4 = '/api/keys/{key_id}'.format(**locals())\n"", ""VAR_6 = self.client.get(VAR_4)\n"", ""self.assertEqual(VAR_6.status_code, 200)\n"", ""self.assertEqual(VAR_5['id'], VAR_6.data['id'])\n"", ""self.assertEqual(VAR_5['public'], VAR_6.data['public'])\n"", ""VAR_6 = self.client.delete(VAR_4)\n"", ""self.assertEqual(VAR_6.status_code, 204)\n""]",1
"[""@db.transact...\n"", ""if not self.consumed(VAR_1, VAR_2):\n"", ""VAR_8 = self.context.current_obj\n"", ""return []\n"", ""if IContainer.providedBy(VAR_8):\n"", ""return [name for name in VAR_8.listnames() if name.startswith(VAR_0)]\n""]",1
"[""def FUNC_14(self, VAR_11, VAR_12):...\n"", ""self.common._cli_run('createhost -iscsi -add %s %s' % (VAR_11, VAR_12), None)\n""]",1
"[""def FUNC_4(VAR_3):...\n"", ""if not VAR_3:\n"", ""return errors.BAD_USERNAME_CHARS\n"", ""if len(VAR_3) < 3:\n"", ""return errors.BAD_USERNAME_SHORT\n"", ""if len(VAR_3) > 20:\n"", ""return errors.BAD_USERNAME_LONG\n"", ""return errors.BAD_USERNAME_CHARS\n""]",0
"[""@utils.synchronized('3par', external=True)...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.common.client_login()\n"", ""self.common.terminate_connection(VAR_6, VAR_9['host'], VAR_9['wwpns'])\n"", ""self.common.client_logout()\n""]",0
"[""from bottle import static_file\n"", ""from streamline import NonIterableRouteBase\n"", ""VAR_0 = '/static/<path:path>'\n"", ""def FUNC_0(self):...\n"", ""return self.config['runtime.static_dir']\n""]",1
"[""def FUNC_1(self):...\n"", ""self.assertTrue(self.client.login(VAR_8='autotest', VAR_9='password'))\n""]",1
"[""def FUNC_0(self, VAR_2, VAR_3, VAR_4, VAR_5):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = []\n"", ""VAR_7 = self.pool.get('ir.model.data')\n"", ""VAR_8 = self.pool.get('res.users').browse(VAR_2, VAR_3, VAR_3).company_id.id\n"", ""VAR_9 = self.pool.get('account.bank.statement')\n"", ""VAR_10 = self.pool.get('ir.sequence')\n"", ""VAR_11 = self.pool.get('account.journal')\n"", ""VAR_2.execute(\n    'select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id'\n     % VAR_3)\n"", ""VAR_12 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""VAR_2.execute('string' % ','.join(map(lambda x: \""'\"" + str(x) + \""'\"", VAR_12)))\n"", ""VAR_13 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""for journal in VAR_11.browse(VAR_2, VAR_3, VAR_13):\n"", ""VAR_4 = VAR_9.search(VAR_2, VAR_3, [('state', '!=', 'confirm'), ('user_id',\n    '=', VAR_3), ('journal_id', '=', journal.id)])\n"", ""VAR_14 = self.pool.get('ir.model.data')\n"", ""if len(VAR_4):\n"", ""VAR_15 = VAR_14._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_tree')\n"", ""VAR_17 = ''\n"", ""VAR_16 = VAR_14._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_form2')\n"", ""if journal.sequence_id:\n"", ""if VAR_15:\n"", ""VAR_17 = VAR_10.get_id(VAR_2, VAR_3, journal.sequence_id.id)\n"", ""VAR_17 = VAR_10.get(VAR_2, VAR_3, 'account.bank.statement')\n"", ""VAR_15 = VAR_14.browse(VAR_2, VAR_3, VAR_15, VAR_5=context).res_id\n"", ""if VAR_16:\n"", ""VAR_18 = VAR_9.create(VAR_2, VAR_3, {'journal_id': journal.id, 'company_id':\n    VAR_8, 'user_id': VAR_3, 'state': 'open', 'name': VAR_17,\n    'starting_details_ids': VAR_9._get_cash_close_box_lines(VAR_2, VAR_3, [])})\n"", ""VAR_16 = VAR_14.browse(VAR_2, VAR_3, VAR_16, VAR_5=context).res_id\n"", ""return {'domain': \""[('state','=','open')]\"", 'name': 'Open Statement',\n    'view_type': 'form', 'view_mode': 'tree,form', 'res_model':\n    'account.bank.statement', 'views': [(VAR_15, 'tree'), (VAR_16, 'form')],\n    'type': 'ir.actions.act_window'}\n"", ""VAR_9.button_open(VAR_2, VAR_3, [VAR_18], VAR_5)\n""]",1
"[""def FUNC_11(VAR_1, *VAR_8, **VAR_9):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if current_user.is_authenticated():\n"", ""return redirect('/')\n"", ""VAR_21 = FUNC_5(VAR_1)\n"", ""if not VAR_21:\n"", ""return redirect('/')\n"", ""if not VAR_16.get(VAR_17(VAR_1.name) + '_autoregister', False):\n"", ""return redirect(url_for('.login', VAR_0=remote.name))\n"", ""VAR_22 = EmailSignUpForm(request.form)\n"", ""if VAR_22.validate_on_submit():\n"", ""VAR_27 = VAR_16.get(VAR_17(VAR_1.name) + '_account_info')\n"", ""return render_template('oauthclient/signup.html', VAR_22=form, VAR_1=remote,\n    app_title=cfg['OAUTHCLIENT_REMOTE_APPS'][remote.name].get('title', ''),\n    app_description=cfg['OAUTHCLIENT_REMOTE_APPS'][remote.name].get(\n    'description', ''), app_icon=cfg['OAUTHCLIENT_REMOTE_APPS'][remote.name\n    ].get('icon', None))\n"", ""VAR_11 = oauth_register(VAR_27, VAR_22.data)\n"", ""if VAR_11 is None:\n"", ""VAR_16.pop(VAR_17(VAR_1.name) + '_autoregister', None)\n"", ""if not oauth_authenticate(VAR_1.consumer_key, VAR_11, require_existing_link\n"", ""return current_app.login_manager.unauthorized()\n"", ""VAR_5 = FUNC_4(VAR_1, VAR_21[0], VAR_6=oauth_token[1])\n"", ""VAR_19 = signup_handlers[VAR_1.name]\n"", ""if VAR_5 is None:\n"", ""if not VAR_5.remote_account.extra_data:\n"", ""VAR_19['setup'](VAR_5)\n"", ""VAR_16.pop(VAR_17(VAR_1.name) + '_account_info', None)\n"", ""if request.args.get('next', None):\n"", ""return redirect(request.args.get('next'))\n"", ""return redirect('/')\n""]",0
"[""@query_cached...\n"", ""VAR_25 = hashlib.sha1(str(VAR_20).encode('utf-8')).hexdigest()\n"", ""VAR_35 = re.match('.*?select\\\\s(.*)from.*', VAR_20, flags=re.IGNORECASE |\n    re.UNICODE | re.DOTALL)\n"", ""if VAR_35:\n"", ""VAR_26 = []\n"", ""VAR_26 = []\n"", ""VAR_44 = 0\n"", ""VAR_0.warning(\n    'Redshift unload requires poorly parsing column names from sql, found: {}'\n    .format(VAR_26))\n"", ""VAR_45 = VAR_35[1].split(',')\n"", ""VAR_20 = \""UNLOAD ('\"" + VAR_20.replace('\\\\', '\\\\\\\\').replace(\""'\"", \""\\\\'\"") + \""') \""\n"", ""for VAR_51 in VAR_45:\n"", ""VAR_20 += \""TO 's3://\"" + os.path.join(lore.io.bucket.name, self.\n    UNLOAD_PREFIX, VAR_25, '') + \""' \""\n"", ""VAR_44 += VAR_51.count('(')\n"", ""if CLASS_0.IAM_ROLE:\n"", ""VAR_44 -= VAR_51.count(')')\n"", ""VAR_20 += \""IAM_ROLE '\"" + CLASS_0.IAM_ROLE + \""' \""\n"", ""VAR_20 += \""DELIMITER '|' ADDQUOTES GZIP ALLOWOVERWRITE\""\n"", ""if VAR_44 == 0:\n"", ""if re.match('(.*?)(limit\\\\s+\\\\d+)(.*)', VAR_20, re.IGNORECASE | re.UNICODE |\n"", ""VAR_26.append(VAR_51.split()[-1].split('.')[-1].strip())\n"", ""if VAR_51 == VAR_45[-1]:\n"", ""VAR_0.warning('LIMIT clause is not supported by unload, returning full set.')\n"", ""self.__execute(VAR_20, VAR_24)\n"", ""VAR_51 = re.split('from', VAR_51, flags=re.IGNORECASE)[0].strip()\n"", ""VAR_20 = re.sub('(.*?)(limit\\\\s+\\\\d+)(.*)', '\\\\1\\\\3', VAR_20, flags=re.\n    IGNORECASE | re.UNICODE | re.DOTALL)\n"", ""return VAR_25, VAR_26\n"", ""VAR_26.append(VAR_51.split()[-1].split('.')[-1].strip())\n""]",0
"[""def FUNC_10():...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_9 = FUNC_3('select * from player_static_view order by wins desc')\n"", ""VAR_10 = 0\n"", ""VAR_11 = len(VAR_9)\n"", ""VAR_12 = []\n"", ""while VAR_10 < VAR_11:\n"", ""VAR_12.append((VAR_9[VAR_10][0], VAR_9[VAR_10][1], VAR_9[VAR_10 + 1][0],\n    VAR_9[VAR_10 + 1][1]))\n"", ""return VAR_12\n"", ""VAR_10 += 2\n""]",0
"[""def FUNC_0():...\n"", ""VAR_7.pack_forget()\n"", ""VAR_5.pack(expand=True, fill='both')\n"", ""VAR_12 = 'meal_planner.db'\n"", ""VAR_20 = conn.cursor()\n"", ""VAR_21 = VAR_20.execute('SELECT * FROM recipe')\n"", ""for result in [VAR_21]:\n"", ""for row in result.fetchall():\n"", ""conn.close()\n"", ""VAR_24 = row[0]\n"", ""for i in range(len(VAR_2)):\n"", ""VAR_2.append(VAR_24)\n"", ""VAR_13 = Label(VAR_5, font=MEDIUM_FONT, bg='#f8f8f8', fg='#000000', text=\n    recipeNames[i])\n"", ""VAR_13.pack()\n"", ""VAR_13.bind('<Button-1>', lambda event, x=VAR_2[i]: [FUNC_1(x), VAR_5.\n    pack_forget()])\n""]",1
"[""@api.model...\n"", ""VAR_22 = self.env['crapo.automaton']\n"", ""VAR_23 = self.env['ir.model'].search([('model', '=', self._name)], limit=1)\n"", ""VAR_24 = VAR_22.search([('model_id', '=', VAR_23.id)], limit=1)\n"", ""if VAR_24:\n"", ""return VAR_24\n"", ""return VAR_22.create({'name': 'Automaton for {}'.format(self._name),\n    'model_id': VAR_23.id})\n""]",0
"[""import unittest\n"", ""import re\n"", ""from mockito import mock, when, any as ANY\n"", ""from pixelated.application import UserAgentMode\n"", ""from test.unit.resources import DummySite\n"", ""from twisted.web.test.requesthelper import DummyRequest\n"", ""from pixelated.resources.root_resource import RootResource\n"", ""VAR_0 = 'test_user@pixelated-project.org'\n"", ""def FUNC_0(self):...\n"", ""self.mail_service = mock()\n"", ""self.services_factory = mock()\n"", ""self.services_factory.mode = UserAgentMode(is_single_user=True)\n"", ""self.services = mock()\n"", ""self.services.mail_service = self.mail_service\n"", ""self.services_factory._services_by_user = {'someuserid': self.mail_service}\n"", ""when(self.services_factory).services(ANY()).thenReturn(self.services)\n"", ""self.mail_service.account_email = self.MAIL_ADDRESS\n"", ""VAR_1 = RootResource(self.services_factory)\n"", ""VAR_1._html_template = (\n    '<html><head><title>$account_email</title></head></html>')\n"", ""VAR_1._mode = VAR_1\n"", ""self.web = DummySite(VAR_1)\n"", ""def FUNC_1(self):...\n"", ""VAR_2 = DummyRequest([''])\n"", ""VAR_3 = self.web.get(VAR_2)\n"", ""def FUNC_2(VAR_4):...\n"", ""VAR_5 = '<title>{0}</title>'.format(self.MAIL_ADDRESS)\n"", ""VAR_6 = re.findall(VAR_5, VAR_2.written[0])\n"", ""self.assertEquals(len(VAR_6), 1)\n"", ""VAR_3.addCallback(FUNC_2)\n"", ""return VAR_3\n""]",1
"[""from django.http import HttpResponse, HttpResponseRedirect\n"", ""from django.shortcuts import get_object_or_404, render\n"", ""from django.views.generic import ListView, DetailView\n"", ""from pure_pagination.mixins import PaginationMixin\n"", ""from django.db.models import Q\n"", ""from .models import tweet\n"", ""from .forms import SearchForm\n"", ""from django.http import JsonResponse\n"", ""from urllib.parse import urlparse\n"", ""from http.client import HTTPSConnection\n"", ""from datetime import datetime, timezone, timedelta\n"", ""VAR_2 = 'twitter/index.html'\n"", ""VAR_3 = 'tws'\n"", ""VAR_4 = 30\n"", ""def FUNC_2(self, **VAR_5):...\n"", ""VAR_10 = super().get_context_data(**kwargs)\n"", ""VAR_11 = SearchForm(self.request.GET)\n"", ""VAR_10['search_form'] = VAR_11\n"", ""VAR_12 = self.object_list.count()\n"", ""VAR_10['count'] = VAR_12\n"", ""VAR_10['30_day_labels'] = self.thirty_day_labels()\n"", ""VAR_10['30_day_data'] = self.thirty_day_data()\n"", ""return VAR_10\n""]",1
"[""def FUNC_13(self):...\n"", ""VAR_4 = {'r': u'not ascii £ һ'}\n"", ""VAR_1 = 'http://my.url.com'\n"", ""VAR_2 = 'True'\n"", ""url_helper.urllib2.urlopen(mox.StrContains(VAR_1), mox.IgnoreArg(), timeout\n    =mox.IgnoreArg()).AndReturn(StringIO.StringIO(VAR_2))\n"", ""self._mox.ReplayAll()\n"", ""self.assertEqual(url_helper.UrlOpen(VAR_1, VAR_4=data), VAR_2)\n"", ""self._mox.VerifyAll()\n""]",1
"[""def FUNC_16():...\n"", ""VAR_38 = socket(AF_INET, SOCK_STREAM)\n"", ""VAR_38.bind(('', 0))\n"", ""VAR_39 = VAR_38.getsockname()[1]\n"", ""VAR_38.close()\n"", ""return VAR_39\n""]",0
"[""def __init__(self, VAR_1, VAR_2, VAR_3, VAR_4, VAR_5):...\n"", ""self.connection = mysql.connector.connect(host=connection_address, user=\n    user_name, VAR_4=password, db=database)\n"", ""self.cursor = self.connection.cursor(buffered=True)\n""]",0
"[""def FUNC_2(self):...\n"", ""VAR_0 = requests.get('http://127.0.0.1:5000/profiles')\n"", ""self.assertEqual(VAR_0.status_code, 200)\n"", ""self.assertIsNotNone(VAR_0.text)\n"", ""VAR_1 = json.loads(VAR_0.text)\n"", ""for user in VAR_1:\n"", ""if user['id'] != 191:\n"", ""VAR_3 = {'login': user['first_name'], 'password': user['first_name']}\n"", ""VAR_0 = requests.post('http://127.0.0.1:5000/login', json=data)\n"", ""print('/login login_user: {}'.format(VAR_0.text))\n"", ""self.assertEqual(VAR_0.status_code, 200)\n"", ""self.assertGreater(user['id'], 0)\n"", ""self.assertIsNotNone(VAR_0.text)\n"", ""VAR_3 = {'login': '', 'password': ''}\n"", ""VAR_0 = requests.post('http://127.0.0.1:5000/login', json=data)\n"", ""self.assertEqual(VAR_0.status_code, 200)\n"", ""self.assertGreater(user['id'], 0)\n"", ""self.assertIsNotNone(VAR_0.text)\n"", ""print('/login login_user: {}'.format(VAR_0.text))\n""]",0
"[""import re\n"", ""import subprocess\n"", ""import sqlite3\n"", ""VAR_0 = '/home/peter/projects/jdk/db/jdk_entries.db'\n"", ""VAR_1 = \""DATETIME(CURRENT_TIMESTAMP, 'localtime')\""\n"", ""VAR_2 = '/home/peter/projects/jdk/db/temp.jdk'\n"", ""def FUNC_0(VAR_3, VAR_4=False):...\n"", ""VAR_5 = sqlite3.connect(VAR_0)\n"", ""VAR_6 = VAR_5.cursor()\n"", ""VAR_6.execute(VAR_3)\n"", ""if VAR_4:\n"", ""VAR_17 = VAR_6.fetchall()\n"", ""VAR_17 = None\n"", ""VAR_5.close()\n"", ""VAR_5.commit()\n"", ""return VAR_17\n""]",0
"[""from flask import request, jsonify\n"", ""from flask_jwt_extended import create_access_token, create_refresh_token, set_access_cookies, set_refresh_cookies, jwt_refresh_token_required, get_jwt_identity\n"", ""from flask_restplus import Namespace, Resource\n"", ""from utilities import database_utilities\n"", ""VAR_0 = Namespace('login', description='Endpoint used to obtain JWT')\n"", ""def FUNC_0(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = request.get_json()\n"", ""if not VAR_1['email']:\n"", ""return jsonify({'msg': 'Missing email'}), 400\n"", ""VAR_2 = database_utilities.execute_query(\n    f\""select * from admins where email = '{VAR_1['email']}'\"")\n"", ""if VAR_2:\n"", ""VAR_6 = VAR_2[0]['email']\n"", ""return jsonify({'msg': 'User is not an admin'})\n"", ""VAR_4 = create_access_token(identity=email)\n"", ""VAR_7 = create_refresh_token(identity=email)\n"", ""VAR_5 = jsonify({'login': True})\n"", ""set_access_cookies(VAR_5, VAR_4)\n"", ""set_refresh_cookies(VAR_5, VAR_7)\n"", ""return VAR_5\n""]",1
"[""def FUNC_8(self):...\n"", ""VAR_15 = self.mock_nsx_clustered_api(retries=9)\n"", ""self.assertEqual(VAR_8.adapters['https://'].max_retries.total, 9)\n""]",0
"[""def __init__(self, VAR_10, VAR_11):...\n"", ""self.__class__.count += 1\n"", ""self.__class__.todo.append(self)\n"", ""from beamr.interpreters import Config\n"", ""VAR_21 = ''\n"", ""VAR_22 = self.__class__.count\n"", ""while VAR_22:\n"", ""VAR_21 += chr(64 + VAR_22 % 27)\n"", ""self.insertCmd = VAR_31.get('vbtmCmds', 'insertion')(VAR_21)\n"", ""VAR_22 //= 27\n"", ""self.head = VAR_10\n"", ""self.body = VAR_11\n"", ""super(CLASS_10, self).__init__(self.insertCmd)\n""]",1
"[""def FUNC_2(self):...\n"", ""VAR_6 = mock.Mock()\n"", ""VAR_6.nsxlib_config = mock.Mock()\n"", ""VAR_6.nsxlib_config.username = 'nsxuser'\n"", ""VAR_6.nsxlib_config.password = 'nsxpassword'\n"", ""VAR_6.nsxlib_config.retries = 100\n"", ""VAR_6.nsxlib_config.insecure = True\n"", ""VAR_6.nsxlib_config.ca_file = None\n"", ""VAR_6.nsxlib_config.http_timeout = 99\n"", ""VAR_6.nsxlib_config.conn_idle_timeout = 39\n"", ""VAR_6.nsxlib_config.client_cert_provider = None\n"", ""VAR_7 = cluster.NSXRequestsHTTPProvider()\n"", ""VAR_8 = VAR_7.new_connection(VAR_6, cluster.Provider('9.8.7.6',\n    'https://9.8.7.6', 'nsxuser', 'nsxpassword', None))\n"", ""self.assertEqual(('nsxuser', 'nsxpassword'), VAR_8.auth)\n"", ""self.assertFalse(VAR_8.verify)\n"", ""self.assertIsNone(VAR_8.cert)\n"", ""self.assertEqual(100, VAR_8.adapters['https://'].max_retries.total)\n"", ""self.assertEqual(99, VAR_8.timeout)\n""]",1
"[""def FUNC_9(self, VAR_5, VAR_6=None):...\n"", ""VAR_15 = CLASS_1(VAR_6=error_msg, VAR_7=self._disclaimer_banner)\n"", ""return renderElement(VAR_5, VAR_15)\n""]",0
"[""@VAR_2.route('/')...\n"", ""if VAR_0 == None:\n"", ""FUNC_16()\n"", ""VAR_5 = request.args.get('tag', default='christmasmike')\n"", ""VAR_7 = get_web(VAR_0=db)\n"", ""return render_template('libraries/html/web.html', VAR_7=data, VAR_5=tag)\n""]",0
"[""def FUNC_3(VAR_2, VAR_0, VAR_1):...\n"", ""current_app.logger.info('Reauthenticating user {!r} for {!r}.'.format(VAR_1,\n    VAR_2))\n"", ""VAR_3['_saml2_session_name_id'] = code(VAR_0['name_id'])\n"", ""VAR_3[VAR_2] = int(time())\n"", ""VAR_3.persist()\n"", ""VAR_5 = request.form.get('RelayState', '/')\n"", ""current_app.logger.debug('Redirecting to the RelayState: ' + VAR_5)\n"", ""return redirect(location=relay_state)\n""]",0
"[""@frappe.whitelist()...\n"", ""\""\""\""docstring\""\""\""\n"", ""FUNC_3()\n"", ""VAR_1 = 1\n"", ""VAR_12 = FUNC_2(VAR_1)\n"", ""VAR_13 = int(VAR_12['ActiveList']['PaginationResult']['TotalNumberOfPages'])\n"", ""while VAR_13 >= VAR_1:\n"", ""for item in VAR_12['ActiveList']['ItemArray']['Item']:\n"", ""VAR_3 = item['ItemID']\n"", ""VAR_1 += 1\n"", ""VAR_4 = int(item['QuantityAvailable'])\n"", ""if VAR_13 >= VAR_1:\n"", ""VAR_2 = item['SKU']\n"", ""VAR_2 = ''\n"", ""VAR_20 = float(item['SellingStatus']['CurrentPrice']['value'])\n"", ""VAR_12 = FUNC_2(VAR_1)\n"", ""VAR_21 = VAR_20 / ugssettings.VAT\n"", ""VAR_22 = 0\n"", ""VAR_23 = 0\n"", ""VAR_24 = 0\n"", ""VAR_6 = ''\n"", ""FUNC_4(VAR_2, VAR_3, VAR_4, VAR_20, VAR_6, VAR_22, VAR_23, VAR_24)\n""]",1
"[""def FUNC_15(self, VAR_14):...\n"", ""VAR_23 = '*'\n"", ""VAR_24 = ''\n"", ""if VAR_14._joins:\n"", ""for VAR_41 in VAR_14._joins:\n"", ""VAR_22 = ''\n"", ""VAR_33 = VAR_41.joint_type\n"", ""if VAR_14._where:\n"", ""if VAR_33 == self.JOIN:\n"", ""VAR_27 = 0\n"", ""VAR_25 = ';'\n"", ""VAR_33 = self.JOIN\n"", ""VAR_33 = self.LEFT_JOIN\n"", ""if isinstance(VAR_14._where, VAR_39):\n"", ""if VAR_14._delete:\n"", ""if VAR_41.dest in VAR_41.src._meta.rel_class and VAR_41.src.isForeignKey(VAR_41\n"", ""VAR_22 = 'WHERE {0}'.format(VAR_14._where)\n"", ""VAR_22 = VAR_14._where.parse()\n"", ""VAR_29 = 'DELETE'\n"", ""VAR_29 = 'SELECT {0}'.format(','.join(VAR_23))\n"", ""VAR_36 = '%s.%s' % (VAR_41.src._meta.table_name, VAR_41.src._meta.rel_class\n    [VAR_41.dest].name)\n"", ""if VAR_41.src in VAR_41.dest._meta.rel_class and VAR_41.dest.isForeignKey(\n"", ""VAR_22 = 'WHERE {0}'.format(VAR_22)\n"", ""if VAR_14.model_class._meta.primary_key:\n"", ""VAR_7 = '{0} FROM {1} {2} {3}{4}'.format(VAR_29, VAR_14.model_class._meta.\n    table_name, VAR_24, VAR_22, VAR_25)\n"", ""VAR_37 = '%s.%s' % (VAR_41.dest._meta.table_name, VAR_41.src._meta.\n    rel_class[VAR_41.dest].reference.name)\n"", ""VAR_36 = '%s.%s' % (VAR_41.src._meta.table_name, VAR_41.dest._meta.\n    rel_class[VAR_41.src].reference.name)\n"", ""VAR_24 += '%s %s on (%s = %s) ' % (VAR_33, VAR_41.dest._meta.table_name,\n    VAR_36, VAR_37)\n"", ""VAR_25 = ' RETURNING id;'\n"", ""return VAR_7\n"", ""VAR_37 = '%s.%s' % (VAR_41.dest._meta.table_name, VAR_41.dest._meta.\n    rel_class[VAR_41.src].name)\n""]",0
"[""def FUNC_4(self):...\n"", ""VAR_1 = self.c.get('/find/?q=terro')\n"", ""self.assertNotContains(VAR_1, '<table')\n"", ""self.assertContains(VAR_1, '<div class=\""results-wrapper\"">')\n""]",0
"[""from openerp import api, fields, models\n"", ""VAR_0 = 'crm.lead'\n"", ""VAR_1 = fields.One2many(comodel_name='crm.phonecall', inverse_name=\n    'opportunity_id', string='Phonecalls')\n"", ""VAR_2 = fields.Integer(compute='_phonecall_count', string='Phonecalls')\n"", ""@api.multi...\n"", ""for lead in self:\n"", ""lead.phonecall_count = self.env['crm.phonecall'].search_count([(\n    'opportunity_id', '=', lead.id)])\n""]",1
"[""import collections\n"", ""import os\n"", ""import pymongo\n"", ""from django.http import Http404\n"", ""from cuckoo.core.database import Database, TASK_PENDING\n"", ""from cuckoo.common.mongo import mongo\n"", ""VAR_0 = Database()\n"", ""@staticmethod...\n"", ""if not isinstance(VAR_1, int):\n"", ""VAR_9 = {}\n"", ""VAR_10 = VAR_0.view_task(VAR_1, details=True)\n"", ""if VAR_10:\n"", ""VAR_19 = VAR_10.to_dict()\n"", ""return Exception('Task not found')\n"", ""VAR_19['guest'] = {}\n"", ""if VAR_10.guest:\n"", ""VAR_19['guest'] = VAR_10.guest.to_dict()\n"", ""VAR_19['errors'] = []\n"", ""for error in VAR_10.errors:\n"", ""VAR_19['errors'].append(error.message)\n"", ""VAR_19['sample'] = {}\n"", ""if VAR_10.sample_id:\n"", ""VAR_26 = VAR_0.view_sample(VAR_10.sample_id)\n"", ""VAR_9['task'] = VAR_19\n"", ""VAR_19['sample'] = VAR_26.to_dict()\n"", ""return VAR_9\n""]",1
"[""def __str__(self):...\n"", ""return self.name\n""]",0
"[""def FUNC_25(VAR_21):...\n"", ""return [VAR_15._select_endpoint() for i in range(VAR_21)]\n""]",0
"[""def FUNC_2(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_4 = '/api/apps'\n"", ""VAR_5 = self.client.post(VAR_4)\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""VAR_6 = VAR_5.data['id']\n"", ""VAR_7 = {'sha': 'df1e628f2244b73f9cdf944f880a2b3470a122f4', 'fingerprint':\n    '88:25:ed:67:56:91:3d:c6:1b:7f:42:c6:9b:41:24:80', 'receive_user':\n    'autotest', 'receive_repo': '{app_id}'.format(**locals()),\n    'ssh_connection': '10.0.1.10 50337 172.17.0.143 22',\n    'ssh_original_command': \""git-receive-pack '{app_id}.git'\"".format(**\n    locals())}\n"", ""VAR_4 = '/api/hooks/push'.format(**locals())\n"", ""VAR_5 = self.client.post(VAR_4, json.dumps(VAR_7), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_5.status_code, 403)\n"", ""VAR_5 = self.client.post(VAR_4, json.dumps(VAR_7), content_type=\n    'application/json', HTTP_X_DEIS_BUILDER_AUTH=settings.BUILDER_KEY)\n"", ""self.assertEqual(VAR_5.status_code, 201)\n"", ""for k in ('owner', 'app', 'sha', 'fingerprint', 'receive_repo',\n"", ""self.assertIn(k, VAR_5.data)\n""]",1
"[""def __new__(VAR_3):...\n"", ""if CLASS_0.instance is None:\n"", ""CLASS_0.instance = object.__new__(VAR_3)\n"", ""return CLASS_0.instance\n""]",0
"[""def FUNC_3(self, VAR_1, VAR_3, VAR_4):...\n"", ""if VAR_3['power'] > 0:\n"", ""VAR_17 = VAR_3['source']['serial_id']\n"", ""VAR_20 = 'string' % (VAR_1, VAR_17, VAR_3['power'], VAR_4 + VAR_3['energy'])\n"", ""self.c.execute(VAR_20)\n""]",1
"[""def FUNC_8(self, VAR_10=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_10:\n"", ""VAR_25 = Win.objects.inactive()\n"", ""VAR_25 = Win.objects.all()\n"", ""if VAR_10:\n"", ""VAR_25 = VAR_25.exclude(user__email__in=settings.IGNORE_USERS)\n"", ""VAR_25 = VAR_25.values()\n"", ""for VAR_5 in VAR_25:\n"", ""yield self._get_win_data(VAR_5)\n""]",0
"[""def FUNC_10(VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return block.path_to_kname(VAR_1).startswith('dm') and FUNC_1(VAR_1\n    ).startswith('LVM')\n""]",0
"[""def FUNC_0(self):...\n"", ""if 'submitter' in self.request.arguments:\n"", ""return list(map(to_unicode, self.request.arguments['submitter']))\n""]",0
"[""def FUNC_24(VAR_10, VAR_3):...\n"", ""VAR_6 = FUNC_21()\n"", ""VAR_28 = VAR_6, VAR_3\n"", ""VAR_18 = 'INSERT INTO {} VALUES (?, ?)'.format(CFG('admintoken_table_name'))\n"", ""VAR_10.execute(VAR_18, VAR_28)\n""]",0
"[""def FUNC_16(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7, VAR_12 = self.make_xsrf_handling_app(VAR_2=('PUT',))\n"", ""VAR_17 = VAR_7.get('/request').body\n"", ""VAR_7.post('/request', {'xsrf_token': VAR_17})\n"", ""VAR_7.put('/request', {'xsrf_token': VAR_17})\n"", ""self.assertEqual([('POST', True), ('PUT', True)], VAR_12)\n"", ""self.assertEqual(200, VAR_7.post('/request').status_int)\n"", ""self.assertEqual(403, VAR_7.put('/request', expect_errors=True).status_int)\n"", ""VAR_18 = {'xsrf_token': 'boo'}\n"", ""self.assertEqual(403, VAR_7.post('/request', VAR_18, expect_errors=True).\n    status_int)\n"", ""self.assertEqual(403, VAR_7.put('/request', VAR_18, expect_errors=True).\n    status_int)\n""]",1
"[""def FUNC_12(self):...\n"", ""VAR_20 = open(VAR_2, 'r')\n"", ""VAR_22 = VAR_20.read()\n"", ""VAR_20.close()\n"", ""return VAR_22\n""]",0
"[""\""\""\""string\""\""\""\n"", ""import mimetypes\n"", ""import os\n"", ""import posixpath\n"", ""import re\n"", ""import stat\n"", ""from django.http import FileResponse, Http404, HttpResponse, HttpResponseNotModified, HttpResponseRedirect\n"", ""from django.template import Context, Engine, TemplateDoesNotExist, loader\n"", ""from django.utils.http import http_date, parse_http_date\n"", ""from django.utils.translation import gettext as _, gettext_lazy\n"", ""def FUNC_0(VAR_0, VAR_1, VAR_2=None, VAR_3=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = posixpath.normpath(VAR_1)\n"", ""VAR_1 = VAR_1.lstrip('/')\n"", ""VAR_10 = ''\n"", ""for VAR_18 in VAR_1.split('/'):\n"", ""if not VAR_18:\n"", ""if VAR_10 and VAR_1 != VAR_10:\n"", ""VAR_17, VAR_18 = os.path.splitdrive(VAR_18)\n"", ""return HttpResponseRedirect(VAR_10)\n"", ""VAR_6 = os.path.join(VAR_2, VAR_10)\n"", ""VAR_19, VAR_18 = os.path.split(VAR_18)\n"", ""if os.path.isdir(VAR_6):\n"", ""if VAR_18 in (os.curdir, os.pardir):\n"", ""if VAR_3:\n"", ""if not os.path.exists(VAR_6):\n"", ""VAR_10 = os.path.join(VAR_10, VAR_18).replace('\\\\', '/')\n"", ""return FUNC_1(VAR_10, VAR_6)\n"", ""VAR_11 = os.stat(VAR_6)\n"", ""if not FUNC_2(VAR_0.META.get('HTTP_IF_MODIFIED_SINCE'), VAR_11.st_mtime,\n"", ""return HttpResponseNotModified()\n"", ""VAR_12, VAR_13 = mimetypes.guess_type(VAR_6)\n"", ""VAR_12 = VAR_12 or 'application/octet-stream'\n"", ""VAR_14 = FileResponse(open(VAR_6, 'rb'), VAR_12=content_type)\n"", ""VAR_14['Last-Modified'] = http_date(VAR_11.st_mtime)\n"", ""if stat.S_ISREG(VAR_11.st_mode):\n"", ""VAR_14['Content-Length'] = VAR_11.st_size\n"", ""if VAR_13:\n"", ""VAR_14['Content-Encoding'] = VAR_13\n"", ""return VAR_14\n""]",1
"[""def FUNC_4(self, VAR_5):...\n"", ""for oldg in VAR_5.get_ancestors():\n"", ""if oldg not in self.groups:\n"", ""if VAR_5 not in self.groups:\n"", ""self.add_group(oldg)\n"", ""self.groups.append(VAR_5)\n""]",1
"[""def FUNC_1(self, VAR_5, VAR_6):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_5 not in ('strings', 'files'):\n"", ""VAR_0.error(\""Bad parameter '%s' for submit_type\"", VAR_5)\n"", ""VAR_13 = Folders.create_temp()\n"", ""return False\n"", ""VAR_14 = {'data': [], 'errors': []}\n"", ""if VAR_5 == 'strings':\n"", ""for VAR_4 in VAR_6:\n"", ""if VAR_5 == 'files':\n"", ""self._handle_string(VAR_14, VAR_13, VAR_4)\n"", ""for entry in VAR_6:\n"", ""return Database().add_submit(VAR_13, VAR_5, VAR_14)\n"", ""VAR_22 = Storage.get_filename_from_path(entry['name'])\n"", ""VAR_18 = Files.create(VAR_13, VAR_22, entry['data'])\n"", ""VAR_14['data'].append({'type': 'file', 'data': VAR_18})\n""]",1
"[""def FUNC_9(self):...\n"", ""self._hosts_cache = None\n"", ""for VAR_12 in self.parent_groups:\n"", ""VAR_12.clear_hosts_cache()\n""]",1
"[""@classmethod...\n"", ""return VAR_4._create_jardep('scala-library', VAR_6)\n""]",1
"[""def FUNC_4(self, VAR_9):...\n"", ""self.cursor.execute(\n    \""SELECT upc, name, weight, description FROM product WHERE name ILIKE '%%%s%%';\""\n    , (VAR_9,))\n"", ""return self.cursor.fetchall()\n""]",1
"[""def FUNC_6(self, VAR_9, VAR_10=[]):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_20 = []\n"", ""VAR_21 = 'https://www.kijiji.ca/p-upload-image.html'\n"", ""for img_file in VAR_10:\n"", ""for i in range(0, 3):\n"", ""return [image for image in VAR_20 if image is not None]\n"", ""VAR_32 = {'file': img_file}\n"", ""VAR_33 = self.session.post(VAR_21, VAR_32=files, headers={\n    'x-ebay-box-token': token})\n"", ""if VAR_33.status_code != 200:\n"", ""print(VAR_33.status_code)\n"", ""VAR_34 = json.loads(VAR_33.text)\n"", ""print('Image Upload failed on try #{}'.format(i + 1))\n"", ""VAR_35 = VAR_34['thumbnailUrl']\n"", ""print('Image Upload success on try #{}'.format(i + 1))\n"", ""VAR_20.append(VAR_35)\n""]",1
"[""def __init__(self, VAR_15):...\n"", ""self._store = []\n"", ""self._ds = VAR_15\n""]",0
"[""def FUNC_23(self):...\n"", ""VAR_14 = self.new_mocked_client(client.NSX3Client)\n"", ""VAR_14.delete('ports/11')\n"", ""FUNC_2('delete', VAR_14, 'https://1.2.3.4/api/v1/ports/11')\n""]",0
"[""def FUNC_2():...\n"", ""\""\""\""docstring\""\""\""\n"", ""return [onboarding.STEP_1, onboarding.STEP_2, onboarding.STEP_3, onboarding\n    .STEP_4, onboarding.STEP_5, onboarding.STEP_6, onboarding.STEP_7,\n    onboarding.STEP_8]\n""]",1
"[""def FUNC_3(self):...\n"", ""VAR_14 = self.new_mocked_client(client.RESTClient, url_prefix='/cloud/api')\n"", ""VAR_14.list()\n"", ""FUNC_1('get', VAR_14, 'https://1.2.3.4/cloud/api')\n"", ""VAR_14 = self.new_mocked_client(client.RESTClient, url_prefix='/cloud/api')\n"", ""VAR_14.url_list('v1/ports')\n"", ""FUNC_1('get', VAR_14, 'https://1.2.3.4/cloud/api/v1/ports')\n""]",0
"[""def FUNC_4(self, VAR_6, VAR_7):...\n"", """"]",0
"[""def FUNC_5(self):...\n"", ""if self.get_qa_status():\n"", ""return 'QA Complete'\n"", ""if self.qa_begun:\n"", ""return 'Continue QA'\n"", ""return 'Begin QA'\n""]",0
"[""@property...\n"", ""\""\""\""docstring\""\""\""\n"", ""return self._version\n""]",0
"[""@VAR_2.route('/h2h')...\n"", ""if VAR_0 == None:\n"", ""FUNC_16()\n"", ""VAR_28 = request.args.get('tag1', default='christmasmike')\n"", ""VAR_29 = request.args.get('tag2', default='christmasmike')\n"", ""VAR_8 = \""SELECT * FROM matches WHERE (player1 = '\"" + str(VAR_28\n    ) + \""' OR \"" + \""player2 = '\"" + str(VAR_28) + \""') AND (player1 = '\"" + str(\n    VAR_29) + \""' OR \"" + \""player2 = '\"" + str(VAR_29) + \""') ORDER BY date DESC;\""\n"", ""VAR_27 = VAR_0.exec(VAR_8)\n"", ""return json.dumps(VAR_27)\n""]",1
"[""@gen.coroutine...\n"", ""VAR_8 = {}\n"", ""VAR_8['host'] = self.dbhost\n"", ""VAR_8['user'] = self.dbuser\n"", ""VAR_8['password'] = self.dbpassword\n"", ""VAR_8['db'] = self.dbname\n"", ""VAR_8['charset'] = 'utf8mb4'\n"", ""VAR_8['cursorclass'] = pymysql.cursors.Cursor\n"", ""VAR_9 = 'SELECT user_pass FROM {0}users WHERE user_login = \""{1}\""'.format(self\n    .table_prefix, VAR_7['username'])\n"", ""if cursor.execute(VAR_9) == 0:\n"", ""return None\n"", ""if phpass.verify(VAR_7['password'], cursor.fetchone()[0]) == True:\n"", ""return VAR_7['username']\n"", ""return None\n""]",1
"[""def FUNC_20(VAR_5):...\n"", ""VAR_8 = {'Authorization': 'token ' + os.environ['GITHUB_TOKEN']}\n"", ""VAR_9 = os.environ['BOT_USERNAME'], os.environ['BOT_PASSWORD']\n"", ""VAR_10 = 'https://api.github.com/repos/{}/pulls'\n"", ""VAR_10 = VAR_10.format(VAR_5['target_repo_fullname'])\n"", ""VAR_40 = {'title': 'Fix pep8 errors', 'head': 'pep8speaks:{}'.format(VAR_5[\n    'new_branch']), 'base': VAR_5['target_repo_branch'], 'body':\n    'The changes are suggested by autopep8'}\n"", ""VAR_11 = requests.post(VAR_10, json=request_json, VAR_8=headers, VAR_9=auth)\n"", ""if VAR_11.status_code == 201:\n"", ""VAR_5['pr_url'] = VAR_11.json()['html_url']\n"", ""VAR_5['error'] = 'Pull request could not be created'\n""]",0
"[""def FUNC_2(VAR_0):...\n"", ""def FUNC_3(VAR_1):...\n"", ""return int(VAR_1)\n"", ""return 0\n"", ""if VAR_0.method == 'POST':\n"", ""VAR_3 = FUNC_3(VAR_0.POST.get('points'))\n"", ""return render(VAR_0, 'exercises/ajax_exercise.html', {'url': VAR_0.\n    build_absolute_uri('{}?{}'.format(reverse('ajax'), VAR_0.META.get(\n    'QUERY_STRING', '')))})\n"", ""VAR_4 = FUNC_3(VAR_0.POST.get('max_points'))\n"", ""VAR_5 = VAR_0.GET.get('submission_url')\n"", ""def FUNC_4(VAR_6):...\n"", ""VAR_7 = HttpResponse(VAR_6)\n"", ""VAR_7['Access-Control-Allow-Origin'] = '*'\n"", ""return VAR_7\n""]",0
"[""def FUNC_6(self):...\n"", ""VAR_1 = '/api/apps'\n"", ""VAR_2 = self.client.post(VAR_1)\n"", ""self.assertEqual(VAR_2.status_code, 201)\n"", ""VAR_3 = VAR_2.data['id']\n"", ""VAR_1 = '/api/apps/{app_id}/builds'.format(**locals())\n"", ""VAR_4 = {'image': 'autotest/example', 'sha': 'a' * 40, 'procfile': json.\n    dumps({'web': 'node server.js', 'worker': 'node worker.js'})}\n"", ""VAR_2 = self.client.post(VAR_1, json.dumps(VAR_4), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_2.status_code, 201)\n"", ""VAR_1 = '/api/apps/{app_id}/releases'.format(**locals())\n"", ""VAR_2 = self.client.get(VAR_1)\n"", ""self.assertEqual(VAR_2.status_code, 200)\n"", ""self.assertEqual(len(VAR_2.data['results']), 2)\n"", ""VAR_1 = '/api/apps/{app_id}/containers'.format(**locals())\n"", ""VAR_2 = self.client.get(VAR_1)\n"", ""self.assertEqual(VAR_2.status_code, 200)\n"", ""self.assertEqual(len(VAR_2.data['results']), 1)\n"", ""VAR_1 = '/api/apps/{app_id}/scale'.format(**locals())\n"", ""VAR_4 = {'web': 20}\n"", ""VAR_2 = self.client.post(VAR_1, json.dumps(VAR_4), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_2.status_code, 204)\n"", ""chaos.CREATE_ERROR_RATE = 0.5\n"", ""chaos.START_ERROR_RATE = 0.5\n"", ""VAR_1 = '/api/apps/{app_id}/config'.format(**locals())\n"", ""VAR_4 = {'values': json.dumps({'NEW_URL1': 'http://localhost:8080/'})}\n"", ""VAR_2 = self.client.post(VAR_1, json.dumps(VAR_4), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_2.status_code, 503)\n"", ""VAR_1 = '/api/apps/{app_id}/releases'.format(**locals())\n"", ""VAR_2 = self.client.get(VAR_1)\n"", ""self.assertEqual(VAR_2.status_code, 200)\n"", ""self.assertEqual(len(VAR_2.data['results']), 2)\n"", ""VAR_1 = '/api/apps/{app_id}/containers'.format(**locals())\n"", ""VAR_2 = self.client.get(VAR_1)\n"", ""self.assertEqual(VAR_2.status_code, 200)\n"", ""self.assertEqual(len(VAR_2.data['results']), 20)\n"", ""VAR_5 = set([c['state'] for c in VAR_2.data['results']])\n"", ""self.assertEqual(VAR_5, set(['up']))\n""]",0
"[""def FUNC_4(VAR_12, VAR_16, VAR_17, VAR_18, VAR_19):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_16 = VAR_16.copy()\n"", ""if VAR_17 is not None:\n"", ""VAR_16['exit_code'] = VAR_17\n"", ""if VAR_18:\n"", ""VAR_16['output'] = base64.b64encode(VAR_18)\n"", ""VAR_35 = VAR_12.url_read_json('/swarming/api/v1/bot/task_update/%s' %\n    VAR_16['task_id'], VAR_31=params)\n"", ""VAR_16['output_chunk_start'] = VAR_19\n"", ""logging.debug('post_update() = %s', VAR_35)\n"", ""if VAR_35.get('error'):\n""]",1
"[""def FUNC_7(self, VAR_21, VAR_23=True):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_21 == '/':\n"", ""return self.fs\n"", ""VAR_55 = VAR_21.strip('/').split('/')\n"", ""VAR_22 = ''\n"", ""VAR_57 = self.fs\n"", ""for VAR_66 in VAR_55:\n"", ""if VAR_66 not in [x[VAR_1] for x in VAR_57[VAR_8]]:\n"", ""return VAR_57\n"", ""return False\n"", ""for x in VAR_57[VAR_8]:\n"", ""if x[VAR_1] == VAR_66:\n"", ""VAR_22 = '/'.join((VAR_22, VAR_66))\n"", ""if VAR_66 == VAR_55[-1] and VAR_23 == False:\n"", ""VAR_57 = x\n"", ""if x[VAR_2] == VAR_11:\n"", ""if x[VAR_9][0] == '/':\n"", ""VAR_57 = x\n"", ""VAR_57 = self.getfile(x[VAR_9], VAR_23=follow_symlinks)\n"", ""VAR_57 = self.getfile('/'.join((VAR_22, x[VAR_9])), VAR_23=follow_symlinks)\n"", ""if VAR_57 == False:\n"", ""return False\n""]",1
"[""@patch('invenio.ext.session.interface.SessionInterface.save_session')...\n"", ""from invenio.modules.oauthclient.models import RemoteToken\n"", ""from invenio.modules.oauthclient.handlers import token_getter\n"", ""from invenio.modules.oauthclient.client import oauth\n"", ""VAR_9 = MagicMock()\n"", ""VAR_9.get_id = MagicMock(return_value=1)\n"", ""VAR_9.is_authenticated = MagicMock(return_value=True)\n"", ""VAR_10 = c.get(url_for('oauthclient.login', remote_app='full'))\n"", ""assert VAR_10.status_code == 302\n"", ""assert VAR_10.location.startswith(oauth.remote_apps['full'].authorize_url)\n"", ""self.mock_response(VAR_5='full')\n"", ""c.get(url_for('oauthclient.authorized', remote_app='full', code='test'))\n"", ""assert session['oauth_token_full'] == ('test_access_token', '')\n"", ""VAR_11 = RemoteToken.get(1, 'fullid')\n"", ""assert VAR_11.remote_account.client_id == 'fullid'\n"", ""assert VAR_11.access_token == 'test_access_token'\n"", ""assert RemoteToken.query.count() == 1\n"", ""self.mock_response(VAR_5='full', VAR_6={'access_token': 'new_access_token',\n    'scope': '', 'token_type': 'bearer'})\n"", ""c.get(url_for('oauthclient.authorized', remote_app='full', code='test'))\n"", ""VAR_11 = RemoteToken.get(1, 'fullid')\n"", ""assert VAR_11.access_token == 'new_access_token'\n"", ""assert RemoteToken.query.count() == 1\n"", ""VAR_12 = token_getter(oauth.remote_apps['full'])\n"", ""assert VAR_12 == ('new_access_token', '')\n"", ""VAR_10 = c.get(url_for('oauthclient.disconnect', remote_app='full'))\n"", ""assert VAR_10.status_code == 302\n"", ""assert VAR_10.location.endswith(url_for('oauthclient_settings.index'))\n"", ""VAR_11 = RemoteToken.get(1, 'fullid')\n"", ""assert VAR_11 is None\n""]",1
"[""def FUNC_20(self):...\n"", ""if self.child:\n"", ""return False\n"", ""return True\n""]",0
"[""from flask import redirect, make_response\n"", ""from random import randint\n"", ""import redis\n"", ""import uuid\n"", ""import time\n"", ""def FUNC_0():...\n"", ""VAR_1 = redis.Redis(host='127.0.0.1', port=6379, db=0)\n"", ""return VAR_1\n""]",1
"[""def FUNC_9(self, VAR_9):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_8 = VAR_9.args.get('csessid')[0]\n"", ""self.last_alive[VAR_8] = time.time(), False\n"", ""VAR_20 = self.sessionhandler.sessions_from_csessid(VAR_8)\n"", ""if VAR_20:\n"", ""VAR_20 = VAR_20[0]\n"", ""return '\""\""'\n"", ""VAR_36 = json.loads(VAR_9.args.get('data')[0])\n"", ""VAR_20.sessionhandler.data_in(VAR_20, **{cmdarray[0]: [cmdarray[1],\n    cmdarray[2]]})\n""]",1
"[""def FUNC_10(self, VAR_11, VAR_12=NoDefault):...\n"", ""if VAR_11 == 'SQLConnectionPoolSize':\n"", ""return 0\n"", ""return SQLObjectStore.setting(self, VAR_11, VAR_12)\n""]",0
"[""def FUNC_15(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_21 = [VAR_28 for VAR_28 in self.expanded_output if VAR_28.exists]\n"", ""if VAR_21:\n"", ""logger.info(\n    \""\""\""Removing output files of failed job {} since they might be corrupted:\n{}\""\""\""\n    .format(self, ', '.join(VAR_21)))\n"", ""for VAR_28 in VAR_21:\n"", ""VAR_28.remove()\n""]",0
"[""def __init__(self, VAR_8):...\n"", ""self.entries = []\n"", ""self.filename = VAR_8\n"", ""VAR_36 = theFile.read()\n"", ""return None\n"", ""VAR_15 = False\n"", ""theFile.close()\n"", ""VAR_16 = VAR_36.split(VAR_4())[-1]\n"", ""VAR_17 = VAR_16.split('\\n')\n"", ""VAR_18 = 'string'\n"", ""for VAR_44 in VAR_17:\n"", ""if VAR_44.strip() == '':\n"", ""if VAR_15 == False:\n"", ""VAR_35 = re.search(VAR_18, VAR_44)\n"", ""VAR_36 = VAR_36.strip()\n"", ""if VAR_35:\n"", ""VAR_37 = VAR_36.split('\\n')[0]\n"", ""VAR_43 = VAR_35.group(0)\n"", ""VAR_45 = None\n"", ""VAR_38 = VAR_36[:150]\n"", ""VAR_44 = VAR_44.replace(VAR_43, '').strip()\n"", ""if ':' in VAR_44:\n"", ""VAR_38 = VAR_38.split('------------')[0]\n"", ""VAR_45 = datetime.datetime.strptime(VAR_43, '<%a., %b. %d, %Y, %I:%M %p>')\n"", ""VAR_46 = VAR_44.split(':')[0]\n"", ""VAR_46 = '(no_key)'\n"", ""self.entries.append(CLASS_0('title', VAR_37, None))\n"", ""VAR_6 = ''.join(VAR_44.split(':')[1:]).strip()\n"", ""VAR_6 = VAR_44\n"", ""if '|' in VAR_6:\n"", ""if VAR_46 == 'title':\n"", ""VAR_51 = VAR_6.split('|')\n"", ""VAR_15 = True\n"", ""self.entries.append(CLASS_0(VAR_46, VAR_6, VAR_45))\n"", ""VAR_6 = []\n"", ""VAR_37 = VAR_6\n"", ""for VAR_52 in VAR_51:\n"", ""VAR_6.append(VAR_52.strip())\n""]",1
"[""def FUNC_29(self, VAR_21):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return self.stat(VAR_21, VAR_23=False)\n""]",0
"[""def FUNC_3(self, VAR_3, VAR_4):...\n"", ""VAR_8 = self.get_all_members()\n"", ""VAR_9 = [x for x in VAR_8 if x.name == VAR_3 and x.discriminator == VAR_4][0]\n"", ""return VAR_9\n""]",0
"[""from modules.database import sql_execute\n"", ""def FUNC_0(VAR_0):...\n"", ""VAR_6 = (\""\""\""INSERT INTO dialogs (name, created_at)\nVALUES ('%s', NOW())\""\""\"" %\n    VAR_0)\n"", ""return {'status': 1}\n""]",1
"[""@VAR_8.command()...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_2 is None:\n"", ""for x in VAR_13:\n"", ""if VAR_9.channel.id in VAR_2:\n"", ""print('!roll command recieved in channel ID ' + str(VAR_9.channel.id))\n"", ""for x in VAR_13:\n"", ""await VAR_9.send(vroll.roll(x))\n"", ""print('!roll command recieved in channel ID ' + str(VAR_9.channel.id) +\n    ' by user ' + str(VAR_9.author))\n"", ""await VAR_9.send(vroll.roll(x))\n""]",0
"[""def FUNC_3(self, VAR_1, VAR_2, VAR_5, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_4 is None:\n"", ""VAR_4 = {}\n"", ""VAR_30 = VAR_4.get('states', [])\n"", ""VAR_31 = VAR_4.get('what', ())\n"", ""if not VAR_5:\n"", ""VAR_5 = self.search(VAR_1, VAR_2, [])\n"", ""VAR_29 = {}.fromkeys(VAR_5, 0.0)\n"", ""if not VAR_5:\n"", ""return VAR_29\n"", ""if VAR_4.get('shop', False):\n"", ""VAR_1.execute('select warehouse_id from sale_shop where id=%s', (int(VAR_4[\n    'shop']),))\n"", ""if VAR_4.get('warehouse', False):\n"", ""VAR_41 = VAR_1.fetchone()\n"", ""VAR_1.execute('select lot_stock_id from stock_warehouse where id=%s', (int(\n    VAR_4['warehouse']),))\n"", ""if VAR_4.get('location', False):\n"", ""if VAR_41:\n"", ""VAR_41 = VAR_1.fetchone()\n"", ""if type(VAR_4['location']) == type(1):\n"", ""VAR_42 = []\n"", ""VAR_4['warehouse'] = VAR_41[0]\n"", ""if VAR_41:\n"", ""VAR_42 = [VAR_4['location']]\n"", ""if type(VAR_4['location']) in (type(''), type(u'')):\n"", ""VAR_43 = self.pool.get('stock.warehouse').search(VAR_1, VAR_2, [], VAR_4=\n    context)\n"", ""VAR_4['location'] = VAR_41[0]\n"", ""if VAR_4.get('compute_child', True):\n"", ""VAR_42 = self.pool.get('stock.location').search(VAR_1, VAR_2, [('name',\n    'ilike', VAR_4['location'])], VAR_4=context)\n"", ""VAR_42 = VAR_4['location']\n"", ""for w in self.pool.get('stock.warehouse').browse(VAR_1, VAR_2, VAR_43,\n"", ""VAR_44 = self.pool.get('stock.location').search(VAR_1, VAR_2, [(\n    'location_id', 'child_of', VAR_42)])\n"", ""VAR_42 = VAR_42\n"", ""VAR_42.append(w.lot_stock_id.id)\n"", ""VAR_42 = VAR_44 or VAR_42\n"", ""VAR_32 = {}\n"", ""VAR_33 = {}\n"", ""for VAR_45 in self.browse(VAR_1, VAR_2, VAR_5, VAR_4=context):\n"", ""VAR_33[VAR_45.id] = VAR_45.uom_id.id\n"", ""VAR_34 = []\n"", ""VAR_32[VAR_45.uom_id.id] = VAR_45.uom_id\n"", ""VAR_35 = []\n"", ""VAR_36 = VAR_4.get('from_date', False)\n"", ""VAR_37 = VAR_4.get('to_date', False)\n"", ""VAR_38 = False\n"", ""if VAR_36 and VAR_37:\n"", ""VAR_38 = \""date_planned>='%s' and date_planned<='%s'\"" % (VAR_36, VAR_37)\n"", ""if VAR_36:\n"", ""if 'in' in VAR_31:\n"", ""VAR_38 = \""date_planned>='%s'\"" % VAR_36\n"", ""if VAR_37:\n"", ""VAR_1.execute('string' + (VAR_38 and 'and ' + VAR_38 + ' ' or '') +\n    'group by product_id,product_uom', (tuple(VAR_42), tuple(VAR_42), tuple\n    (VAR_5), tuple(VAR_30)))\n"", ""if 'out' in VAR_31:\n"", ""VAR_38 = \""date_planned<='%s'\"" % VAR_37\n"", ""VAR_34 = VAR_1.fetchall()\n"", ""VAR_1.execute('string' + (VAR_38 and 'and ' + VAR_38 + ' ' or '') +\n    'group by product_id,product_uom', (tuple(VAR_42), tuple(VAR_42), tuple\n    (VAR_5), tuple(VAR_30)))\n"", ""VAR_39 = self.pool.get('product.uom')\n"", ""VAR_35 = VAR_1.fetchall()\n"", ""VAR_40 = map(lambda x: x[2], VAR_34) + map(lambda x: x[2], VAR_35)\n"", ""if VAR_4.get('uom', False):\n"", ""VAR_40 += [VAR_4['uom']]\n"", ""VAR_40 = filter(lambda x: x not in VAR_32.keys(), VAR_40)\n"", ""if VAR_40:\n"", ""VAR_40 = VAR_39.browse(VAR_1, VAR_2, list(set(VAR_40)), VAR_4=context)\n"", ""for VAR_46 in VAR_40:\n"", ""VAR_32[VAR_46.id] = VAR_46\n"", ""for VAR_47, prod_id, prod_uom in VAR_34:\n"", ""VAR_47 = VAR_39._compute_qty_obj(VAR_1, VAR_2, VAR_32[prod_uom], VAR_47,\n    VAR_32[VAR_4.get('uom', False) or VAR_33[prod_id]])\n"", ""for VAR_47, prod_id, prod_uom in VAR_35:\n"", ""VAR_29[prod_id] += VAR_47\n"", ""VAR_47 = VAR_39._compute_qty_obj(VAR_1, VAR_2, VAR_32[prod_uom], VAR_47,\n    VAR_32[VAR_4.get('uom', False) or VAR_33[prod_id]])\n"", ""return VAR_29\n"", ""VAR_29[prod_id] -= VAR_47\n""]",1
"[""@property...\n"", ""\""\""\""docstring\""\""\""\n"", ""for VAR_28, VAR_27 in zip(self.output, self.rule.output):\n"", ""if VAR_28 in self.dynamic_output:\n"", ""VAR_29 = self.expand_dynamic(VAR_27, VAR_13=self.wildcards, VAR_14=_IOFile.\n    dynamic_fill)\n"", ""yield VAR_28\n"", ""if not VAR_29:\n"", ""yield VAR_27\n"", ""for VAR_28, _ in VAR_29:\n"", ""yield IOFile(VAR_28, self.rule)\n""]",1
"[""def FUNC_0(VAR_0, VAR_1, VAR_2):...\n"", ""VAR_4 = VAR_0.cursor()\n"", ""VAR_5 = 'ALTER TABLE Presets DROP COLUMN id;'\n"", ""VAR_4.execute(VAR_5)\n"", ""VAR_5 = (\n    'ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;'\n    )\n"", ""VAR_4.execute(VAR_5)\n"", ""VAR_6 = Table('Presets')\n"", ""VAR_7 = MySQLQuery.into(VAR_6).columns('querval', 'description').insert(VAR_1,\n    VAR_2)\n"", ""print(VAR_7)\n"", ""VAR_5 = str(VAR_7)\n"", ""VAR_4.execute(VAR_5)\n"", ""VAR_5 = 'ALTER TABLE Presets DROP COLUMN id;'\n"", ""VAR_4.execute(VAR_5)\n"", ""VAR_5 = (\n    'ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;'\n    )\n"", ""VAR_4.execute(VAR_5)\n""]",1
"[""def FUNC_21(self, VAR_14):...\n"", """"]",0
"[""@wraps(VAR_7)...\n"", ""if VAR_12:\n"", ""return VAR_7(VAR_8[0], VAR_1, *VAR_8[1:], **kwargs)\n"", ""return VAR_7(VAR_1, *VAR_8, **kwargs)\n""]",0
"[""def FUNC_0(self, VAR_3):...\n"", ""VAR_5 = '%s bool' % str(VAR_3)\n"", ""return VAR_5\n""]",0
"[""def FUNC_16():...\n"", ""VAR_19.join(timeout=self._connecttimeout)\n"", ""if VAR_19.is_alive():\n"", ""warnings.warn('timed out waiting for connection')\n"", ""if self._session is None:\n"", ""VAR_22 = 'unable to connect after {} secs'.format(self._connecttimeout)\n"", ""if self._run_server_ex is None:\n"", ""VAR_22 = VAR_22 + os.linesep + self._run_server_ex\n""]",0
"[""def FUNC_6(VAR_7):...\n"", ""@wraps(VAR_7)...\n"", ""if not app.config.get('USE_AUTH'):\n"", ""return VAR_7(*VAR_9, **kwargs)\n"", ""if g.auth_type == 'kms':\n"", ""return VAR_7(*VAR_9, **kwargs)\n"", ""if VAR_1.check_csrf_token():\n"", ""return VAR_7(*VAR_9, **kwargs)\n"", ""return abort(401)\n""]",1
"[""\""\""\""Test admin interface.\""\""\""\n"", ""from __future__ import absolute_import, print_function\n"", ""import uuid\n"", ""from flask import url_for\n"", ""from flask_admin import Admin, menu\n"", ""from mock import patch\n"", ""from sqlalchemy.exc import SQLAlchemyError\n"", ""from invenio_records.admin import record_adminview\n"", ""from invenio_records.api import Record\n"", ""def FUNC_0(VAR_0, VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = Admin(VAR_0, name='Test')\n"", ""assert 'model' in record_adminview\n"", ""assert 'modelview' in record_adminview\n"", ""VAR_3 = record_adminview.pop('model')\n"", ""VAR_4 = record_adminview.pop('modelview')\n"", ""VAR_2.add_view(VAR_4(VAR_3, VAR_1.session, **record_adminview))\n"", ""VAR_5 = {str(item.name): item for item in VAR_2.menu()}\n"", ""assert 'Records' in VAR_5\n"", ""assert VAR_5['Records'].is_category()\n"", ""VAR_6 = {str(item.name): item for item in VAR_5['Records'].get_children()}\n"", ""assert 'Record Metadata' in VAR_6\n"", ""assert isinstance(VAR_6['Record Metadata'], menu.MenuView)\n"", ""VAR_7 = str(uuid.uuid4())\n"", ""Record.create({'title': 'test'}, id_=rec_uuid)\n"", ""VAR_1.session.commit()\n"", ""VAR_8 = url_for('recordmetadata.index_view')\n"", ""VAR_9 = url_for('recordmetadata.delete_view')\n"", ""VAR_10 = url_for('recordmetadata.details_view', id=rec_uuid)\n"", ""VAR_11 = client.get(VAR_8)\n"", ""assert VAR_11.status_code == 200\n"", ""db_mock.side_effect = SQLAlchemyError()\n"", ""VAR_11 = client.post(VAR_9, data={'id': rec_uuid}, follow_redirects=True)\n"", ""assert VAR_11.status_code == 200\n"", ""VAR_11 = client.post(VAR_9, data={'id': rec_uuid}, follow_redirects=True)\n"", ""assert VAR_11.status_code == 200\n"", ""VAR_11 = client.get(VAR_10)\n"", ""assert VAR_11.status_code == 200\n"", ""assert '<pre>null</pre>' in VAR_11.get_data(as_text=True)\n"", ""VAR_11 = client.post(VAR_9, data={'id': rec_uuid}, follow_redirects=True)\n"", ""assert VAR_11.status_code == 200\n""]",1
"[""def FUNC_24(VAR_6):...\n"", ""if 'Cache-Control' in VAR_6.headers:\n"", ""return True\n"", ""return False\n""]",0
"[""\""\""\""string\""\""\""\n"", ""import base64\n"", ""import json\n"", ""import logging\n"", ""import optparse\n"", ""import os\n"", ""import signal\n"", ""import sys\n"", ""import time\n"", ""import xsrf_client\n"", ""from utils import net\n"", ""from utils import on_error\n"", ""from utils import subprocess42\n"", ""from utils import zip_package\n"", ""VAR_0 = os.path.abspath(zip_package.get_main_script_path())\n"", ""VAR_1 = 102400\n"", ""VAR_2 = 30\n"", ""VAR_3 = 10\n"", ""VAR_4 = 3\n"", ""VAR_5 = signal.SIGBREAK if sys.platform == 'win32' else signal.SIGTERM\n"", ""VAR_6 = 0\n"", ""def FUNC_0():...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_20 = time.time()\n"", ""if VAR_20 > VAR_6:\n"", ""VAR_6 = VAR_20\n"", ""return VAR_6\n""]",1
"[""def FUNC_1(self, VAR_3):...\n"", ""VAR_0 = [c for c in self.commands if c.id == VAR_3]\n"", ""if not VAR_0:\n"", ""VAR_7 = VAR_0[0]\n"", ""return VAR_7.run()\n""]",1
"[""def FUNC_20(self, VAR_13):...\n"", ""self.copy_database_file()\n"", ""VAR_15 = self.create_tab_title_from_filepath(self.\n    filechooser_creation_dialog.get_current_name())\n"", ""self.start_database_creation_routine(VAR_15)\n"", ""self.override_dialog.destroy()\n""]",0
"[""def FUNC_23(VAR_14, VAR_16):...\n"", ""self.assertEqual(self.server, VAR_14._remote)\n"", ""VAR_38 = VAR_16.splitlines()\n"", ""self.assertEqual('Jumping out of the loop', VAR_38[0])\n"", ""self.assertEqual('Traceback (most recent call last):', VAR_38[1])\n""]",1
"[""def FUNC_6(self):...\n"", ""if self._IsServerAlive():\n"", ""self._server_popen.terminate()\n"", ""utils.RemoveIfExists(self._temp_options_filename)\n""]",1
"[""def FUNC_23(VAR_14, VAR_16):...\n"", ""self.assertEqual(self.server, VAR_14._remote)\n"", ""VAR_38 = VAR_16.splitlines()\n"", ""self.assertEqual('Jumping out of the loop', VAR_38[0])\n"", ""self.assertEqual('Traceback (most recent call last):', VAR_38[1])\n""]",1
"[""import vim\n"", ""import requests\n"", ""import urlparse\n"", ""from retries import retries\n"", ""from requests_futures.sessions import FuturesSession\n"", ""from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor\n"", ""from ycm import vimsupport\n"", ""from ycm.utils import ToUtf8Json\n"", ""from ycm.server.responses import ServerError, UnknownExtraConf\n"", ""VAR_0 = {'content-type': 'application/json'}\n"", ""VAR_1 = UnsafeThreadPoolExecutor(max_workers=30)\n"", ""VAR_2 = 30\n"", ""def __init__(self):...\n"", ""def FUNC_5(self):...\n"", ""def FUNC_6(self):...\n"", ""return True\n""]",0
"[""def FUNC_1(self, VAR_4, VAR_5, VAR_6):...\n"", ""VAR_10 = str(VAR_4.event_type_id.name).lower()\n"", ""VAR_11 = http.request.env['fit.subscription'].sudo().search([(\n    'subscription_type', '=', 'ai_montly'), ('subscription_partner', '=',\n    VAR_5.id)])\n"", ""VAR_12 = http.request.env['fit.subscription'].sudo().search([(\n    'subscription_type', '=', 'cf_montly'), ('subscription_partner', '=',\n    VAR_5.id)])\n"", ""VAR_13 = http.request.env['fit.subscription'].sudo().search([(\n    'subscription_type', '=', 'bc_montly'), ('subscription_partner', '=',\n    VAR_5.id)])\n"", ""VAR_14 = http.request.env['fit.subscription'].sudo().search([(\n    'subscription_type', '=', 'bc_tickets'), ('subscription_partner', '=',\n    VAR_5.id)])\n"", ""VAR_15 = http.request.env['fit.subscription'].sudo().search([(\n    'subscription_type', '=', 'bz_tickets'), ('subscription_partner', '=',\n    VAR_5.id)])\n"", ""if VAR_11.subscription_is_active:\n"", ""return\n"", ""if VAR_10 == 'bokszaktraining':\n"", ""if VAR_15:\n"", ""if VAR_10 == 'bootcamp':\n"", ""VAR_15.subscription_counter += VAR_6\n"", ""if VAR_13 and VAR_13.subscription_is_active:\n"", ""return\n"", ""if VAR_12 and VAR_12.subscription_is_active:\n"", ""return\n"", ""if VAR_14:\n"", ""VAR_14.subscription_counter += VAR_6\n""]",1
"[""def FUNC_6(self, VAR_33):...\n"", ""if self.options and VAR_33 not in self.options:\n"", ""VAR_101.errors.add(errors.INVALID_OPTION)\n"", ""return VAR_33\n"", ""return self.default\n""]",0
"[""def __init__(self, VAR_5, VAR_6, VAR_7, VAR_8):...\n"", ""self.UserID = VAR_5\n"", ""self.Username = VAR_6\n"", ""self.PasswordHash = VAR_7\n"", ""self.DisplayName = VAR_8\n""]",0
"[""\""\""\""string\""\""\""\n"", ""import mimetypes\n"", ""import os\n"", ""import posixpath\n"", ""import re\n"", ""import stat\n"", ""from django.http import FileResponse, Http404, HttpResponse, HttpResponseNotModified, HttpResponseRedirect\n"", ""from django.template import Context, Engine, TemplateDoesNotExist, loader\n"", ""from django.utils.http import http_date, parse_http_date\n"", ""from django.utils.translation import gettext as _, gettext_lazy\n"", ""def FUNC_0(VAR_0, VAR_1, VAR_2=None, VAR_3=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = posixpath.normpath(VAR_1)\n"", ""VAR_1 = VAR_1.lstrip('/')\n"", ""VAR_10 = ''\n"", ""for VAR_18 in VAR_1.split('/'):\n"", ""if not VAR_18:\n"", ""if VAR_10 and VAR_1 != VAR_10:\n"", ""VAR_17, VAR_18 = os.path.splitdrive(VAR_18)\n"", ""return HttpResponseRedirect(VAR_10)\n"", ""VAR_6 = os.path.join(VAR_2, VAR_10)\n"", ""VAR_19, VAR_18 = os.path.split(VAR_18)\n"", ""if os.path.isdir(VAR_6):\n"", ""if VAR_18 in (os.curdir, os.pardir):\n"", ""if VAR_3:\n"", ""if not os.path.exists(VAR_6):\n"", ""VAR_10 = os.path.join(VAR_10, VAR_18).replace('\\\\', '/')\n"", ""return FUNC_1(VAR_10, VAR_6)\n"", ""VAR_11 = os.stat(VAR_6)\n"", ""if not FUNC_2(VAR_0.META.get('HTTP_IF_MODIFIED_SINCE'), VAR_11.st_mtime,\n"", ""return HttpResponseNotModified()\n"", ""VAR_12, VAR_13 = mimetypes.guess_type(VAR_6)\n"", ""VAR_12 = VAR_12 or 'application/octet-stream'\n"", ""VAR_14 = FileResponse(open(VAR_6, 'rb'), VAR_12=content_type)\n"", ""VAR_14['Last-Modified'] = http_date(VAR_11.st_mtime)\n"", ""if stat.S_ISREG(VAR_11.st_mode):\n"", ""VAR_14['Content-Length'] = VAR_11.st_size\n"", ""if VAR_13:\n"", ""VAR_14['Content-Encoding'] = VAR_13\n"", ""return VAR_14\n""]",1
"[""@click.command(help='Get information for a monitor')...\n"", ""VAR_12 = newrelic.get_monitor(VAR_0.obj['ACCOUNT'], VAR_12)\n"", ""if VAR_11:\n"", ""print(json.dumps(VAR_12))\n"", ""VAR_22 = VAR_12.get('severity', 0)\n"", ""return\n"", ""if VAR_22 == 2:\n"", ""VAR_31 = click.style(u'✔', fg='green')\n"", ""if VAR_22 == 1:\n"", ""VAR_12['health'] = VAR_31\n"", ""VAR_31 = click.style(u'❢', fg='yellow')\n"", ""VAR_31 = click.style(u'✖', fg='red')\n"", ""VAR_23 = VAR_12['status'].lower()\n"", ""if VAR_23 in ('muted', 'disabled'):\n"", ""VAR_23 = click.style(u'❢ {}'.format(VAR_23), fg='yellow')\n"", ""VAR_23 = click.style(u'✔ OK', fg='green')\n"", ""VAR_24 = [['Monitor', VAR_12['id']], ['Status', VAR_23], ['Health', VAR_31],\n    ['Name', VAR_12['name']], ['URI', VAR_12['uri']], ['Type', VAR_12[\n    'type']], ['Locations', ', '.join(VAR_12['locations'])], [\n    'slaThreshold', VAR_12['slaThreshold']], ['Emails', ', '.join(VAR_12[\n    'emails'])], ['Frequency', VAR_12['frequency']], ['Created', VAR_12[\n    'createdAt']], ['Modified', VAR_12['modifiedAt']]]\n"", ""VAR_25 = SingleTable(VAR_24)\n"", ""VAR_25.title = click.style('Monitor', fg='black')\n"", ""print(VAR_25.table)\n""]",1
"[""@app.route('/api/commands/<id>/run', methods=['POST'])...\n"", ""return commands.run(VAR_4)\n""]",1
"[""def FUNC_6(VAR_3, VAR_4, VAR_5):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7 = \""SELECT current_setting('%s') = '%s'\""\n"", ""VAR_3.execute(VAR_7 % (VAR_4, VAR_5))\n"", ""return VAR_3.fetchone()[0]\n""]",1
"[""def FUNC_4(self, VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7 = get_random_string(import_from_settings('OIDC_STATE_SIZE', 32))\n"", ""VAR_8 = import_from_settings('OIDC_REDIRECT_FIELD_NAME', 'next')\n"", ""VAR_9 = {'response_type': 'code', 'scope': 'openid', 'client_id': self.\n    OIDC_RP_CLIENT_ID, 'redirect_uri': absolutify(VAR_1, reverse(\n    'oidc_authentication_callback')), 'state': VAR_7}\n"", ""if import_from_settings('OIDC_USE_NONCE', True):\n"", ""VAR_6 = get_random_string(import_from_settings('OIDC_NONCE_SIZE', 32))\n"", ""VAR_1.session['oidc_state'] = VAR_7\n"", ""VAR_9.update({'nonce': VAR_6})\n"", ""VAR_1.session['oidc_login_next'] = VAR_1.GET.get(VAR_8)\n"", ""VAR_1.session['oidc_nonce'] = VAR_6\n"", ""VAR_10 = urlencode(VAR_9)\n"", ""VAR_11 = '{url}?{query}'.format(url=self.OIDC_OP_AUTH_ENDPOINT, VAR_10=query)\n"", ""return HttpResponseRedirect(VAR_11)\n""]",1
"[""@classmethod...\n"", ""if VAR_3.returns_rows:\n"", ""VAR_0 = VAR_3.keys()\n"", ""return VAR_2(None, None)\n"", ""VAR_1 = [make_row_serializable(row) for row in VAR_3]\n"", ""return VAR_2(VAR_0, VAR_1)\n""]",0
"[""def FUNC_14(self, VAR_18=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_18 is None:\n"", ""self.remove_completed()\n"", ""if not isinstance(VAR_18, list):\n"", ""self.save()\n"", ""VAR_18 = [VAR_18]\n"", ""for job in VAR_18:\n"", ""self.execute('DELETE FROM history WHERE nzo_id=?', (job,))\n"", ""logging.info('Removing job %s from history', job)\n""]",0
"[""def FUNC_36(VAR_11):...\n"", ""for VAR_51, VAR_58 in VAR_11.items():\n"", ""if isinstance(VAR_58, str) or not isinstance(VAR_58, Iterable):\n"", ""VAR_58 = [VAR_58]\n"", ""yield [(VAR_51, VAR_16) for VAR_16 in VAR_58]\n""]",0
"[""def FUNC_33(self):...\n"", ""self.assertEqual(self.cursor.rowcount, -1)\n"", ""self.cursor.execute('create table t1(i int)')\n"", ""VAR_26 = 4\n"", ""for i in range(VAR_26):\n"", ""self.cursor.execute('insert into t1 values (?)', i)\n"", ""self.cursor.execute('delete from t1')\n"", ""self.assertEqual(self.cursor.rowcount, VAR_26)\n""]",0
"[""@VAR_1.route('/results')...\n"", ""VAR_17 = FUNC_7('results.json')\n"", ""VAR_18 = []\n"", ""for VAR_8, values in VAR_17.items():\n"", ""VAR_43 = {'id': VAR_8, 'values': {'x': [], 'y': []}}\n"", ""VAR_18.sort(VAR_13=lambda ts_item: ts_item['result_type'], reverse=False)\n"", ""VAR_44 = [VAR_13 for VAR_13 in values]\n"", ""return render_template('results.html', VAR_17=results, VAR_18=time_series)\n"", ""VAR_44.sort()\n"", ""for date in VAR_44:\n"", ""VAR_43['values']['x'].append(date)\n"", ""if re.search(':timeseries$', VAR_8):\n"", ""VAR_43['values']['y'].append(values[date])\n"", ""VAR_47 = VAR_8.split(':')\n"", ""if re.search('\\\\(output,.*\\\\)$', VAR_8):\n"", ""(VAR_49, VAR_50), VAR_48 = VAR_47[:2], VAR_47[2:]\n"", ""VAR_51 = re.sub('[()]', '', VAR_8)\n"", ""if re.search('input,source_type:', VAR_8):\n"", ""VAR_43['result_type'] = 'Input time series'\n"", ""VAR_47 = VAR_51.split(',')\n"", ""VAR_47 = VAR_8.split(',')\n"", ""VAR_18.append(VAR_43)\n"", ""VAR_43['ts_name'] = VAR_49\n"", ""(VAR_49, VAR_50, VAR_52, VAR_53), VAR_48 = VAR_47[:4], VAR_47[4:]\n"", ""(VAR_49, VAR_53, VAR_50, VAR_52), VAR_54 = VAR_47[:4], VAR_47[4:]\n"", ""VAR_43['ts_author'] = VAR_50\n"", ""VAR_43['result_type'] = 'Output time series'\n"", ""VAR_43['result_type'] = 'Intermediate input time series'\n"", ""VAR_43['ts_name'] = VAR_49\n"", ""VAR_43['ts_name'] = VAR_49\n"", ""VAR_43['ts_author'] = VAR_50\n"", ""VAR_43['ts_author'] = VAR_50\n"", ""VAR_43['model_name'] = VAR_53\n"", ""VAR_43['model_name'] = VAR_53\n"", ""if re.search('input,source_type:output', VAR_8):\n"", ""VAR_55, VAR_48 = VAR_54[1], VAR_54[2:]\n"", ""VAR_43['source_type'] = 'timeseries'\n"", ""VAR_43['source_model_name'] = VAR_55\n"", ""VAR_43['source_type'] = 'model'\n""]",0
"[""import io\n"", ""import time\n"", ""from cauldron.cli.threads import abort_thread\n"", ""\""\""\""string\""\""\""\n"", ""def __init__(self, VAR_0):...\n"", ""self.active = False\n"", ""self.bytes_buffer = io.BytesIO()\n"", ""self.redirection_source = VAR_0\n"", ""self.last_write_time = 0\n"", ""super(CLASS_0, self).__init__(buffer=self.bytes_buffer, encoding=\n    redirection_source.encoding, write_through=True)\n"", ""@property...\n"", ""if self.redirection_source.encoding:\n"", ""return self.redirection_source.encoding\n"", ""return 'utf8'\n""]",1
"[""def FUNC_5(VAR_8):...\n"", ""return set(VAR_29.group('name') for VAR_29 in VAR_5.finditer(VAR_8))\n""]",0
"[""@Slot()...\n"", ""\""\""\""docstring\""\""\""\n"", ""for VAR_14 in self.clients.values():\n"", ""if VAR_14['status'] == self.RUNNING:\n"", ""VAR_17 = self.get_root_path()\n"", ""VAR_18 = VAR_14['instance']\n"", ""VAR_18.folder = VAR_17\n"", ""VAR_18.initialize()\n""]",1
"[""@utils.synchronized('3par', external=True)...\n"", """"]",0
"[""def FUNC_5(self, VAR_12):...\n"", ""VAR_14 = 'string'.format(VAR_12)\n"", ""self.cur.execute(VAR_14)\n"", ""return self.cur.fetchall()\n""]",1
"[""def FUNC_4(self, VAR_5):...\n"", ""VAR_20 = 'string' % VAR_5\n"", ""self.c.execute(VAR_20)\n"", ""VAR_3 = self.c.fetchone()\n"", ""return VAR_3[0], VAR_3[1], VAR_3[2]\n""]",1
"[""def __init__(self, VAR_23, VAR_24):...\n"", ""self.base = VAR_23\n"", ""self.redirections = VAR_24\n""]",0
"[""def __call__(self, VAR_2, VAR_3, VAR_4=None):...\n"", ""VAR_45 = subprocess.Popen(['host', VAR_3], VAR_66=subprocess.PIPE)\n"", ""VAR_46, VAR_47 = VAR_45.communicate()\n"", ""VAR_46 = VAR_46.decode().strip()\n"", ""self.reply(VAR_2, VAR_46)\n""]",1
"[""def FUNC_13(self, VAR_11, VAR_12, VAR_13, VAR_14):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_31 = 'createhost -iscsi -persona %s -domain %s %s %s' % (VAR_14, VAR_13,\n    VAR_11, VAR_12)\n"", ""VAR_32 = self.common._cli_run(VAR_31, None)\n"", ""if VAR_32 and len(VAR_32) > 1:\n"", ""return self.common.parse_create_host_error(VAR_11, VAR_32)\n"", ""return VAR_11\n""]",1
"[""def FUNC_15(VAR_6):...\n"", ""VAR_4.register_jvm_tool(VAR_8, VAR_4._key_for_tool_version('scalastyle',\n    VAR_6), VAR_15=[scala_style_jar])\n""]",1
"[""\""\""\""SchoolCMS-handler-init.\n\nroute.\n\""\""\""\n"", ""from __future__ import absolute_import\n"", ""from __future__ import print_function\n"", ""from __future__ import unicode_literals\n"", ""from .. import version as system_version\n"", ""from ..db import SQL_Session, User, GroupList, Login_Session\n"", ""from ..util import webassets_react\n"", ""import functools\n"", ""import os\n"", ""from webassets import Environment, Bundle\n"", ""import tornado.web\n"", ""from tornado.escape import json_encode\n"", ""from tornado.options import options\n"", ""def FUNC_0(self, VAR_1=True):...\n"", ""self.is_api = VAR_1\n"", ""self.assets = Environment(os.path.join(os.path.dirname(__file__),\n    '../static'), '/static')\n"", ""VAR_11 = Bundle('css/bootstrap.min.css', 'css/material.min.css', Bundle(\n    'css/schoolcms.css', 'css/dropdown.css', filters='cssmin'),\n    'outdatedbrowser/outdatedbrowser.min.css', output='dict/plugin.min.css')\n"", ""VAR_12 = Bundle(Bundle('outdatedbrowser/outdatedbrowser.min.js',\n    'react-0.13.2/react-with-addons.min.js', 'js/jquery-2.1.3.min.js',\n    'js/bootstrap.min.js', 'js/react-bootstrap.min.js',\n    'js/react-mini-router.min.js', 'js/marked.min.js', 'js/material.min.js',\n    'js/isMobile.min.js', 'js/moment-with-locales.min.js', 'js/dropdown.js',\n    filters='jsmin'), Bundle('schoolcms/init.jsx', 'schoolcms/mixin/*.jsx',\n    'schoolcms/component/*.jsx', 'schoolcms/page/*.jsx', filters=('react',\n    'jsmin')), output='dict/plugin.min.js')\n"", ""self.assets.register('css_all', VAR_11)\n"", ""self.assets.register('js_all', VAR_12)\n"", ""def FUNC_1(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.sql_session = SQL_Session()\n"", ""def FUNC_2(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.sql_session.close()\n"", ""def FUNC_3(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_13 = self.get_secure_cookie('session_key')\n"", ""if not VAR_13:\n"", ""return None\n"", ""VAR_14 = Login_Session.get_by_key(VAR_13, self.sql_session)\n"", ""if not VAR_14:\n"", ""return None\n"", ""return User.by_key(VAR_14.userkey, self.sql_session).scalar()\n""]",1
"[""def FUNC_6(VAR_4, VAR_5=''):...\n"", ""VAR_0, VAR_10 = FUNC_0()\n"", ""VAR_18 = 'UPDATE {} SET \""options_selected\""=\\'{}\\' WHERE token=\\'{}\\''.format(\n    CFG('tokens_table_name'), VAR_5, VAR_4)\n"", ""VAR_10.execute(VAR_18)\n"", ""FUNC_1(VAR_0)\n""]",1
"[""def FUNC_31():...\n"", ""VAR_24 = vim.eval('tagfiles()')\n"", ""VAR_25 = VAR_0.getcwd()\n"", ""return [VAR_0.path.join(VAR_25, x) for x in VAR_24]\n""]",0
"[""import collections\n"", ""import os\n"", ""import pymongo\n"", ""from django.http import Http404\n"", ""from cuckoo.core.database import Database, TASK_PENDING\n"", ""from cuckoo.common.mongo import mongo\n"", ""VAR_0 = Database()\n"", ""@staticmethod...\n"", ""if not isinstance(VAR_1, int):\n"", ""VAR_9 = {}\n"", ""VAR_10 = VAR_0.view_task(VAR_1, details=True)\n"", ""if VAR_10:\n"", ""VAR_19 = VAR_10.to_dict()\n"", ""return Exception('Task not found')\n"", ""VAR_19['guest'] = {}\n"", ""if VAR_10.guest:\n"", ""VAR_19['guest'] = VAR_10.guest.to_dict()\n"", ""VAR_19['errors'] = []\n"", ""for error in VAR_10.errors:\n"", ""VAR_19['errors'].append(error.message)\n"", ""VAR_19['sample'] = {}\n"", ""if VAR_10.sample_id:\n"", ""VAR_26 = VAR_0.view_sample(VAR_10.sample_id)\n"", ""VAR_9['task'] = VAR_19\n"", ""VAR_19['sample'] = VAR_26.to_dict()\n"", ""return VAR_9\n""]",1
"[""@VAR_1.route('/new_franchise/<lat>/<lng>')...\n"", """"]",0
"[""from const import *\n"", ""from model import *\n"", ""from utils import *\n"", ""import reveal\n"", ""\""\""\""An admin page to delete person records.\""\""\""\n"", ""VAR_0 = True\n"", ""VAR_1 = False\n"", ""VAR_2 = True\n"", ""def FUNC_0(self):...\n"", ""VAR_3 = XsrfTool()\n"", ""VAR_4 = users.get_current_user()\n"", ""self.render('admin_delete_record.html', id=self.env.domain + '/person.',\n    xsrf_token=xsrf_tool.generate_token(user.user_id(), 'admin_delete_record'))\n"", ""def FUNC_1(self):...\n"", ""VAR_3 = XsrfTool()\n"", ""VAR_4 = users.get_current_user()\n"", ""if not (self.params.xsrf_token and VAR_3.verify_token(self.params.\n"", ""self.error(403)\n"", ""VAR_5 = 'delete', str(self.params.id)\n"", ""return False\n"", ""self.redirect('/delete', id=self.params.id, signature=reveal.sign(action))\n""]",1
"[""def FUNC_3(self):...\n"", ""self.set_secure_cookie('username', self.get_argument('username'))\n"", ""self.redirect('/', permanent=True)\n""]",1
"[""import random\n"", ""import string\n"", ""from urllib import quote\n"", ""from saker.fuzzers.fuzzer import Fuzzer\n"", ""\""\""\""Code Payload\""\""\""\n"", ""VAR_0 = {'a': 'а', 'c': 'ϲ', 'd': 'ԁ', 'e': 'е', 'h': 'һ', 'i': 'і', 'j':\n    'ј', 'l': 'ӏ', 'o': 'о', 'p': 'р', 'r': 'г', 'q': 'ԛ', 's': 'ѕ', 'w':\n    'ԝ', 'x': 'х', 'y': 'у'}\n"", ""def __init__(self):...\n"", ""super(CLASS_0, self).__init__()\n"", ""@staticmethod...\n"", ""for i in xrange(256):\n"", ""yield chr(i)\n"", ""@staticmethod...\n"", ""for i in xrange(VAR_1):\n"", ""yield unichr(random.randint(0, 65535))\n"", ""@staticmethod...\n"", ""VAR_2 = VAR_2.replace('A', 'Ā', VAR_1)\n"", ""VAR_2 = VAR_2.replace('A', 'Ă', VAR_1)\n"", ""VAR_2 = VAR_2.replace('A', 'Ą', VAR_1)\n"", ""VAR_2 = VAR_2.replace('a', 'α', VAR_1)\n"", ""VAR_2 = VAR_2.replace('e', 'е', VAR_1)\n"", ""VAR_2 = VAR_2.replace('a', 'а', VAR_1)\n"", ""VAR_2 = VAR_2.replace('e', 'ё', VAR_1)\n"", ""VAR_2 = VAR_2.replace('o', 'о', VAR_1)\n"", ""return VAR_2\n""]",1
"[""def __init__(self, VAR_7):...\n"", ""self._user_options = VAR_7\n"", ""self._user_notified_about_crash = False\n"", ""self._diag_interface = DiagnosticInterface(VAR_7)\n"", ""self._omnicomp = OmniCompleter(VAR_7)\n"", ""self._latest_completion_request = None\n"", ""self._latest_file_parse_request = None\n"", ""self._server_stdout = None\n"", ""self._server_stderr = None\n"", ""self._server_popen = None\n"", ""self._filetypes_with_keywords_loaded = set()\n"", ""self._temp_options_filename = None\n"", ""self._ycmd_keepalive = YcmdKeepalive()\n"", ""self._SetupServer()\n"", ""self._ycmd_keepalive.Start()\n""]",1
"[""def FUNC_2(VAR_0, VAR_3):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_4 = 'string'.format(VAR_3)\n"", ""VAR_6 = FUNC_3(VAR_0, VAR_4)\n"", ""if VAR_6 is not None:\n"", ""VAR_8 = open('error_report.txt', 'w')\n"", ""return False\n"", ""for row in VAR_6:\n"", ""VAR_8.write('{} - {}% errors \\n'.format(row[0], row[1]))\n"", ""VAR_8.close()\n"", ""return True\n""]",1
"[""def FUNC_5(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = self.bindings\n"", ""VAR_6 = VAR_1['TEST_APP_COMPONENT_NAME']\n"", ""VAR_7 = '{0}/targetPools/{1}-tp'.format(VAR_1['TEST_GCE_REGION'], VAR_6)\n"", ""VAR_8 = {'checkIntervalSec': 9, 'healthyThreshold': 3, 'unhealthyThreshold':\n    5, 'timeoutSec': 2, 'port': 80}\n"", ""VAR_9 = self.agent.make_json_payload_from_kwargs(job=[{'cloudProvider':\n    'gce', 'provider': 'gce', 'stack': bindings['TEST_STACK'], 'detail':\n    bindings['TEST_COMPONENT_DETAIL'], 'credentials': bindings[\n    'GCE_CREDENTIALS'], 'region': bindings['TEST_GCE_REGION'], 'ipProtocol':\n    'TCP', 'portRange': spec['port'], 'loadBalancerName':\n    load_balancer_name, 'healthCheck': {'port': spec['port'], 'timeoutSec':\n    spec['timeoutSec'], 'checkIntervalSec': spec['checkIntervalSec'],\n    'healthyThreshold': spec['healthyThreshold'], 'unhealthyThreshold':\n    spec['unhealthyThreshold']}, 'type': 'upsertLoadBalancer',\n    'availabilityZones': {bindings['TEST_GCE_REGION']: []}, 'user':\n    '[anonymous]'}], description='Create Load Balancer: ' +\n    load_balancer_name, application=self.TEST_APP)\n"", ""VAR_10 = gcp.GceContractBuilder(self.gce_observer)\n"", ""VAR_10.new_clause_builder('Health Check Added', retryable_for_secs=30\n    ).list_resources('http-health-checks').contains_pred_list([jc.\n    PathContainsPredicate('name', '%s-hc' % VAR_6), jc.DICT_SUBSET(VAR_8)])\n"", ""VAR_10.new_clause_builder('Target Pool Added', retryable_for_secs=30\n    ).list_resources('target-pools').contains_path_value('name', '%s-tp' %\n    VAR_6)\n"", ""VAR_10.new_clause_builder('Forwarding Rules Added', retryable_for_secs=30\n    ).list_resources('forwarding-rules').contains_pred_list([jc.\n    PathContainsPredicate('name', VAR_6), jc.PathContainsPredicate('target',\n    VAR_7)])\n"", ""return st.OperationContract(self.new_post_operation(title=\n    'upsert_load_balancer', data=payload, path='tasks'), VAR_5=builder.build())\n""]",1
"[""def FUNC_4(self, VAR_1, VAR_4, VAR_3):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.cursor.execute('UPDATE {0} SET {1} WHERE {2}'.format(VAR_1, VAR_4, VAR_3))\n"", ""print('Erro: {}'.format(error))\n"", ""self.__connection.commit()\n"", ""return self.cursor\n""]",1
"[""def FUNC_1(VAR_0: str) ->List[str]:...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_3 = FUNC_0(VAR_0)\n"", ""return [line.strip().decode() for line in VAR_3.splitlines()]\n""]",1
"[""def FUNC_39(self, VAR_20):...\n"", ""for VAR_14 in self.list_properties.keys():\n"", ""if self.is_relation(VAR_14):\n"", ""if VAR_20 == self.get_related_model(VAR_14):\n"", ""return VAR_14\n""]",0
"[""async def FUNC_6(VAR_6):...\n"", ""import csv\n"", ""VAR_10 = {'Authorization': f'Bearer {VAR_1}'}\n"", ""VAR_11 = csv.reader(open('jogging_dataset.csv'), delimiter=',')\n"", ""for row in VAR_11:\n"", ""VAR_7 = {'date': row[0], 'location': row[1], 'distance': int(row[2]),\n    'time': int(row[3])}\n"", ""VAR_8 = await VAR_6.post('/results', VAR_10=headers, VAR_7=json.dumps(data))\n"", ""assert VAR_8.status == 201\n""]",0
"[""def FUNC_2(self):...\n"", ""self.driver._eql_execute = self.mox.CreateMock(self.driver._eql_execute)\n"", ""VAR_1 = {'name': self.volume_name, 'size': 1}\n"", ""self.driver._eql_execute('volume', 'create', VAR_1['name'], '%sG' % VAR_1[\n    'size'], 'pool', self.configuration.eqlx_pool, 'thin-provision').AndReturn(\n    ['iSCSI target name is %s.' % self.fake_iqn])\n"", ""self.mox.ReplayAll()\n"", ""VAR_2 = self.driver.create_volume(VAR_1)\n"", ""self.assertEqual(VAR_2, self._model_update)\n""]",0
"[""import cgi\n"", ""import mysql.connector\n"", ""from html import beghtml, endhtml\n"", ""VAR_0 = cgi.FieldStorage()\n"", ""VAR_1 = VAR_0.getvalue('enzyme_name')\n"", ""VAR_2 = VAR_0.getvalue('process_name')\n"", ""VAR_3 = VAR_0.getvalue('enzyme_name2')\n"", ""VAR_4 = VAR_0.getvalue('process_name2')\n"", ""VAR_5 = VAR_0.getvalue('enzyme_name3')\n"", ""VAR_6 = VAR_0.getvalue('conc')\n"", ""VAR_7 = VAR_0.getvalue('compound')\n"", ""VAR_8 = VAR_0.getvalue('inter')\n"", ""VAR_9 = VAR_0.getvalue('sub')\n"", ""VAR_10 = VAR_0.getvalue('organelle')\n"", ""VAR_5 = VAR_0.getvalue('enzyme_name3')\n"", ""VAR_11 = VAR_0.getvalue('process_name3')\n"", ""VAR_12 = VAR_0.getvalue('organelle2')\n"", ""VAR_13 = VAR_0.getvalue('conc2')\n"", ""VAR_14 = VAR_0.getvalue('compound2')\n"", ""VAR_15 = mysql.connector.connect(user='eapfelba', database='eapfelba2',\n    host='localhost', password='chumash1000')\n"", ""VAR_16 = ''\n"", ""VAR_17 = VAR_15.cursor()\n"", ""if VAR_1:\n"", ""VAR_16 = \""delete from converts where enzyme_name = '%s'\"" % VAR_1\n"", ""if VAR_5:\n"", ""VAR_16 = \""delete from enzyme where enzyme_name = '%s'\"" % VAR_5\n"", ""if VAR_2:\n"", ""VAR_16 = \""delete from process where process_name = '%s'\"" % VAR_2\n"", ""if VAR_4 and VAR_3:\n"", ""VAR_16 = (\n    \""delete from uses where process_name = '%s' and enzyme_name = '%s'\"" % (\n    VAR_4, VAR_3))\n"", ""if VAR_6 and VAR_7:\n"", ""VAR_16 = \""delete from conds where concentration = '%s' and compound = '%s'\"" % (\n    VAR_6, VAR_7)\n"", ""if VAR_8:\n"", ""VAR_16 = \""delete from intermediate where intermediate_name = '%s'\"" % VAR_8\n"", ""if VAR_10 and VAR_9:\n"", ""VAR_16 = (\n    \""delete from location where organelle = '%s' and substructure = '%s'\"" %\n    (VAR_10, VAR_9))\n"", ""if VAR_5 and VAR_12:\n"", ""VAR_16 = (\n    \""delete from located_in where enzyme_name = '%s' and organelle = '%s'\"" %\n    (VAR_5, VAR_12))\n"", ""if VAR_11 and VAR_13 and VAR_14:\n"", ""VAR_16 = (\n    \""delete from operates_uner where process_name = '%s' and concentration = '%s' and compound = '%s'\""\n     % (VAR_11, VAR_13, VAR_14))\n"", ""VAR_18 = False\n"", ""if not VAR_16:\n"", ""beghtml()\n"", ""VAR_17.execute(VAR_16)\n"", ""beghtml()\n"", ""if VAR_18 == False:\n"", ""print(\""<h3>You didn't fill anything out! :/</h3>\"")\n"", ""VAR_15.commit()\n"", ""print('Something went wrong: {}'.format(err) + '<br><br>')\n"", ""beghtml()\n"", ""VAR_17.close()\n"", ""print(\n    '<b><a href = \""http://ada.sterncs.net/~eapfelbaum/delete.html\"">Back</a></b>'\n    )\n"", ""print(\n    '<b><a href = \""http://ada.sterncs.net/~eapfelbaum/delete.html\"">Back</a></b>'\n    )\n"", ""print('<h3>Deleted!</h3>')\n"", ""VAR_15.close()\n"", ""print(\n    '<br><b><a href = \""http://ada.sterncs.net/~eapfelbaum/biobase.html\"">Home</a></b>'\n    )\n"", ""endhtm()\n"", ""print('string')\n"", ""endhtml()\n"", ""VAR_18 = True\n"", ""print(\n    '<b><a href = \""http://ada.sterncs.net/~eapfelbaum/biobase.html\"">Try Something Else!</a></b><br><br>'\n    )\n"", ""VAR_18 = True\n"", ""print(\n    '<b><a href = \""http://ada.sterncs.net/~eapfelbaum/delete.html\"">Back</a></b>'\n    )\n"", ""endhtml()\n""]",1
"[""def FUNC_7(self):...\n"", ""self.mock(time, 'time', lambda : 126.0)\n"", ""self.mock(logging, 'error', lambda *VAR_15, **_kw: None)\n"", ""self.mock(bot_main, 'get_remote', lambda : self.server)\n"", ""self.mock(os_utilities, 'get_state', lambda : {'foo': 'bar'})\n"", ""VAR_13 = bot_main.get_attributes(None)\n"", ""self.expected_requests([(\n    'https://localhost:1/auth/api/v1/accounts/self/xsrf_token', {'data':\n    VAR_13, 'headers': {'X-XSRF-Token-Request': '1'}}, {'xsrf_token':\n    'token'}), ('https://localhost:1/swarming/api/v1/bot/task_error/23', {\n    'data': {'id': VAR_13['dimensions']['id'][0], 'message': 'error',\n    'task_id': 23}, 'headers': {'X-XSRF-Token': 'token'}}, {})])\n"", ""VAR_14 = bot_main.get_bot()\n"", ""bot_main.post_error_task(VAR_14, 'error', 23)\n""]",1
"[""\""\""\""string\""\""\""\n"", ""from lxml import etree\n"", ""from cinder import exception\n"", ""from cinder.openstack.common import log as logging\n"", ""from cinder.volume.drivers.san.san import SanISCSIDriver\n"", ""VAR_0 = logging.getLogger(__name__)\n"", ""\""\""\""string\""\""\""\n"", ""VAR_1 = {}\n"", ""def __init__(self, *VAR_2, **VAR_3):...\n"", ""super(CLASS_0, self).__init__(*VAR_2, **kwargs)\n"", ""self.cluster_vip = None\n"", ""def FUNC_0(self, VAR_4, VAR_5, VAR_6=True):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_14 = []\n"", ""for VAR_43, v in VAR_5.items():\n"", ""VAR_14.append(' %s=%s' % (VAR_43, v))\n"", ""VAR_15 = VAR_4 + ''.join(VAR_14)\n"", ""return self._run_ssh(VAR_15, VAR_6)\n""]",1
"[""def FUNC_39(VAR_101):...\n"", ""VAR_101.shellcmd = VAR_81\n"", ""return VAR_101\n""]",0
"[""def FUNC_0(self):...\n"", ""self.assertTrue(self.client.login(username='autotest', password='password'))\n"", ""settings.SSH_PRIVATE_KEY = '<some-ssh-private-key>'\n""]",1
"[""def FUNC_4(VAR_2, VAR_4):...\n"", ""if VAR_4.status == 'failed':\n"", ""VAR_8 = str(uuid.uuid4())\n"", ""os.chdir('screenshots')\n"", ""VAR_2.browser.save_screenshot('failed ' + str(VAR_4.name) + '_' + VAR_8 +\n    '.png')\n"", ""FUNC_7(VAR_2, 'failed ' + str(VAR_4.name) + '_' + VAR_8 + '.html')\n"", ""os.chdir('../')\n""]",0
"[""def FUNC_7(self):...\n"", ""VAR_4 = Lint.executable\n"", ""VAR_5 = 'invalid_binary_which_doesnt_exist'\n"", ""Lint.executable = VAR_5\n"", ""self.assertEqual(Lint.check_prerequisites(), \""'{}' is not installed.\"".\n    format(VAR_5))\n"", ""Lint.executable = 'echo'\n"", ""self.assertTrue(Lint.check_prerequisites())\n"", ""self.assertTrue(Lint.check_prerequisites())\n"", ""Lint.executable = VAR_4\n""]",0
"[""def FUNC_4(VAR_9, VAR_2):...\n"", ""return VAR_9 not in VAR_10 and helpers.convert(VAR_2[VAR_9][0])[0\n    ] == 'JUMPDEST'\n""]",0
"[""def FUNC_25(self):...\n"", ""VAR_13 = webapp2.Request({'HTTP_X_APPENGINE_INBOUND_APPID': 'some-app'})\n"", ""self.assertEqual(model.Identity(model.IDENTITY_SERVICE, 'some-app'),\n    handler.service_to_service_authentication(VAR_13))\n""]",0
"[""def FUNC_3(self):...\n"", ""VAR_14 = db_interac.delete_users()\n"", ""return {}, 204\n""]",0
"[""def FUNC_40(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return list(self.list_properties.keys())\n""]",0
"[""def FUNC_4(self, VAR_3, **VAR_6):...\n"", ""logging.warn('url_open(%s, %s)', VAR_3[:500], str(VAR_6)[:500])\n"", ""if not self._requests:\n"", ""return None\n"", ""VAR_6.pop('stream', None)\n"", ""for i, n in enumerate(self._requests):\n"", ""if n[0] == VAR_3:\n"", ""self.fail('Unknown request %s' % VAR_3)\n"", ""VAR_9 = self._requests.pop(i)\n"", ""if len(VAR_9) != 4:\n"", ""self.fail('Expected normal request, got json data; %s' % VAR_3)\n"", ""VAR_10, VAR_11, VAR_12, VAR_4 = VAR_9\n"", ""if callable(VAR_11):\n"", ""VAR_11(VAR_6)\n"", ""self.assertEqual(VAR_11, VAR_6)\n"", ""if VAR_12 is not None:\n"", ""return FUNC_0(VAR_12, VAR_3, VAR_4)\n"", ""return None\n""]",1
"[""@pytest.mark.skip(reason='not handled yet')...\n"", ""FUNC_2(VAR_2)\n"", ""FUNC_3(VAR_2, 'DYMOND', VAR_7='1')\n"", ""FUNC_5(VAR_4, VAR_5, VAR_11='DIAMOND', VAR_10=[{'name': 'DYMOND'}])\n""]",0
"[""def FUNC_2(self, VAR_8):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_5 = {}\n"", ""VAR_5['clusterName'] = VAR_8\n"", ""VAR_5['searchDepth'] = '1'\n"", ""VAR_5['verbose'] = '0'\n"", ""VAR_18 = self._cliq_run_xml('getClusterInfo', VAR_5)\n"", ""return VAR_18\n""]",0
"[""def FUNC_23(self):...\n"", ""self.log.info('Initializing interprocess signal socket %s', self.pr_sa)\n"", ""self.pr_sock = self.p.ctx.socket(zmq.PUB)\n"", ""self.pr_sock.bind(self.pr_sa)\n""]",0
"[""def FUNC_8(VAR_15):...\n"", ""VAR_32 = VAR_15.to_dict()\n"", ""VAR_32['tags'] = AnnTag.get_ann_tags(VAR_15.id, self.sql_session)\n"", ""return VAR_32\n""]",0
"[""def FUNC_0(self, VAR_4, VAR_5, VAR_6=True):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_14 = []\n"", ""for VAR_43, v in VAR_5.items():\n"", ""VAR_14.append(' %s=%s' % (VAR_43, v))\n"", ""VAR_15 = VAR_4 + ''.join(VAR_14)\n"", ""return self._run_ssh(VAR_15, VAR_6)\n""]",1
"[""def FUNC_3(self):...\n"", ""VAR_1 = self.c.get('/find/?q=diatom')\n"", ""self.assertContains(VAR_1, 'Filter by Group Type')\n"", ""VAR_1 = self.c.get('/find/?q=diatom&group_type=Unidentified')\n"", ""self.assertContains(VAR_1, 'Showing 1 - 20 of')\n"", ""VAR_1 = self.c.get('/find/?q=diatom&group_type=BadGroupName')\n"", ""self.assertContains(VAR_1, 'Sorry, no result found')\n""]",1
"[""@classmethod...\n"", ""if not os.path.isfile(VAR_6.userConfigPath):\n"", ""if VAR_11:\n"", ""if not VAR_11:\n"", ""cf.write(VAR_6.userConfigTemplate % VAR_11)\n"", ""err('Editor not given. Cannot edit.')\n"", ""for VAR_15 in yaml.load_all(cf):\n"", ""if not VAR_11:\n"", ""subprocess.call([VAR_11, VAR_6.userConfigPath])\n"", ""return 2\n"", ""if 'editor' in VAR_15:\n"", ""err('Editor not given. Cannot edit.')\n"", ""return 0\n"", ""VAR_11 = VAR_15['editor']\n"", ""return 3\n""]",1
"[""def FUNC_3(VAR_2):...\n"", ""if not VAR_2:\n"", ""return []\n"", ""VAR_9 = []\n"", ""VAR_10 = frappe.db.get_value('Department', {'name': VAR_2}, ['lft', 'rgt'],\n    as_dict=True)\n"", ""VAR_11 = frappe.db.sql(\n    \""\""\""select name from `tabDepartment`\n\t\twhere lft >= %s and rgt <= %s order by lft desc\n\t\t\""\""\""\n    , (VAR_10.lft, VAR_10.rgt), as_list=True)\n"", ""for d in VAR_11:\n"", ""VAR_9.extend([l.leave_approver for l in frappe.db.sql('string', d, as_dict=\n    True)])\n"", ""return VAR_9\n""]",0
"[""def FUNC_2(self):...\n"", ""self.client.get(f'/qa/extractionscript/{self.objects.exscript.pk}/')\n"", ""VAR_0 = self.objects.extext.pk\n"", ""VAR_1 = self.client.post(f'/qa/extractedtext/{VAR_0}/', {'approve': [47]})\n"", ""self.assertEqual(VAR_1.url, '/qa/extractionscript/',\n    'User should be redirected to QA homepage after last extext is approved.')\n""]",1
"[""def FUNC_6(VAR_6):...\n"", ""\""\""\""docstring\""\""\""\n"", ""@wraps(VAR_6)...\n"", ""if not request.is_xhr:\n"", ""return abort(401)\n"", ""return VAR_6(*VAR_11, **kwargs)\n""]",0
"[""def FUNC_1(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.nodes.pop()\n""]",1
"[""from __future__ import unicode_literals\n"", ""import frappe, unittest\n"", ""from frappe.model.db_query import DatabaseQuery\n"", ""from frappe.desk.reportview import get_filters_cond\n"", ""def FUNC_1(self):...\n"", ""self.assertTrue({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    limit_page_length=None))\n"", ""def FUNC_2(self):...\n"", ""self.assertTrue({'name': 'DocType', 'issingle': 0} in DatabaseQuery(\n    'DocType').execute(fields=['name', 'issingle'], limit_page_length=None))\n"", ""def FUNC_3(self):...\n"", ""self.assertFalse({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    filters=[['DocType', 'name', 'like', 'J%']]))\n"", ""def FUNC_4(self):...\n"", ""self.assertFalse({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    filters=[{'name': ['like', 'J%']}]))\n"", ""def FUNC_5(self):...\n"", ""self.assertFalse({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    filters={'name': ['like', 'J%']}))\n"", ""def FUNC_6(self):...\n"", ""self.assertTrue({'name': 'DocField'} in DatabaseQuery('DocType').execute(\n    filters={'name': 'DocField'}))\n"", ""def FUNC_7(self):...\n"", ""self.assertFalse(DatabaseQuery('DocType').execute(filters={'name': ['in',\n    None]}))\n"", ""self.assertTrue({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    filters={'name': ['not in', None]}))\n"", ""for result in [{'name': 'DocType'}, {'name': 'DocField'}]:\n"", ""self.assertTrue(result in DatabaseQuery('DocType').execute(filters={'name':\n    ['in', 'DocType,DocField']}))\n"", ""for result in [{'name': 'DocType'}, {'name': 'DocField'}]:\n"", ""self.assertFalse(result in DatabaseQuery('DocType').execute(filters={'name':\n    ['not in', 'DocType,DocField']}))\n"", ""def FUNC_8(self):...\n"", ""VAR_3 = DatabaseQuery('DocField').execute(filters={'parent': 'DocType'},\n    fields=['fieldname', 'fieldtype'], or_filters=[{'fieldtype': 'Table'},\n    {'fieldtype': 'Select'}])\n"", ""self.assertTrue({'fieldtype': 'Table', 'fieldname': 'fields'} in VAR_3)\n"", ""self.assertTrue({'fieldtype': 'Select', 'fieldname': 'document_type'} in VAR_3)\n"", ""self.assertFalse({'fieldtype': 'Check', 'fieldname': 'issingle'} in VAR_3)\n"", ""def FUNC_9(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""frappe.db.sql('delete from tabEvent')\n"", ""VAR_4 = FUNC_0()\n"", ""VAR_5 = FUNC_0(VAR_1='2016-07-05 23:59:59')\n"", ""VAR_6 = FUNC_0(VAR_1='2016-07-06 00:00:00')\n"", ""VAR_7 = FUNC_0(VAR_1='2016-07-07 23:59:59')\n"", ""VAR_8 = FUNC_0(VAR_1='2016-07-08 00:00:01')\n"", ""VAR_3 = DatabaseQuery('Event').execute(filters={'starts_on': ['between',\n    None]}, fields=['name'])\n"", ""self.assertTrue({'name': VAR_5.name} not in VAR_3)\n"", ""VAR_3 = DatabaseQuery('Event').execute(filters={'starts_on': ['between', [\n    '2016-07-06', '2016-07-07']]}, fields=['name'])\n"", ""self.assertTrue({'name': VAR_6.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_7.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_5.name} not in VAR_3)\n"", ""self.assertTrue({'name': VAR_8.name} not in VAR_3)\n"", ""VAR_3 = DatabaseQuery('Event').execute(filters={'starts_on': ['between', [\n    '2016-07-07']]}, fields=['name'])\n"", ""self.assertTrue({'name': VAR_7.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_8.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_4.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_5.name} not in VAR_3)\n"", ""self.assertTrue({'name': VAR_6.name} not in VAR_3)\n"", ""def FUNC_10(self):...\n"", ""frappe.set_user('test1@example.com')\n"", ""self.assertRaises(frappe.PermissionError, get_filters_cond, 'DocType', dict\n    (istable=1), [])\n"", ""self.assertTrue(get_filters_cond('DocType', dict(istable=1), [],\n    ignore_permissions=True))\n"", ""frappe.set_user('Administrator')\n"", ""def FUNC_11(self):...\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name', 'issingle, version()'], limit_start=0, limit_page_length=1)\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name',\n    'issingle, IF(issingle=1, (select name from tabUser), count(name))'],\n    limit_start=0, limit_page_length=1)\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name', 'issingle, (select count(*) from tabSessions)'],\n    limit_start=0, limit_page_length=1)\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name',\n    \""issingle, SELECT LOCATE('', `tabUser`.`user`) AS user;\""], limit_start=\n    0, limit_page_length=1)\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name',\n    'issingle, IF(issingle=1, (SELECT name from tabUser), count(*))'],\n    limit_start=0, limit_page_length=1)\n"", ""VAR_3 = DatabaseQuery('DocType').execute(fields=['name', 'issingle',\n    'count(name)'], limit_start=0, limit_page_length=1)\n"", ""self.assertTrue('count(name)' in VAR_3[0])\n"", ""VAR_3 = DatabaseQuery('DocType').execute(fields=['name', 'issingle',\n    \""locate('', name) as _relevance\""], limit_start=0, limit_page_length=1)\n"", ""self.assertTrue('_relevance' in VAR_3[0])\n"", ""VAR_3 = DatabaseQuery('DocType').execute(fields=['name', 'issingle',\n    'date(creation) as creation'], limit_start=0, limit_page_length=1)\n"", ""self.assertTrue('creation' in VAR_3[0])\n"", ""VAR_3 = DatabaseQuery('DocType').execute(fields=['name', 'issingle',\n    'datediff(modified, creation) as date_diff'], limit_start=0,\n    limit_page_length=1)\n"", ""self.assertTrue('date_diff' in VAR_3[0])\n"", ""def FUNC_0(VAR_0='_Test Event', VAR_1=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""from frappe.utils import get_datetime\n"", ""VAR_2 = frappe.get_doc({'doctype': 'Event', 'subject': VAR_0, 'event_type':\n    'Public', 'starts_on': get_datetime(VAR_1)}).insert(ignore_permissions=True\n    )\n"", ""return VAR_2\n""]",1
"[""def FUNC_0(VAR_2, VAR_3=None, VAR_4=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""import atexit, os, subprocess, signal\n"", ""if VAR_3:\n"", ""from watchdog.observers import Observer\n"", ""def FUNC_11(VAR_18):...\n"", ""from watchdog.events import FileSystemEventHandler\n"", ""if not VAR_4:\n"", ""print('Restarting worker due to change in %s' % VAR_18.src_path)\n"", ""log.info('modified %s' % VAR_18.src_path)\n"", ""FUNC_13()\n"", ""log.exception('Error while restarting worker')\n"", ""VAR_19 = FileSystemEventHandler()\n"", ""FUNC_12()\n"", ""VAR_19.on_modified = FUNC_11\n"", ""VAR_20 = []\n"", ""log.info('starting %s workers' % VAR_2)\n"", ""def FUNC_12():...\n"", ""VAR_20 = []\n"", ""for i in range(int(VAR_2)):\n"", ""VAR_26 = subprocess.Popen([sys.executable, __file__], stdout=subprocess.\n    PIPE, stderr=subprocess.PIPE)\n"", ""def FUNC_13():...\n"", ""VAR_20.append(VAR_26.pid)\n"", ""\""\""\""docstring\""\""\""\n"", ""log.info('Started worker with pid %s' % VAR_26.pid)\n"", ""log.info('Stopping worker(s)')\n"", ""for pid in VAR_20:\n"", ""if pid is not None:\n"", ""FUNC_12()\n"", ""os.kill(pid, VAR_7.SIGTERM)\n"", ""atexit.register(FUNC_13)\n"", ""VAR_7.signal(VAR_7.SIGTERM, FUNC_13)\n"", ""if VAR_3:\n"", ""VAR_24 = Observer()\n"", ""while 1:\n"", ""for path in VAR_3:\n"", ""sleep(1)\n"", ""log.info('Keyboard interrupt, exiting')\n"", ""if not VAR_4:\n"", ""VAR_24.start()\n"", ""if VAR_3:\n"", ""print('Watching for changes under %s' % path)\n"", ""VAR_24.schedule(VAR_19, path=path, recursive=True)\n"", ""VAR_24.stop()\n"", ""sys.exit(0)\n"", ""VAR_24.join()\n""]",0
"[""@property...\n"", ""\""\""\""docstring\""\""\""\n"", ""return self._device_class\n""]",0
"[""@frappe.whitelist(allow_guest=True)...\n"", ""from frappe.www.contact import send_message as website_send_message\n"", ""VAR_4 = VAR_5 = None\n"", ""website_send_message(VAR_0, VAR_1, VAR_2)\n"", ""VAR_5 = frappe.db.sql('string'.format(email_id=sender))\n"", ""if not VAR_5:\n"", ""VAR_4 = frappe.db.get_value('Lead', dict(email_id=sender))\n"", ""VAR_6 = frappe.get_doc(dict(doctype='Opportunity', enquiry_from='Customer' if\n    customer else 'Lead', VAR_3='Open', title=subject, contact_email=sender,\n    to_discuss=message))\n"", ""if not VAR_4:\n"", ""if VAR_5:\n"", ""VAR_8 = frappe.get_doc(dict(doctype='Lead', email_id=sender, lead_name=\n    sender.split('@')[0].title())).insert(ignore_permissions=True)\n"", ""VAR_6.customer = VAR_5[0][0]\n"", ""if VAR_4:\n"", ""VAR_6.insert(ignore_permissions=True)\n"", ""VAR_6.lead = VAR_4\n"", ""VAR_6.lead = VAR_8.name\n"", ""VAR_7 = frappe.get_doc({'doctype': 'Communication', 'subject': VAR_0,\n    'content': VAR_1, 'sender': VAR_2, 'sent_or_received': 'Received',\n    'reference_doctype': 'Opportunity', 'reference_name': VAR_6.name})\n"", ""VAR_7.insert(ignore_permissions=True)\n"", ""return 'okay'\n""]",1
"[""def FUNC_5(self, VAR_0):...\n"", ""VAR_5 = ['GET', 'POST', 'PUT', 'DELETE', 'HEAD']\n"", ""VAR_6 = [m for m in VAR_5 if hasattr(self, 'render_%s' % m)] + ['OPTIONS']\n"", ""VAR_0.setHeader('Allow', ', '.join(VAR_6))\n"", ""from opennode.oms.endpoint.httprest.root import EmptyResponse\n"", ""return EmptyResponse\n""]",0
"[""def FUNC_0(self):...\n"", ""if not GenericRequest.test_success(self):\n"", ""return False\n"", ""self.get_submission_info()\n"", ""return False\n"", ""return True\n""]",0
"[""from osv import fields, osv\n"", ""from tools.translate import _\n"", ""VAR_0 = 'product.product'\n"", ""def FUNC_0(self, VAR_1, VAR_2, VAR_3, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_4 is None:\n"", ""VAR_4 = {}\n"", ""VAR_17 = self.pool.get('product.product').browse(VAR_1, VAR_2, VAR_3, VAR_4\n    =context)\n"", ""VAR_18 = (VAR_17.property_stock_account_input and VAR_17.\n    property_stock_account_input.id or False)\n"", ""if not VAR_18:\n"", ""VAR_18 = (VAR_17.categ_id.property_stock_account_input_categ and VAR_17.\n    categ_id.property_stock_account_input_categ.id or False)\n"", ""VAR_19 = (VAR_17.property_stock_account_output and VAR_17.\n    property_stock_account_output.id or False)\n"", ""if not VAR_19:\n"", ""VAR_19 = (VAR_17.categ_id.property_stock_account_output_categ and VAR_17.\n    categ_id.property_stock_account_output_categ.id or False)\n"", ""VAR_20 = (VAR_17.categ_id.property_stock_journal and VAR_17.categ_id.\n    property_stock_journal.id or False)\n"", ""VAR_21 = (VAR_17.categ_id.property_stock_variation and VAR_17.categ_id.\n    property_stock_variation.id or False)\n"", ""return {'stock_account_input': VAR_18, 'stock_account_output': VAR_19,\n    'stock_journal': VAR_20, 'property_stock_variation': VAR_21}\n""]",0
"[""def FUNC_24(self):...\n"", ""return self.finish()\n""]",0
"[""def FUNC_12(self, VAR_22):...\n"", ""\""\""\""docstring\""\""\""\n"", ""logging.warning(\""\""\""Authentication error.\n%s\""\""\"", VAR_22)\n"", ""self.abort(401, detail=str(error))\n""]",0
"[""@VAR_0.route('/register', methods=['GET', 'POST'])...\n"", ""VAR_11 = registerForm(request.form)\n"", ""if request.method == 'POST' and VAR_11.validate():\n"", ""VAR_8 = VAR_3.connection\n"", ""return render_template('register.html', VAR_11=form)\n"", ""VAR_9 = VAR_8.cursor()\n"", ""VAR_15 = VAR_11.username.data\n"", ""VAR_18 = VAR_11.firstname.data\n"", ""VAR_19 = VAR_11.lastname.data\n"", ""VAR_20 = VAR_11.email.data\n"", ""VAR_21 = sha256_crypt.hash(VAR_11.password.data)\n"", ""VAR_10 = VAR_9.execute(\n    'INSERT INTO users (first_name, last_name, username, password, email) VALUES (%s, %s, %s, %s, %s)'\n    , (VAR_18, VAR_19, VAR_15, VAR_21, VAR_20))\n"", ""VAR_8.commit()\n"", ""if str(VAR_10):\n"", ""return redirect(url_for('login'))\n""]",1
"[""def FUNC_5(VAR_17):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_23 = {}\n"", ""VAR_46 = reader.KeywordToken\n"", ""for VAR_76, v in acronymer.get_acronyms(VAR_17).items():\n"", ""VAR_23[VAR_46(VAR_76, type='acronym')] = v\n"", ""return VAR_23\n""]",0
"[""import undead\n"", ""import unittest\n"", ""def FUNC_0(self):...\n"", ""VAR_0 = 'string'\n"", ""VAR_1 = VAR_0.split('#')[-1]\n"", ""VAR_2 = Board(VAR_1)\n"", ""def FUNC_1(self):...\n"", ""VAR_3 = Walker()\n"", ""VAR_4 = 3\n"", ""VAR_5 = 0\n"", ""VAR_3.walk(VAR_2, VAR_4, VAR_5, 'east')\n"", ""if __name__ == '__main__':\n"", ""unittest.main()\n""]",1
"[""def FUNC_8(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_47 = re.compile('^.*[,();].*')\n"", ""VAR_48 = ['select', 'create', 'insert', 'delete', 'drop', 'update', 'case']\n"", ""VAR_49 = ['concat', 'concat_ws', 'if', 'ifnull', 'nullif', 'coalesce',\n    'connection_id', 'current_user', 'database', 'last_insert_id',\n    'session_user', 'system_user', 'user', 'version']\n"", ""def FUNC_26():...\n"", ""frappe.throw(_('Cannot use sub-query or function in fields'), frappe.DataError)\n"", ""for field in self.fields:\n"", ""if VAR_47.match(field):\n"", ""if any(keyword in field.lower() for keyword in VAR_48):\n"", ""FUNC_26()\n"", ""if any('{0}('.format(keyword) in field.lower() for keyword in VAR_49):\n"", ""FUNC_26()\n""]",1
"[""from __future__ import unicode_literals\n"", ""from django.db import models, migrations\n"", ""import django.db.models.deletion\n"", ""VAR_0 = [('userprofile', '0003_auto_20160728_1139'), ('course',\n    '0024_auto_20160726_1232')]\n"", ""VAR_1 = [migrations.CreateModel(name='StudentGroup', fields=[('id', models.\n    AutoField(verbose_name='ID', primary_key=True, auto_created=True,\n    serialize=False)), ('timestamp', models.DateTimeField(auto_now_add=True\n    )), ('course_instance', models.ForeignKey(related_name='groups', to=\n    'course.CourseInstance')), ('members', models.ManyToManyField(to=\n    'userprofile.UserProfile', related_name='groups'))], options={\n    'ordering': ['course_instance', 'timestamp']}, bases=(models.Model,)),\n    migrations.AddField(model_name='enrollment', name='selected_group',\n    field=models.ForeignKey(null=True, on_delete=django.db.models.deletion.\n    SET_NULL, default=None, blank=True, to='course.StudentGroup'),\n    preserve_default=True)]\n""]",1
"[""def FUNC_14(self):...\n"", ""return self._get_ancestors().values()\n""]",1
"[""def FUNC_3(self, VAR_18):...\n"", ""self.base.execute(VAR_18)\n""]",0
"[""def FUNC_7(self, VAR_13, VAR_4):...\n"", ""VAR_17, VAR_18 = VAR_13.compile(self.lhs)\n"", ""return \""(%s -> '%s')\"" % (VAR_17, self.key_name), VAR_18\n""]",1
"[""def FUNC_9(VAR_1, VAR_8, **VAR_6):...\n"", ""import sql\n"", ""VAR_38 = '/etc/keepalived/keepalived.conf' if VAR_6.get('keepalived'\n    ) else sql.get_setting('haproxy_config_path')\n"", ""VAR_37 = FUNC_8(VAR_1)\n"", ""VAR_74 = VAR_37.open_sftp()\n"", ""VAR_37 = str(e)\n"", ""VAR_74.get(VAR_38, VAR_8)\n"", ""return VAR_37\n"", ""VAR_74.close()\n"", ""VAR_37.close()\n""]",0
"[""from django.db.models.signals import post_save, post_delete\n"", ""from lib.cache import CachedAbstract\n"", ""from .models import Notification\n"", ""VAR_3 = 'notifications'\n"", ""def __init__(self, VAR_4):...\n"", ""super().__init__(VAR_4)\n"", ""def FUNC_1(self, VAR_4, VAR_5=None):...\n"", ""if not VAR_4 or not VAR_4.is_authenticated():\n"", ""return {'count': 0, 'notifications': []}\n"", ""def FUNC_4(VAR_6):...\n"", ""VAR_8 = VAR_6.submission.exercise if VAR_6.submission else None\n"", ""return {'id': VAR_6.id, 'submission_id': VAR_6.submission.id if VAR_6.\n    submission else 0, 'name': '{} {}, {}'.format(VAR_6.course_instance.\n    course.code, str(VAR_8.parent) if VAR_8 and VAR_8.parent else VAR_6.\n    course_instance.instance_name, str(VAR_8) if VAR_8 else VAR_6.subject),\n    'link': VAR_6.get_display_url()}\n""]",1
"[""def FUNC_16(self):...\n"", ""VAR_6 = None\n"", ""VAR_6 = tempfile.NamedTemporaryFile(delete=False)\n"", ""if VAR_6:\n"", ""VAR_6.close()\n"", ""os.remove(VAR_6.name)\n"", ""os.chmod(VAR_6.name, stat.S_IREAD)\n"", ""self._mox.StubOutWithMock(url_helper, 'UrlOpen')\n"", ""url_helper.UrlOpen(mox.IgnoreArg(), method='GET').AndReturn('data')\n"", ""self._mox.ReplayAll()\n"", ""self.assertFalse(url_helper.DownloadFile(VAR_6.name, 'http://www.fakeurl.com'))\n"", ""self._mox.VerifyAll()\n""]",0
"[""@property...\n"", ""return FUNC_0(self.file).st_mtime\n""]",0
"[""def FUNC_34(VAR_16, VAR_22, VAR_28, VAR_23):...\n"", ""VAR_90 = FUNC_33(VAR_16, VAR_22, VAR_23)\n"", ""if FUNC_13(VAR_16, VAR_28, VAR_18=tournaments):\n"", ""return True\n"", ""return False\n""]",1
"[""def FUNC_6(self, VAR_1):...\n"", ""self.cursor.execute('SELECT count(id) FROM projects where id = %s' % VAR_1)\n"", ""return self.cursor.fetchall()[0][0] == 1\n""]",1
"[""def FUNC_29(self):...\n"", ""if VAR_54.flags.in_import:\n"", ""return\n"", ""for VAR_25 in self.meta.get_select_fields():\n"", ""if VAR_25.fieldname == 'naming_series' or not (self.get(VAR_25.fieldname) and\n"", ""VAR_56 = (VAR_25.options or '').split('\\n')\n"", ""if not filter(None, VAR_56):\n"", ""self.set(VAR_25.fieldname, cstr(self.get(VAR_25.fieldname)).strip())\n"", ""VAR_9 = self.get(VAR_25.fieldname)\n"", ""if VAR_9 not in VAR_56 and not (VAR_54.flags.in_test and VAR_9.startswith(\n"", ""VAR_67 = _('Row #{0}:').format(self.idx) if self.get('parentfield') else ''\n"", ""VAR_37 = _(self.meta.get_label(VAR_25.fieldname))\n"", ""VAR_68 = '\"", \""'.join(_(each) for each in VAR_56)\n"", ""VAR_54.throw(_('{0} {1} cannot be \""{2}\"". It should be one of \""{3}\""').format\n    (VAR_67, VAR_37, VAR_9, VAR_68))\n""]",0
"[""def FUNC_0(self):...\n"", ""def FUNC_33(self):...\n"", ""@api.public...\n"", ""@api.require(lambda : True)...\n""]",0
"[""def FUNC_18(self, VAR_3, VAR_4, VAR_5, VAR_11=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return self.__make_proxy('make_proxy', VAR_3, (VAR_4, VAR_5), dict(VAR_11=\n    options))\n""]",0
"[""def __lt__(self, VAR_11):...\n"", ""return self.rule.__lt__(VAR_11.rule)\n""]",0
"[""def FUNC_1(VAR_1):...\n"", ""VAR_6 = VAR_5.mogrify(\n    'SELECT * FROM articles WHERE index IN %s ORDER BY last_submitted DESC',\n    (tuple(VAR_1),))\n"", ""VAR_5.execute(VAR_6)\n"", ""VAR_19 = VAR_5.fetchall()\n"", ""return VAR_19\n""]",0
"[""@auth.before_request...\n"", ""g.user = current_user\n""]",0
"[""def FUNC_0(self):...\n"", ""VAR_2 = sql.connect(self.dbStr)\n"", ""VAR_3 = VAR_2.cursor()\n"", ""VAR_3.execute('SELECT * FROM {tn} WHERE {upc}={my_upc}'.format(tn=self.\n    table_name, cn=self.column_2, upc=self.column_2, my_upc=self.some_upc))\n"", ""VAR_4 = VAR_3.fetchone()\n"", ""return VAR_4\n""]",1
"[""def FUNC_12(self, VAR_10=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_30 = vars(self.parse_known_args(VAR_15=True)[0])\n"", ""VAR_13 = VAR_30.get('image_mode', None)\n"", ""if VAR_13 is not None and VAR_13 != 'none':\n"", ""self.add_image_args(VAR_13)\n"", ""VAR_12 = VAR_30.get('task', None)\n"", ""if VAR_12 is not None:\n"", ""self.add_task_args(VAR_12)\n"", ""VAR_31 = VAR_30.get('evaltask', None)\n"", ""if VAR_31 is not None:\n"", ""self.add_task_args(VAR_31)\n"", ""VAR_11 = VAR_30.get('model', None)\n"", ""if VAR_11 is not None:\n"", ""self.add_model_subargs(VAR_11)\n"", ""self.set_defaults(**self._defaults)\n""]",1
"[""def FUNC_15():...\n"", ""if VAR_14 not in self._timers:\n"", ""return\n"", ""self._timers.remove(VAR_14)\n"", ""VAR_10()\n"", ""logging.exception('Timer callback failed')\n""]",0
"[""from __future__ import unicode_literals\n"", ""import frappe, unittest\n"", ""from frappe.model.db_query import DatabaseQuery\n"", ""from frappe.desk.reportview import get_filters_cond\n"", ""def FUNC_1(self):...\n"", ""self.assertTrue({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    limit_page_length=None))\n"", ""def FUNC_2(self):...\n"", ""self.assertTrue({'name': 'DocType', 'issingle': 0} in DatabaseQuery(\n    'DocType').execute(fields=['name', 'issingle'], limit_page_length=None))\n"", ""def FUNC_3(self):...\n"", ""self.assertFalse({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    filters=[['DocType', 'name', 'like', 'J%']]))\n"", ""def FUNC_4(self):...\n"", ""self.assertFalse({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    filters=[{'name': ['like', 'J%']}]))\n"", ""def FUNC_5(self):...\n"", ""self.assertFalse({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    filters={'name': ['like', 'J%']}))\n"", ""def FUNC_6(self):...\n"", ""self.assertTrue({'name': 'DocField'} in DatabaseQuery('DocType').execute(\n    filters={'name': 'DocField'}))\n"", ""def FUNC_7(self):...\n"", ""self.assertFalse(DatabaseQuery('DocType').execute(filters={'name': ['in',\n    None]}))\n"", ""self.assertTrue({'name': 'DocType'} in DatabaseQuery('DocType').execute(\n    filters={'name': ['not in', None]}))\n"", ""for result in [{'name': 'DocType'}, {'name': 'DocField'}]:\n"", ""self.assertTrue(result in DatabaseQuery('DocType').execute(filters={'name':\n    ['in', 'DocType,DocField']}))\n"", ""for result in [{'name': 'DocType'}, {'name': 'DocField'}]:\n"", ""self.assertFalse(result in DatabaseQuery('DocType').execute(filters={'name':\n    ['not in', 'DocType,DocField']}))\n"", ""def FUNC_8(self):...\n"", ""VAR_3 = DatabaseQuery('DocField').execute(filters={'parent': 'DocType'},\n    fields=['fieldname', 'fieldtype'], or_filters=[{'fieldtype': 'Table'},\n    {'fieldtype': 'Select'}])\n"", ""self.assertTrue({'fieldtype': 'Table', 'fieldname': 'fields'} in VAR_3)\n"", ""self.assertTrue({'fieldtype': 'Select', 'fieldname': 'document_type'} in VAR_3)\n"", ""self.assertFalse({'fieldtype': 'Check', 'fieldname': 'issingle'} in VAR_3)\n"", ""def FUNC_9(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""frappe.db.sql('delete from tabEvent')\n"", ""VAR_4 = FUNC_0()\n"", ""VAR_5 = FUNC_0(VAR_1='2016-07-05 23:59:59')\n"", ""VAR_6 = FUNC_0(VAR_1='2016-07-06 00:00:00')\n"", ""VAR_7 = FUNC_0(VAR_1='2016-07-07 23:59:59')\n"", ""VAR_8 = FUNC_0(VAR_1='2016-07-08 00:00:01')\n"", ""VAR_3 = DatabaseQuery('Event').execute(filters={'starts_on': ['between',\n    None]}, fields=['name'])\n"", ""self.assertTrue({'name': VAR_5.name} not in VAR_3)\n"", ""VAR_3 = DatabaseQuery('Event').execute(filters={'starts_on': ['between', [\n    '2016-07-06', '2016-07-07']]}, fields=['name'])\n"", ""self.assertTrue({'name': VAR_6.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_7.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_5.name} not in VAR_3)\n"", ""self.assertTrue({'name': VAR_8.name} not in VAR_3)\n"", ""VAR_3 = DatabaseQuery('Event').execute(filters={'starts_on': ['between', [\n    '2016-07-07']]}, fields=['name'])\n"", ""self.assertTrue({'name': VAR_7.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_8.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_4.name} in VAR_3)\n"", ""self.assertTrue({'name': VAR_5.name} not in VAR_3)\n"", ""self.assertTrue({'name': VAR_6.name} not in VAR_3)\n"", ""def FUNC_10(self):...\n"", ""frappe.set_user('test1@example.com')\n"", ""self.assertRaises(frappe.PermissionError, get_filters_cond, 'DocType', dict\n    (istable=1), [])\n"", ""self.assertTrue(get_filters_cond('DocType', dict(istable=1), [],\n    ignore_permissions=True))\n"", ""frappe.set_user('Administrator')\n"", ""def FUNC_11(self):...\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name', 'issingle, version()'], limit_start=0, limit_page_length=1)\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name',\n    'issingle, IF(issingle=1, (select name from tabUser), count(name))'],\n    limit_start=0, limit_page_length=1)\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name', 'issingle, (select count(*) from tabSessions)'],\n    limit_start=0, limit_page_length=1)\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name',\n    \""issingle, SELECT LOCATE('', `tabUser`.`user`) AS user;\""], limit_start=\n    0, limit_page_length=1)\n"", ""self.assertRaises(frappe.DataError, DatabaseQuery('DocType').execute,\n    fields=['name',\n    'issingle, IF(issingle=1, (SELECT name from tabUser), count(*))'],\n    limit_start=0, limit_page_length=1)\n"", ""VAR_3 = DatabaseQuery('DocType').execute(fields=['name', 'issingle',\n    'count(name)'], limit_start=0, limit_page_length=1)\n"", ""self.assertTrue('count(name)' in VAR_3[0])\n"", ""VAR_3 = DatabaseQuery('DocType').execute(fields=['name', 'issingle',\n    \""locate('', name) as _relevance\""], limit_start=0, limit_page_length=1)\n"", ""self.assertTrue('_relevance' in VAR_3[0])\n"", ""VAR_3 = DatabaseQuery('DocType').execute(fields=['name', 'issingle',\n    'date(creation) as creation'], limit_start=0, limit_page_length=1)\n"", ""self.assertTrue('creation' in VAR_3[0])\n"", ""VAR_3 = DatabaseQuery('DocType').execute(fields=['name', 'issingle',\n    'datediff(modified, creation) as date_diff'], limit_start=0,\n    limit_page_length=1)\n"", ""self.assertTrue('date_diff' in VAR_3[0])\n"", ""def FUNC_0(VAR_0='_Test Event', VAR_1=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""from frappe.utils import get_datetime\n"", ""VAR_2 = frappe.get_doc({'doctype': 'Event', 'subject': VAR_0, 'event_type':\n    'Public', 'starts_on': get_datetime(VAR_1)}).insert(ignore_permissions=True\n    )\n"", ""return VAR_2\n""]",1
"[""__packagename__ = 'dwave-hybrid'\n"", ""__title__ = 'D-Wave Hybrid'\n"", ""__version__ = '0.1.4'\n"", ""__author__ = 'D-Wave Systems Inc.'\n"", ""__authoremail__ = 'radomir@dwavesys.com'\n"", ""__description__ = 'Hybrid Asynchronous Decomposition Solver Framework'\n"", ""__url__ = 'https://github.com/dwavesystems/dwave-hybrid'\n"", ""__license__ = 'Apache 2.0'\n"", ""__copyright__ = '2018, D-Wave Systems Inc.'\n""]",1
"[""@staticmethod...\n"", ""if not VAR_1:\n"", ""if not VAR_5:\n"", ""VAR_5 = CLASS_0.get_report(VAR_1)['analysis']\n"", ""VAR_9 = {'data': [], 'status': True}\n"", ""for VAR_17 in VAR_5.get('behavior', {}).get('generic', []):\n"", ""VAR_9['data'].append({'process_name': VAR_17['process_name'], 'pid': VAR_17\n    ['pid']})\n"", ""VAR_9['data'] = sorted(VAR_9['data'], key=lambda k: k['process_name'])\n"", ""return VAR_9\n""]",0
"[""__author__ = 'Johannes Köster'\n"", ""__copyright__ = 'Copyright 2015, Johannes Köster'\n"", ""__email__ = 'koester@jimmy.harvard.edu'\n"", ""__license__ = 'MIT'\n"", ""import re\n"", ""import os\n"", ""import sys\n"", ""import signal\n"", ""import json\n"", ""import urllib\n"", ""from collections import OrderedDict\n"", ""from itertools import filterfalse, chain\n"", ""from functools import partial\n"", ""from operator import attrgetter\n"", ""from snakemake.logging import logger, format_resources, format_resource_names\n"", ""from snakemake.rules import Rule, Ruleorder\n"", ""from snakemake.exceptions import RuleException, CreateRuleException, UnknownRuleException, NoRulesException, print_exception, WorkflowError\n"", ""from snakemake.shell import shell\n"", ""from snakemake.dag import DAG\n"", ""from snakemake.scheduler import JobScheduler\n"", ""from snakemake.parser import parse\n"", ""import snakemake.io\n"", ""from snakemake.io import protected, temp, temporary, expand, dynamic, glob_wildcards, flag, not_iterable, touch\n"", ""from snakemake.persistence import Persistence\n"", ""from snakemake.utils import update_config\n"", ""def __init__(self, VAR_1=None, VAR_2=None, VAR_3=None, VAR_4=None, VAR_5=...\n"", ""\""\""\""docstring\""\""\""\n"", ""self._rules = OrderedDict()\n"", ""self.first_rule = None\n"", ""self._workdir = None\n"", ""self.overwrite_workdir = VAR_6\n"", ""self.workdir_init = os.path.abspath(os.curdir)\n"", ""self._ruleorder = Ruleorder()\n"", ""self._localrules = set()\n"", ""self.linemaps = dict()\n"", ""self.rule_count = 0\n"", ""self.basedir = os.path.dirname(VAR_1)\n"", ""self.snakefile = os.path.abspath(VAR_1)\n"", ""self.snakemakepath = VAR_2\n"", ""self.included = []\n"", ""self.included_stack = []\n"", ""self.jobscript = VAR_3\n"", ""self.persistence = None\n"", ""self.global_resources = None\n"", ""self.globals = globals()\n"", ""self._subworkflows = dict()\n"", ""self.overwrite_shellcmd = VAR_4\n"", ""self.overwrite_config = VAR_5\n"", ""self.overwrite_configfile = VAR_7\n"", ""self.config_args = VAR_8\n"", ""self._onsuccess = lambda log: None\n"", ""self._onerror = lambda log: None\n"", ""self.debug = VAR_9\n"", ""VAR_85 = dict()\n"", ""VAR_85.update(self.overwrite_config)\n"", ""VAR_86 = CLASS_3()\n"", ""@property...\n"", ""return self._subworkflows.values()\n""]",1
"[""@property...\n"", ""if self._hosts is None:\n"", ""self._hosts = set(self.hosts)\n"", ""return self._hosts\n""]",0
"[""\""\""\""\nFlask App for Todo List MVP\n\""\""\""\n"", ""from flask import abort, Flask, jsonify\n"", ""from flask import render_template, request, url_for\n"", ""import json\n"", ""from models import storage, Task, User, REQUIRED, PORT, HOST\n"", ""import requests\n"", ""from uuid import uuid4\n"", ""VAR_0 = Flask(__name__)\n"", ""VAR_0.url_map.strict_slashes = False\n"", ""VAR_1 = ['Not a JSON', 'Missing required information', 'Missing id',\n    'Wrong id type']\n"", ""def FUNC_0(VAR_2, VAR_3, VAR_4):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_12 = {VAR_2: VAR_3, 'status_code': VAR_4}\n"", ""VAR_13 = jsonify(VAR_3)\n"", ""return VAR_13\n""]",0
"[""def FUNC_0():...\n"", ""VAR_1 = psycopg2.connect('dbname=forum')\n"", ""VAR_2 = VAR_1.cursor()\n"", ""VAR_2.execute('SELECT time, content FROM posts ORDER BY time desc')\n"", ""VAR_3 = ({'content': str(row[1]), 'time': str(row[0])} for row in VAR_2.\n    fetchall())\n"", ""VAR_1.close()\n"", ""return VAR_3\n""]",1
"[""def FUNC_6(self, VAR_11):...\n"", ""return utils.sanitize_url(VAR_11)\n""]",0
"[""def FUNC_1(self, VAR_2):...\n"", ""VAR_4 = 'string' % VAR_2\n"", ""VAR_5 = sql.queryDB(self.conn, VAR_4)\n"", ""return VAR_5\n""]",1
"[""def FUNC_2(self):...\n"", ""VAR_15 = time.time()\n"", ""print('=' * 25)\n"", ""print(\""\""\""\n[*]Target: {}\n[*]Date: {}\""\""\"".format(VAR_6.get(), datetime.now().\n    strftime('%d/%m/%Y %H:%M:%S')))\n"", ""VAR_16 = [VAR_6.get()]\n"", ""if VAR_14.get() == 'On':\n"", ""VAR_16 += bane.crawl(VAR_6.get(), bypass=True)\n"", ""VAR_17 = VAR_12.get()\n"", ""if len(VAR_17) == 0:\n"", ""VAR_17 = None\n"", ""if VAR_8.get() == 'GET':\n"", ""VAR_21 = True\n"", ""if VAR_8.get() == 'POST':\n"", ""VAR_22 = False\n"", ""VAR_21 = False\n"", ""VAR_21 = True\n"", ""VAR_18 = False\n"", ""VAR_22 = True\n"", ""VAR_22 = True\n"", ""if VAR_13.get() == 'On':\n"", ""VAR_18 = True\n"", ""VAR_19 = None\n"", ""VAR_20 = VAR_7.get()\n"", ""if len(VAR_20) > 0:\n"", ""VAR_19 = VAR_20\n"", ""for x in VAR_16:\n"", ""if VAR_0 == True:\n"", ""print(\""\""\""[*]Test was finished at: {}\n[*]Duration: {} seconds\n\""\""\"".format(\n    datetime.now().strftime('%d/%m/%Y %H:%M:%S'), int(time.time() - VAR_15)))\n"", ""print('[*]URL: {}'.format(x))\n"", ""print('=' * 25)\n"", ""bane.xss(x, VAR_11=payload.get(), VAR_12=pr, VAR_21=get, VAR_22=post,\n    VAR_10=user_agent.get(), VAR_18=fresh, VAR_7=ck)\n""]",0
"[""@staticmethod...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_16 = []\n"", ""for VAR_35 in VAR_3:\n"", ""if VAR_35:\n"", ""return VAR_16\n"", ""VAR_35 = str(VAR_35).strip()\n"", ""VAR_16.append(VAR_35)\n"", ""log.info('Looking up collation for %s', VAR_35)\n"", ""VAR_36 = 'SELECT right_tag FROM tag_table WHERE wrong_tag=\""{}\""'.format(VAR_35)\n"", ""VAR_37 = db.execute_query(VAR_36)\n"", ""if not VAR_37:\n"", ""log.error(\""Can't check the tag because of the db error\"")\n"", ""if VAR_37.rowcount:\n"", ""log.warning('Tag will stay as is.')\n"", ""VAR_35 = VAR_37.fetchone()[0]\n"", ""log.info('Tag after looking up in tag_tables - %s.', VAR_35)\n""]",1
"[""def FUNC_20(self, VAR_21):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_21 = VAR_21.rstrip('/')\n"", ""VAR_60 = os.path.basename(VAR_21)\n"", ""VAR_61 = os.path.dirname(VAR_21)\n"", ""VAR_58 = self.getfile(VAR_21, VAR_23=False)\n"", ""if VAR_58 == False:\n"", ""if VAR_58[VAR_2] != VAR_12:\n"", ""if len(self.get_path(VAR_21)) > 0:\n"", ""VAR_62 = self.get_path(VAR_61, VAR_23=True)\n"", ""for i in VAR_62[:]:\n"", ""if i[VAR_1] == VAR_60:\n"", ""return False\n"", ""VAR_62.remove(i)\n"", ""return True\n""]",0
"[""def FUNC_1(VAR_1):...\n"", ""VAR_4 = os.path.dirname(VAR_1)\n"", ""VAR_5 = os.path.splitext(os.path.basename(VAR_1))[0]\n"", ""VAR_6 = [VAR_5] if VAR_5 != '__init__' else []\n"", ""VAR_7 = None\n"", ""while VAR_4 != VAR_7 and FUNC_0(VAR_4):\n"", ""VAR_7 = os.path.dirname(VAR_4)\n"", ""return VAR_4, '.'.join(reversed(VAR_6))\n"", ""VAR_6.append(os.path.basename(VAR_4))\n"", ""VAR_4 = VAR_7\n""]",1
"[""\""\""\""string\""\""\""\n"", ""from builtins import str\n"", ""import json\n"", ""import logging\n"", ""import socket\n"", ""import threading\n"", ""import time\n"", ""from mobly.controllers.android_device_lib import adb\n"", ""from mobly.controllers.android_device_lib import callback_handler\n"", ""VAR_0 = 15\n"", ""VAR_1 = -1\n"", ""VAR_2 = 60\n"", ""VAR_3 = callback_handler.MAX_TIMEOUT\n"", ""\""\""\""Raised when the app is not able to be started.\""\""\""\n"", ""\""\""\""Raised when remote API reports an error.\""\""\""\n"", ""\""\""\""Raised when there is some error in exchanging data with server.\""\""\""\n"", ""VAR_4 = 'No response from handshake.'\n"", ""VAR_5 = 'No response from server.'\n"", ""VAR_6 = 'Mismatched API id.'\n"", ""\""\""\""string\""\""\""\n"", ""VAR_7 = 'initiate'\n"", ""VAR_8 = 'continue'\n"", ""\""\""\""string\""\""\""\n"", ""def __init__(self, VAR_9, VAR_10, VAR_11, VAR_12, VAR_13=logging.getLogger()):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.host_port = VAR_9\n"", ""self.device_port = VAR_10\n"", ""self.app_name = VAR_11\n"", ""self.uid = None\n"", ""self._adb = VAR_12\n"", ""self._client = None\n"", ""self._conn = None\n"", ""self._counter = None\n"", ""self._lock = threading.Lock()\n"", ""self._event_client = None\n"", ""self._log = VAR_13\n"", ""def __del__(self):...\n"", ""self.close()\n"", ""def FUNC_0(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""def FUNC_1(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""def FUNC_2(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""def FUNC_3(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""def FUNC_4(self, VAR_14=VAR_0):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.check_app_installed()\n"", ""self._do_start_app()\n"", ""for _ in range(VAR_14):\n"", ""time.sleep(1)\n"", ""def FUNC_5(self, VAR_15=VAR_1, VAR_16=CLASS_4.INIT):...\n"", ""if self._is_app_running():\n"", ""\""\""\""docstring\""\""\""\n"", ""self._log.debug('Successfully started %s', self.app_name)\n"", ""self._counter = self._id_counter()\n"", ""return\n"", ""self._conn = socket.create_connection(('127.0.0.1', self.host_port), VAR_2)\n"", ""self._conn.settimeout(VAR_3)\n"", ""self._client = self._conn.makefile(mode='brw')\n"", ""VAR_22 = self._cmd(VAR_16, VAR_15)\n"", ""if not VAR_22:\n"", ""VAR_23 = json.loads(str(VAR_22, encoding='utf8'))\n"", ""if VAR_23['status']:\n"", ""self.uid = VAR_23['uid']\n"", ""self.uid = VAR_1\n"", ""def FUNC_6(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if self._conn:\n"", ""self._conn.close()\n"", ""def FUNC_7(self, VAR_17):...\n"", ""self._conn = None\n"", ""\""\""\""docstring\""\""\""\n"", ""return self._adb.shell(VAR_17).decode('utf-8')\n"", ""if e.ret_code == 1 and not e.stdout and not e.stderr:\n"", ""def FUNC_8(self, VAR_18, VAR_15=None):...\n"", ""return False\n"", ""\""\""\""docstring\""\""\""\n"", ""if not VAR_15:\n"", ""VAR_15 = self.uid\n"", ""self._client.write(json.dumps({'cmd': VAR_18, 'uid': VAR_15}).encode('utf8'\n    ) + b'\\n')\n"", ""self._client.flush()\n"", ""return self._client.readline()\n""]",1
"[""def FUNC_8(self, VAR_9, VAR_10=None, VAR_11=None):...\n"", ""get_and_check_project(VAR_9, VAR_11)\n"", ""VAR_28 = self.queryset.get(VAR_10=pk, VAR_1=project_pk)\n"", ""VAR_26 = CLASS_1(VAR_28)\n"", ""return Response(VAR_26.data)\n""]",0
"[""def FUNC_2(self):...\n"", ""CLASS_4.ScenarioMaker().given_a_deep_link_domain('pachatary://app'\n    ).given_a_dynamic_link('').when_call_root_redirect(\n    ).then_response_should_be_a_redirect_to('pachatary://app/')\n""]",1
"[""\""\""\""string\""\""\""\n"", ""import copy\n"", ""from flask import current_app, session\n"", ""from flask.ext.login import current_user\n"", ""from invenio.ext.sqlalchemy.utils import session_manager\n"", ""VAR_0 = dict(title='ORCID', description=\n    'Connecting Research and Researchers.', icon='', authorized_handler=\n    'invenio.modules.oauthclient.handlers:authorized_signup_handler',\n    disconnect_handler=\n    'invenio.modules.oauthclient.handlers:disconnect_handler',\n    signup_handler=dict(info=\n    'invenio.modules.oauthclient.contrib.orcid:account_info', setup=\n    'invenio.modules.oauthclient.contrib.orcid:account_setup', view=\n    'invenio.modules.oauthclient.handlers:signup_handler'), params=dict(\n    request_token_params={'scope': '/authenticate'}, base_url=\n    'https://pub.orcid.com/', request_token_url=None, access_token_url=\n    'https://pub.orcid.org/oauth/token', access_token_method='POST',\n    authorize_url='https://orcid.org/oauth/authorize#show_login', app_key=\n    'ORCID_APP_CREDENTIALS', content_type='application/json'))\n"", ""\""\""\"" ORCID Remote Application. \""\""\""\n"", ""VAR_1 = copy.deepcopy(VAR_0)\n"", ""\""\""\""ORCID Sandbox Remote Application.\""\""\""\n"", ""VAR_1['params'].update(dict(base_url='https://api.sandbox.orcid.org/',\n    access_token_url='https://api.sandbox.orcid.org/oauth/token',\n    authorize_url='https://sandbox.orcid.org/oauth/authorize#show_login'))\n"", ""def FUNC_0(VAR_2, VAR_3):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_5 = dict(external_id=resp.get('orcid'), external_method='orcid')\n"", ""return VAR_5\n""]",1
"[""\""\""\""string\""\""\""\n"", ""from __future__ import print_function\n"", ""import os\n"", ""from six import iteritems\n"", ""import config as bconfig\n"", ""from invenio.legacy.bibclassify import ontology_reader as reader\n"", ""import text_extractor as extractor\n"", ""import text_normalizer as normalizer\n"", ""import keyword_analyzer as keyworder\n"", ""import acronym_analyzer as acronymer\n"", ""from invenio.utils.url import make_user_agent_string\n"", ""from invenio.utils.text import encode_for_xml\n"", ""VAR_0 = bconfig.get_logger('bibclassify.engine')\n"", ""def FUNC_0(VAR_1, VAR_2, VAR_3='text', VAR_4=bconfig....\n"", ""\""\""\""docstring\""\""\""\n"", ""def FUNC_30():...\n"", ""if VAR_3 == 'text':\n"", ""print('Input file: %s' % VAR_75)\n"", ""VAR_52 = FUNC_2(VAR_15, VAR_2, VAR_3=output_mode, VAR_4=output_limit, VAR_5\n    =spires, VAR_6=match_mode, VAR_7=no_cache, VAR_8=with_author_keywords,\n    VAR_9=rebuild_cache, VAR_10=only_core_tags, VAR_11=extract_acronyms)\n"", ""if VAR_12:\n"", ""return VAR_52\n"", ""if isinstance(VAR_52, dict):\n"", ""for VAR_84 in VAR_52:\n"", ""for entry in VAR_1:\n"", ""print(VAR_52[VAR_84])\n"", ""VAR_0.info('Trying to read input file %s.' % entry)\n"", ""def FUNC_1(VAR_14, VAR_2, VAR_3='text', VAR_4=bconfig....\n"", ""VAR_15 = None\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_75 = ''\n"", ""VAR_0.info('Analyzing keywords for local file %s.' % VAR_14)\n"", ""if os.path.isdir(entry):\n"", ""VAR_15 = extractor.text_lines_from_local_file(VAR_14)\n"", ""for VAR_40 in os.listdir(entry):\n"", ""if os.path.isfile(entry):\n"", ""return FUNC_2(VAR_15, VAR_2, VAR_3=output_mode, VAR_4=output_limit, VAR_5=\n    spires, VAR_6=match_mode, VAR_7=no_cache, VAR_8=with_author_keywords,\n    VAR_9=rebuild_cache, VAR_10=only_core_tags, VAR_11=extract_acronyms)\n"", ""if VAR_40.startswith('.'):\n"", ""VAR_15 = extractor.text_lines_from_local_file(entry)\n"", ""VAR_15 = extractor.text_lines_from_url(entry, user_agent=\n    make_user_agent_string('BibClassify'))\n"", ""VAR_40 = os.path.join(entry, VAR_40)\n"", ""if VAR_15:\n"", ""if VAR_15:\n"", ""if os.path.isfile(VAR_40):\n"", ""VAR_75 = os.path.basename(entry)\n"", ""VAR_75 = entry.split('/')[-1]\n"", ""VAR_15 = extractor.text_lines_from_local_file(VAR_40)\n"", ""FUNC_30()\n"", ""FUNC_30()\n"", ""if VAR_15:\n"", ""VAR_75 = VAR_40\n"", ""FUNC_30()\n""]",1
"[""def FUNC_0(self):...\n"", ""for path, directories, files in self.walk_fn(self.base_directory_path):\n"", ""VAR_3 = relpath(path, self.base_directory_path)\n"", ""VAR_4 = basename(path)\n"", ""if VAR_3 != '.' and not self.directory_filter(VAR_4):\n"", ""for file in files:\n"", ""if not self.file_filter(file):\n"", ""yield join(path, file)\n""]",1
"[""@VAR_0.route('/css/<path:filename>')...\n"", ""return send_from_directory('css', VAR_5)\n""]",1
"[""def FUNC_13(VAR_6):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if isinstance(VAR_6, CLASS_1):\n"", ""return VAR_6.literal\n"", ""if isinstance(VAR_6, six.string_types):\n"", ""VAR_6 = VAR_6.replace(\""'\"", \""\\\\'\"")\n"", ""if isinstance(VAR_6, datetime):\n"", ""return u\""'{}'\"".format(VAR_6)\n"", ""VAR_6 = VAR_6.replace(tzinfo=None, microsecond=0)\n"", ""if isinstance(VAR_6, VAR_59):\n"", ""return \""toDateTime('{}')\"".format(VAR_6.isoformat())\n"", ""return \""toDate('{}')\"".format(VAR_6.isoformat())\n"", ""if isinstance(VAR_6, (list, tuple)):\n"", ""return u'({})'.format(', '.join(FUNC_13(v) for v in VAR_6))\n"", ""if isinstance(VAR_6, numbers.Number):\n"", ""return str(VAR_6)\n"", ""if VAR_6 is None:\n"", ""return ''\n""]",1
"[""def FUNC_1(VAR_6, VAR_7, VAR_8):...\n"", ""VAR_8.debug('Running component check for %s' % VAR_6['name'])\n"", ""VAR_33 = len(VAR_6['cmd']) > 1 and 'check' in VAR_6['cmd'][1]\n"", ""VAR_9 = FUNC_6(VAR_7, VAR_6['name'])\n"", ""if VAR_9:\n"", ""VAR_56 = FUNC_2(VAR_9)\n"", ""VAR_8.debug('%s window is not running. Running custom check' % VAR_6['name'])\n"", ""VAR_8.debug('Found window pid: %s' % VAR_56)\n"", ""if VAR_33 and FUNC_0(VAR_6):\n"", ""VAR_57 = []\n"", ""VAR_8.debug('Component was not started by Hyperion, but the check succeeded')\n"", ""VAR_8.debug(\n    'Window not running and no check command is available or it failed: returning false'\n    )\n"", ""for entry in VAR_56:\n"", ""return CLASS_0.STARTED_BY_HAND\n"", ""return CLASS_0.STOPPED\n"", ""VAR_57.extend(Process(entry).children(recursive=True))\n"", ""VAR_58 = [p.pid for p in VAR_57]\n"", ""VAR_8.debug('Window is running %s child processes' % len(VAR_58))\n"", ""if len(VAR_58) < 3:\n"", ""VAR_8.debug(\n    'Main window process has finished. Running custom check if available')\n"", ""if VAR_33 and FUNC_0(VAR_6):\n"", ""if VAR_33 and FUNC_0(VAR_6):\n"", ""VAR_8.debug('Check succeeded')\n"", ""if not VAR_33:\n"", ""VAR_8.debug('Process terminated but check was successful')\n"", ""VAR_8.debug('Check failed or no check available: returning false')\n"", ""return CLASS_0.RUNNING\n"", ""VAR_8.debug(\n    'No custom check specified and got sufficient pid amount: returning true')\n"", ""VAR_8.debug('Check failed: returning false')\n"", ""return CLASS_0.STOPPED_BUT_SUCCESSFUL\n"", ""return CLASS_0.STOPPED\n"", ""return CLASS_0.RUNNING\n"", ""return CLASS_0.STOPPED\n""]",1
"[""@ndb.transactional...\n"", ""VAR_10 = WfSuspectedCL.Get(VAR_0, VAR_1)\n"", ""if not VAR_10 or not VAR_10.builds:\n"", ""return False\n"", ""if not VAR_10.builds.get(VAR_2):\n"", ""return True\n"", ""VAR_10.builds[VAR_2]['status'] = VAR_3\n"", ""VAR_11 = True\n"", ""VAR_12 = True\n"", ""VAR_13 = False\n"", ""for build in VAR_10.builds.values():\n"", ""if build['status'] is None:\n"", ""if VAR_13:\n"", ""VAR_13 = True\n"", ""if build['status'] == suspected_cl_status.CORRECT:\n"", ""VAR_10.status = suspected_cl_status.PARTIALLY_TRIAGED\n"", ""if VAR_11:\n"", ""VAR_12 = False\n"", ""VAR_11 = False\n"", ""VAR_10.updated_time = VAR_4 or time_util.GetUTCNow()\n"", ""VAR_10.status = suspected_cl_status.CORRECT\n"", ""if VAR_12:\n"", ""VAR_10.put()\n"", ""VAR_10.status = suspected_cl_status.INCORRECT\n"", ""VAR_10.status = suspected_cl_status.PARTIALLY_CORRECT\n"", ""return True\n""]",0
"[""@property...\n"", ""return await CLASS_0.filter(VAR_8=self.id).count()\n""]",0
"[""def FUNC_29(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = {'SEVERITY': {'LOW': 1}, 'CONFIDENCE': {'HIGH': 1}}\n"", ""self.check_example('os_system.py', VAR_2)\n""]",0
"[""def FUNC_0(self, VAR_0, VAR_1, VAR_2, VAR_3):...\n"", ""if not hasattr(VAR_0, 'kbsite'):\n"", ""return None\n"", ""VAR_7 = VAR_0.kbsite\n"", ""if VAR_7.is_active:\n"", ""return None\n"", ""if self._path_allowed(VAR_0.path):\n"", ""return None\n"", ""if VAR_0.user.is_staff or VAR_0.user.is_superuser:\n"", ""return None\n"", ""return HttpResponse('Site temporarily unavailable', status=503)\n""]",1
"[""from __future__ import absolute_import\n"", ""from __future__ import division\n"", ""from __future__ import print_function\n"", ""import threading\n"", ""import traceback\n"", ""import redis\n"", ""import ray\n"", ""from ray import ray_constants\n"", ""from ray import cloudpickle as pickle\n"", ""from ray import profiling\n"", ""from ray import utils\n"", ""\""\""\""string\""\""\""\n"", ""def __init__(self, VAR_0, VAR_1):...\n"", ""self.worker = VAR_0\n"", ""self.mode = VAR_1\n"", ""self.redis_client = VAR_0.redis_client\n"", ""def FUNC_0(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_3 = threading.Thread(target=self._run, name='ray_import_thread')\n"", ""VAR_3.daemon = True\n"", ""VAR_3.start()\n"", ""def FUNC_1(self):...\n"", ""VAR_4 = self.redis_client.pubsub()\n"", ""VAR_4.subscribe('__keyspace@0__:Exports')\n"", ""VAR_5 = 0\n"", ""VAR_9 = self.redis_client.lrange('Exports', 0, -1)\n"", ""for VAR_2 in VAR_9:\n"", ""VAR_5 += 1\n"", ""for msg in VAR_4.listen():\n"", ""def FUNC_2(self, VAR_2):...\n"", ""self._process_key(VAR_2)\n"", ""if msg['type'] == 'subscribe':\n"", ""\""\""\""docstring\""\""\""\n"", ""assert msg['data'] == b'rpush'\n"", ""if self.mode != ray.WORKER_MODE:\n"", ""VAR_12 = self.redis_client.llen('Exports')\n"", ""if VAR_2.startswith(b'FunctionsToRun'):\n"", ""if VAR_2.startswith(b'RemoteFunction'):\n"", ""assert VAR_12 >= VAR_5\n"", ""self.fetch_and_execute_function_to_run(VAR_2)\n"", ""return\n"", ""self.worker.function_actor_manager.fetch_and_register_remote_function(VAR_2)\n"", ""if VAR_2.startswith(b'FunctionsToRun'):\n"", ""for i in range(VAR_5, VAR_12):\n"", ""def FUNC_3(self, VAR_2):...\n"", ""self.fetch_and_execute_function_to_run(VAR_2)\n"", ""if VAR_2.startswith(b'ActorClass'):\n"", ""VAR_5 += 1\n"", ""\""\""\""docstring\""\""\""\n"", ""self.worker.function_actor_manager.imported_actor_classes.add(VAR_2)\n"", ""VAR_2 = self.redis_client.lindex('Exports', i)\n"", ""VAR_6, VAR_7, VAR_8 = self.redis_client.hmget(VAR_2, ['driver_id',\n    'function', 'run_on_other_drivers'])\n"", ""self._process_key(VAR_2)\n"", ""if utils.decode(VAR_8\n"", ""return\n"", ""VAR_10 = pickle.loads(VAR_7)\n"", ""VAR_11 = traceback.format_exc()\n"", ""VAR_10({'worker': self.worker})\n"", ""utils.push_error_to_driver(self.worker, ray_constants.\n    FUNCTION_TO_RUN_PUSH_ERROR, VAR_11, VAR_6=ray.DriverID(driver_id))\n""]",1
"[""def FUNC_3(VAR_2):...\n"", ""if not VAR_2:\n"", ""return []\n"", ""VAR_9 = []\n"", ""VAR_10 = frappe.db.get_value('Department', {'name': VAR_2}, ['lft', 'rgt'],\n    as_dict=True)\n"", ""VAR_11 = frappe.db.sql(\n    \""\""\""select name from `tabDepartment`\n\t\twhere lft >= %s and rgt <= %s order by lft desc\n\t\t\""\""\""\n    , (VAR_10.lft, VAR_10.rgt), as_list=True)\n"", ""for d in VAR_11:\n"", ""VAR_9.extend([l.leave_approver for l in frappe.db.sql('string', d, as_dict=\n    True)])\n"", ""return VAR_9\n""]",0
"[""def FUNC_24(self):...\n"", ""self.cursor.execute(u'select 1')\n""]",0
"[""def FUNC_15(self):...\n"", """"]",0
"[""import mock\n"", ""import webapp2\n"", ""from google.appengine.api import users\n"", ""from handlers.flake import analyze_regression_range\n"", ""from handlers.flake.analyze_regression_range import AnalyzeRegressionRange\n"", ""from model.flake.master_flake_analysis import MasterFlakeAnalysis\n"", ""from waterfall.test import wf_testcase\n"", ""VAR_0 = webapp2.WSGIApplication([('/waterfall/analyze_regression_range',\n    AnalyzeRegressionRange)], debug=True)\n"", ""def FUNC_0(self):...\n"", ""self.assertTrue(analyze_regression_range._ValidateInput('1', '1', '100'))\n"", ""self.assertTrue(analyze_regression_range._ValidateInput('2', '1', '100'))\n"", ""self.assertTrue(analyze_regression_range._ValidateInput(None, '1', '100'))\n"", ""self.assertTrue(analyze_regression_range._ValidateInput('1', None, '100'))\n"", ""self.assertFalse(analyze_regression_range._ValidateInput(None, None, '100'))\n"", ""self.assertFalse(analyze_regression_range._ValidateInput('a', '1', '100'))\n"", ""def FUNC_1(self):...\n"", ""self.assertEqual((0, 0), analyze_regression_range.\n    _GetLowerAndUpperBoundCommitPositions(0, 0))\n"", ""self.assertEqual((0, 0), analyze_regression_range.\n    _GetLowerAndUpperBoundCommitPositions(None, 0))\n"", ""self.assertEqual((0, 0), analyze_regression_range.\n    _GetLowerAndUpperBoundCommitPositions(0, None))\n"", ""self.assertEqual((None, None), analyze_regression_range.\n    _GetLowerAndUpperBoundCommitPositions(None, None))\n"", ""self.assertEqual((1, 2), analyze_regression_range.\n    _GetLowerAndUpperBoundCommitPositions(1, 2))\n"", ""self.assertEqual((1, 2), analyze_regression_range.\n    _GetLowerAndUpperBoundCommitPositions(2, 1))\n"", ""@mock.patch.object(users, 'is_current_user_admin', return_value=True)...\n"", ""VAR_2 = MasterFlakeAnalysis.Create('m', 'b', 123, 's', 't')\n"", ""VAR_2.put()\n"", ""self.mock_current_user(user_email='test@google.com')\n"", ""VAR_3 = self.test_app.get('/waterfall/analyze_regression_range', params={\n    'lower_bound_commit_position': 1, 'upper_bound_commit_position': 2,\n    'iterations_to_rerun': 100, 'key': analysis.key.urlsafe()})\n"", ""self.assertEqual(200, VAR_3.status_int)\n""]",1
"[""from lxml import html\n"", ""from django.test import Client\n"", ""from django.urls import reverse\n"", ""from django.test import TestCase, override_settings\n"", ""from django.core.exceptions import ObjectDoesNotExist\n"", ""from dashboard.forms import *\n"", ""from factotum.settings import EXTRA\n"", ""from dashboard.tests.loader import *\n"", ""VAR_0 = fixtures_standard\n"", ""def FUNC_0(self):...\n"", ""self.client.login(username='Karyn', password='specialP@55word')\n"", ""def FUNC_1(self):...\n"", ""for VAR_13 in DataDocument.objects.all():\n"", ""VAR_11 = VAR_13.id\n"", ""def FUNC_2(self):...\n"", ""VAR_12 = self.client.get('/datadocument/%s/' % VAR_11)\n"", ""VAR_1 = DataDocument.objects.first()\n"", ""self.assertEqual(VAR_12.status_code, 200,\n    'The page must return a 200 status code')\n"", ""VAR_2 = self.client.get(f'/datadocument/179486/')\n"", ""VAR_20 = ExtractedText.objects.get(data_document=dd)\n"", ""self.assertContains(VAR_12, 'No Extracted Text exists for this Data Document')\n"", ""self.assertContains(VAR_12, '<h4>Extracted Text')\n"", ""self.assertIn('Download Script', VAR_2.content.decode('utf-8'))\n"", ""self.assertIn('Extraction Script', VAR_2.content.decode('utf-8'))\n"", ""def FUNC_3(self):...\n"", ""VAR_2 = self.client.get('/datadocument/179486/')\n"", ""VAR_3 = VAR_2.content.decode('utf-8')\n"", ""VAR_4 = VAR_3.index('<h4>Extracted Text')\n"", ""VAR_5 = VAR_3.index('<h4 class=\""d-inline\"">Products')\n"", ""self.assertTrue(VAR_5 > VAR_4,\n    'Product card should come after Extracted Text card')\n"", ""def FUNC_4(self):...\n"", ""VAR_2 = self.client.get('/datadocument/167497/')\n"", ""self.assertContains(VAR_2, '/link_product_form/167497/')\n"", ""VAR_6 = {'title': ['New Product'], 'upc': ['stub_1860'], 'document_type': [\n    1], 'return_url': ['/datadocument/167497/']}\n"", ""VAR_2 = self.client.post('/link_product_form/167497/', VAR_6=data)\n"", ""self.assertRedirects(VAR_2, '/datadocument/167497/')\n"", ""VAR_2 = self.client.get(VAR_2.url)\n"", ""self.assertContains(VAR_2, 'New Product')\n"", ""def FUNC_5(self):...\n"", ""VAR_2 = self.client.get('/datadocument/245401/')\n"", ""self.assertContains(VAR_2, '/link_product_form/245401/')\n"", ""VAR_6 = {'title': ['Product Title'], 'upc': ['stub_9100'], 'document_type':\n    [1], 'return_url': ['/datadocument/245401/']}\n"", ""VAR_2 = self.client.post('/link_product_form/245401/', VAR_6=data)\n"", ""self.assertRedirects(VAR_2, '/datadocument/245401/')\n"", ""VAR_2 = self.client.get(VAR_2.url)\n"", ""VAR_7 = Product.objects.get(upc='stub_9100')\n"", ""self.assertContains(VAR_2, f'product/%s' % VAR_7.id)\n"", ""VAR_6 = {'title': ['Product Title'], 'upc': ['stub_9101'], 'document_type':\n    [1], 'return_url': ['/datadocument/245401/']}\n"", ""VAR_2 = self.client.post('/link_product_form/245401/', VAR_6=data)\n"", ""self.assertRedirects(VAR_2, '/datadocument/245401/')\n"", ""VAR_2 = self.client.get(VAR_2.url)\n"", ""VAR_7 = Product.objects.get(upc='stub_9101')\n"", ""self.assertContains(VAR_2, f'product/%s' % VAR_7.id)\n"", ""def FUNC_6(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = DataDocument.objects.get(pk=354784)\n"", ""self.assertFalse(VAR_1.extracted, 'This document is matched but not extracted')\n"", ""VAR_6 = {'hhe_report_number': ['47']}\n"", ""VAR_2 = self.client.post('/extractedtext/edit/354784/', VAR_6=data, follow=True\n    )\n"", ""VAR_1 = DataDocument.objects.get(pk=354784)\n"", ""self.assertTrue(VAR_1.extracted, 'This document is not extracted ')\n"", ""VAR_8 = VAR_3.fromstring(VAR_2.content)\n"", ""VAR_9 = VAR_8.xpath('//dd[contains(@class, \""hh-report-no\"")]')[0].text\n"", ""self.assertIn('47', VAR_9)\n"", ""VAR_0 = fixtures_standard\n"", ""def FUNC_0(self):...\n"", ""self.client.login(username='Karyn', password='specialP@55word')\n"", ""def FUNC_7(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""for et in ExtractedText.objects.all():\n"", ""for ex_child in et.fetch_extracted_records():\n"", ""def FUNC_8(self):...\n"", ""VAR_21 = ex_child.__class__\n"", ""\""\""\""docstring\""\""\""\n"", ""self.assertEqual(et.pk, VAR_21.objects.get(pk=ex_child.pk).extracted_text.\n    pk, 'string')\n"", ""for VAR_1 in DataDocument.objects.all():\n"", ""def FUNC_9(self):...\n"", ""VAR_22 = ExtractedText.objects.get_subclass(data_document=doc)\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_1.data_group.group_type.code == 'CP':\n"", ""for et in ExtractedText.objects.all():\n"", ""self.assertEqual(type(VAR_22), ExtractedCPCat)\n"", ""if VAR_1.data_group.group_type.code == 'HH':\n"", ""VAR_13 = et.data_document\n"", ""def FUNC_10(self):...\n"", ""self.assertEqual(type(VAR_22), ExtractedHHDoc)\n"", ""self.assertEqual(type(VAR_22), ExtractedText)\n"", ""VAR_14, VAR_15 = create_detail_formset(VAR_13, EXTRA)\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_16 = VAR_14(instance=et)\n"", ""for et in ExtractedText.objects.all():\n"", ""VAR_17 = VAR_15(instance=et)\n"", ""VAR_13 = et.data_document\n"", ""def FUNC_11(self):...\n"", ""VAR_18 = get_extracted_models(VAR_13.data_group.group_type.code)[1]\n"", ""VAR_14, VAR_15 = create_detail_formset(VAR_13)\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_19 = VAR_17.__dict__.get('queryset').__dict__.get('model')\n"", ""VAR_17 = VAR_15(instance=et)\n"", ""VAR_10 = {'CO': ExtractedChemical, 'FU': ExtractedFunctionalUse, 'HP':\n    ExtractedHabitsAndPractices, 'CP': ExtractedListPresence, 'HH':\n    ExtractedHHRec}\n"", ""self.assertEqual(VAR_18, VAR_19)\n"", ""for form in VAR_17.forms:\n"", ""for code, model in VAR_10.items():\n"", ""if VAR_13.data_group.type in ['CO', 'UN']:\n"", ""if DataDocument.objects.filter(document_type__group_type__code=code,\n"", ""VAR_25 = form.instance\n"", ""self.assertFalse('true_cas' in form.fields)\n"", ""VAR_1 = DataDocument.objects.filter(document_type__group_type__code=code,\n    extractedtext__isnull=False).first()\n"", ""if VAR_25.dsstox is not None:\n"", ""VAR_2 = self.client.get(reverse('data_document', kwargs={'pk': doc.pk}))\n"", ""self.assertTrue('true_cas' in form.fields)\n"", ""self.assertFalse('true_cas' in form.fields)\n"", ""VAR_23 = VAR_2.context['detail_formset'].total_form_count()\n"", ""self.assertTrue('SID' in form.fields)\n"", ""self.assertFalse('SID' in form.fields)\n"", ""VAR_24 = model.objects.filter(VAR_20=doc.extractedtext).count()\n"", ""if VAR_1.detail_page_editable:\n"", ""VAR_26 = f'{model.__module__} should have one more forms than instances'\n"", ""VAR_26 = (\n    f'{model.__module__} should have the same number of forms as instances')\n"", ""self.assertEqual(VAR_23, VAR_24 + 1, VAR_26)\n"", ""self.assertEqual(VAR_23, VAR_24, VAR_26)\n""]",1
"[""import six\n"", ""def FUNC_0(VAR_0):...\n"", ""if '[' in VAR_0:\n"", ""VAR_7, VAR_8, VAR_9 = VAR_0.rstrip(']').partition('[')\n"", ""if '{' in VAR_0:\n"", ""return VAR_9, CLASS_0, VAR_7\n"", ""VAR_7, VAR_8, VAR_12 = VAR_0.rstrip('}').partition('{')\n"", ""return CLASS_0, CLASS_0, VAR_0\n"", ""VAR_13, VAR_8, VAR_14 = VAR_12.partition('=')\n"", ""return VAR_14, VAR_13, VAR_7\n""]",0
"[""def FUNC_6(self):...\n"", ""return self.title\n""]",0
"[""def FUNC_6():...\n"", ""populate_test_database()\n"", ""VAR_11 = VAR_3.post('/playlists/nn')\n"", ""assert VAR_11.json['status'] == 'OK'\n"", ""VAR_12 = VAR_3.put('/playlists/1/name')\n"", ""assert VAR_12.json['status'] == 'OK'\n"", ""VAR_13 = VAR_3.get('/playlists')\n"", ""assert VAR_13.json['status'] == 'OK'\n"", ""assert VAR_13.json['data'] == [dict(id=1, VAR_8='name')]\n""]",0
"[""def FUNC_15(self, VAR_1):...\n"", ""def FUNC_31():...\n"", ""yield self._bin_path\n"", ""if self._is_jdk:\n"", ""yield os.path.join(self.home, 'jre', 'bin')\n"", ""for VAR_5 in FUNC_31():\n"", ""VAR_23 = os.path.join(VAR_5, VAR_1)\n"", ""if self._is_executable(VAR_23):\n"", ""return VAR_23\n""]",0
"[""@handled_slot(bool)...\n"", ""print('Opening IDLE.')\n"", ""subprocess.Popen(\n    'python -m idlelib -t \""Matisse Controller - Python Shell\"" -c \""from matisse import Matisse; '\n     +\n    'matisse = Matisse(); print(\\'Access the Matisse using \\\\\\'matisse.[method]\\\\\\'\\')\""'\n    )\n""]",1
"[""def FUNC_17(self, VAR_14):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if not self.is_mine(VAR_14):\n"", ""VAR_11 = VAR_14.user\n"", ""VAR_11.message_set.create(message=self.message_template % self.created_at)\n""]",0
"[""def FUNC_7(self):...\n"", ""return self.content\n""]",0
"[""from django.db import models\n"", ""from .dsstox_lookup import DSSToxLookup\n"", ""from .extracted_text import ExtractedText\n"", ""from model_utils.managers import InheritanceManager\n"", ""from django.apps import apps\n"", ""from django.db.models.signals import pre_save\n"", ""from django.dispatch import receiver\n"", ""from model_utils import FieldTracker\n"", ""VAR_0 = models.ForeignKey(ExtractedText, related_name='rawchem', on_delete=\n    models.CASCADE, null=False, blank=False)\n"", ""VAR_1 = models.CharField('Raw CAS', max_length=100, null=True, blank=True)\n"", ""VAR_2 = models.CharField('Raw chemical name', max_length=500, null=True,\n    blank=True)\n"", ""VAR_3 = models.IntegerField(default=0, null=True, blank=True)\n"", ""VAR_4 = models.CharField(max_length=255, null=True, blank=True)\n"", ""VAR_5 = models.CharField(max_length=50, null=True, blank=True)\n"", ""VAR_6 = models.ForeignKey(DSSToxLookup, related_name='curated_chemical',\n    on_delete=models.PROTECT, null=True, blank=True)\n"", ""VAR_7 = InheritanceManager()\n"", ""VAR_8 = FieldTracker()\n"", ""def __str__(self):...\n"", ""return str(self.raw_chem_name) if self.raw_chem_name else ''\n""]",1
"[""def FUNC_9(VAR_6):...\n"", ""if VAR_6.is_redirect:\n"", ""return False\n"", ""return True\n""]",0
"[""def FUNC_21(self, VAR_14):...\n"", """"]",0
"[""def FUNC_3(VAR_3):...\n"", """"]",0
"[""def FUNC_4(self, VAR_4):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_9 = \""SELECT tag FROM tid_tag WHERE tid = '\"" + str(VAR_4) + \""'\""\n"", ""self.query(VAR_9)\n"", ""return [i[0] for i in self.c.fetchall()]\n""]",1
"[""def FUNC_12(self, VAR_10=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_30 = vars(self.parse_known_args(VAR_15=True)[0])\n"", ""VAR_13 = VAR_30.get('image_mode', None)\n"", ""if VAR_13 is not None and VAR_13 != 'none':\n"", ""self.add_image_args(VAR_13)\n"", ""VAR_12 = VAR_30.get('task', None)\n"", ""if VAR_12 is not None:\n"", ""self.add_task_args(VAR_12)\n"", ""VAR_31 = VAR_30.get('evaltask', None)\n"", ""if VAR_31 is not None:\n"", ""self.add_task_args(VAR_31)\n"", ""VAR_11 = VAR_30.get('model', None)\n"", ""if VAR_11 is not None:\n"", ""self.add_model_subargs(VAR_11)\n"", ""self.set_defaults(**self._defaults)\n""]",1
"[""def FUNC_29(self, *VAR_33):...\n"", ""self._run_tracker.log(Report.WARN, *VAR_33)\n""]",0
"[""def FUNC_2(VAR_1, VAR_4, VAR_2, VAR_5=0):...\n"", ""VAR_6 = 'string' % (VAR_2, VAR_4, VAR_1, VAR_5)\n"", ""return {'status': 1}\n""]",1
"[""def FUNC_12():...\n"", ""VAR_18 = requests.get(FUNC_2('healthy'))\n"", ""VAR_18.raise_for_status()\n"", ""return VAR_18.json()\n""]",1
"[""def FUNC_3(self, VAR_8, VAR_9, VAR_10, VAR_11):...\n"", ""VAR_14 = ('string' + VAR_8 + \""', '\"" + VAR_9 + \""', '\"" + VAR_10 + \""', '\"" +\n    VAR_11 + \""', '0', '0')\"")\n"", ""self.cursor.execute(VAR_14)\n"", ""self.connection.commit()\n""]",1
"[""def FUNC_0(self, VAR_49, VAR_48=None, VAR_50=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_43 = None\n"", ""VAR_57 = None\n"", ""VAR_55 = None\n"", ""if VAR_49 in self.conf:\n"", ""if 'playbook' in self.conf[VAR_49]:\n"", ""if VAR_43 is None:\n"", ""VAR_43 = self.conf[VAR_49]['playbook']\n"", ""if 'log_file' in self.conf[VAR_49]:\n"", ""VAR_43 = self.conf['playbook']\n"", ""if VAR_55 is None and VAR_55 in self.conf:\n"", ""VAR_57 = self.conf[VAR_49]['log_file']\n"", ""if 'template' in self.conf[VAR_49]:\n"", ""VAR_55 = self.conf['template']\n"", ""if VAR_57 is None:\n"", ""VAR_55 = self.conf[VAR_49]['template']\n"", ""if 'log_file' in self.conf:\n"", ""if VAR_55:\n"", ""VAR_57 = self.conf['log_file']\n"", ""VAR_57 = open(os.devnull, 'w')\n"", ""open(VAR_43, 'w').write(self.generate_ansible_playbook_from_template(VAR_55,\n    VAR_48))\n"", ""VAR_58 = CLASS_1(VAR_43=playbook, VAR_1=0)\n"", ""VAR_59 = VAR_58.run(VAR_45=context.last_job_id)\n""]",0
"[""def FUNC_5(self, VAR_8, VAR_10):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_9 = self.requests.get(VAR_8)\n"", ""if VAR_9:\n"", ""VAR_9.write(FUNC_0(VAR_10))\n"", ""VAR_23 = self.databuffer.get(VAR_8, [])\n"", ""VAR_9.finish()\n"", ""VAR_23.append(FUNC_0(VAR_10))\n"", ""self.databuffer[VAR_8] = VAR_23\n""]",0
"[""def FUNC_5(VAR_4, *VAR_5, **VAR_6):...\n"", """"]",0
"[""def __init__(self, VAR_0):...\n"", ""debug('Comment ', VAR_0)\n"", ""super(CLASS_1, self).__init__('% ' + VAR_0)\n""]",1
"[""def FUNC_1(VAR_2):...\n"", ""return CLASS_0.all().filter('email =', VAR_2).get()\n""]",0
"[""def FUNC_3(self, VAR_6, VAR_7):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_14 = ray.gcs_utils.GcsTableEntry.GetRootAsGcsTableEntry(VAR_7, 0)\n"", ""VAR_26 = VAR_14.Entries(0)\n"", ""VAR_16 = ray.gcs_utils.DriverTableData.GetRootAsDriverTableData(VAR_26, 0)\n"", ""VAR_8 = VAR_16.DriverId()\n"", ""VAR_0.info('Monitor: XRay Driver {} has been removed.'.format(binary_to_hex\n    (VAR_8)))\n"", ""self._xray_clean_up_entries_for_driver(VAR_8)\n""]",0
"[""\""\""\""string\""\""\""\n"", ""VAR_0 = {}\n"", ""\""\""\""Configuration of remote applications.\""\""\""\n"", ""VAR_1 = 'oauth_token'\n"", ""\""\""\""Session key prefix used when storing the access token for a remote app.\""\""\""\n""]",0
"[""import json\n"", ""from django.http import JsonResponse\n"", ""from django.shortcuts import redirect\n"", ""from django.views.decorators.csrf import csrf_exempt\n"", ""from django.views.decorators.http import require_http_methods\n"", ""from cuckoo.common.config import config\n"", ""from cuckoo.core.submit import SubmitManager\n"", ""from cuckoo.web.bin.utils import api_post, JsonSerialize, json_error_response\n"", ""VAR_0 = SubmitManager()\n"", ""def FUNC_0():...\n"", ""VAR_1 = config('cuckoo:cuckoo:machinery')\n"", ""if config('routing:vpn:enabled'):\n"", ""VAR_4 = config('routing:vpn:vpns')\n"", ""VAR_4 = []\n"", ""return {'machine': config('%s:%s:machines' % (VAR_1, VAR_1)), 'package':\n    None, 'priority': 2, 'timeout': config('cuckoo:timeouts:default'),\n    'routing': {'route': config('routing:routing:route'), 'inetsim': config\n    ('routing:inetsim:enabled'), 'tor': config('routing:tor:enabled'),\n    'vpns': VAR_4}, 'options': {'enable-services': False, 'enforce-timeout':\n    False, 'full-memory-dump': config('cuckoo:cuckoo:memory_dump'),\n    'no-injection': False, 'process-memory-dump': True,\n    'simulated-human-interaction': True}}\n""]",0
"[""\""\""\"" Client blueprint used to handle OAuth callbacks. \""\""\""\n"", ""from __future__ import absolute_import\n"", ""from flask import Blueprint, abort, current_app, url_for, request\n"", ""from flask.ext.login import user_logged_out\n"", ""from invenio.base.globals import cfg\n"", ""from invenio.ext.sslify import ssl_required\n"", ""from ..client import oauth, handlers, disconnect_handlers, signup_handlers\n"", ""from ..handlers import authorized_default_handler, make_token_getter, make_handler, disconnect_handler, oauth_logout_handler\n"", ""VAR_0 = Blueprint('oauthclient', __name__, url_prefix='/oauth',\n    static_folder='../static', template_folder='../templates')\n"", ""@VAR_0.before_app_first_request...\n"", ""\""\""\""docstring\""\""\""\n"", ""user_logged_out.connect(oauth_logout_handler)\n"", ""oauth.init_app(current_app)\n"", ""for VAR_1, conf in cfg['OAUTHCLIENT_REMOTE_APPS'].items():\n"", ""if VAR_1 not in oauth.remote_apps:\n"", ""@VAR_0.route('/login/<remote_app>/')...\n"", ""VAR_4 = oauth.remote_app(VAR_1, **conf['params'])\n"", ""VAR_4 = oauth.remote_apps[VAR_1]\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_4.tokengetter(make_token_getter(VAR_4))\n"", ""if VAR_1 not in oauth.remote_apps:\n"", ""handlers.register(VAR_1, VAR_4.authorized_handler(make_handler(conf.get(\n    'authorized_handler', authorized_default_handler), VAR_4)))\n"", ""return abort(404)\n"", ""VAR_2 = url_for('.authorized', VAR_1=remote_app, next=request.args.get(\n    'next') or request.referrer or None, _external=True)\n"", ""disconnect_handlers.register(VAR_1, make_handler(conf.get(\n    'disconnect_handler', disconnect_handler), VAR_4, with_response=False))\n"", ""return oauth.remote_apps[VAR_1].authorize(callback=callback_url)\n"", ""def FUNC_5(VAR_4, *VAR_5, **VAR_6):...\n"", ""VAR_7 = conf.get('signup_handler', dict())\n"", ""VAR_8 = make_handler(VAR_7.get('info', FUNC_5), VAR_4, with_response=False)\n"", ""VAR_9 = make_handler(VAR_7.get('setup', FUNC_5), VAR_4, with_response=False)\n"", ""VAR_10 = make_handler(VAR_7.get('view', FUNC_5), VAR_4, with_response=False)\n"", ""signup_handlers.register(VAR_1, dict(info=account_info_handler, setup=\n    account_setup_handler, view=account_view_handler))\n""]",1
"[""def FUNC_9(self):...\n"", ""subprocess.call(['touch', VAR_2])\n"", ""return None\n""]",0
"[""from osv import osv\n"", ""from tools.translate import _\n"", ""VAR_0 = 'pos.close.statement'\n"", ""VAR_1 = 'Close Statements'\n"", ""def FUNC_0(self, VAR_2, VAR_3, VAR_4, VAR_5):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = self.pool.get('res.users').browse(VAR_2, VAR_3, VAR_3).company_id.id\n"", ""VAR_7 = []\n"", ""VAR_8 = self.pool.get('ir.model.data')\n"", ""VAR_9 = self.pool.get('account.bank.statement')\n"", ""VAR_10 = self.pool.get('account.journal')\n"", ""VAR_2.execute(\n    'select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id'\n     % VAR_3)\n"", ""VAR_11 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""VAR_2.execute('string' % ','.join(map(lambda x: \""'\"" + str(x) + \""'\"", VAR_11)))\n"", ""VAR_12 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""for journal in VAR_10.browse(VAR_2, VAR_3, VAR_12):\n"", ""VAR_4 = VAR_9.search(VAR_2, VAR_3, [('state', '!=', 'confirm'), ('user_id',\n    '=', VAR_3), ('journal_id', '=', journal.id)])\n"", ""VAR_13 = self.pool.get('ir.model.data')\n"", ""if not VAR_4:\n"", ""VAR_14 = VAR_13._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_tree')\n"", ""VAR_7.append(VAR_4[0])\n"", ""VAR_15 = VAR_13._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_form2')\n"", ""if not journal.check_dtls:\n"", ""if VAR_14:\n"", ""VAR_9.button_confirm_cash(VAR_2, VAR_3, VAR_4, VAR_5)\n"", ""VAR_14 = VAR_13.browse(VAR_2, VAR_3, VAR_14, VAR_5=context).res_id\n"", ""if VAR_15:\n"", ""VAR_15 = VAR_13.browse(VAR_2, VAR_3, VAR_15, VAR_5=context).res_id\n"", ""return {'domain': \""[('id','in',\"" + str(VAR_7) + ')]', 'name':\n    'Close Statements', 'view_type': 'form', 'view_mode': 'tree,form',\n    'res_model': 'account.bank.statement', 'views': [(VAR_14, 'tree'), (\n    VAR_15, 'form')], 'type': 'ir.actions.act_window'}\n""]",1
"[""@pytest.fixture(scope='session', autouse=True)...\n"", ""VAR_13 = FUNC_6()\n"", ""conn.execute(f'DROP DATABASE IF EXISTS {VAR_13}')\n"", ""conn.execute(f'CREATE DATABASE {VAR_13}')\n"", ""FUNC_10()\n"", ""VAR_0.addfinalizer(lambda : FUNC_5(VAR_4))\n""]",1
"[""@patch('invenio.ext.session.interface.SessionInterface.save_session')...\n"", ""from invenio.modules.oauthclient.models import RemoteToken\n"", ""from invenio.modules.oauthclient.handlers import token_getter\n"", ""from invenio.modules.oauthclient.client import oauth\n"", ""VAR_9 = MagicMock()\n"", ""VAR_9.get_id = MagicMock(return_value=1)\n"", ""VAR_9.is_authenticated = MagicMock(return_value=True)\n"", ""VAR_10 = c.get(url_for('oauthclient.login', remote_app='full'))\n"", ""assert VAR_10.status_code == 302\n"", ""assert VAR_10.location.startswith(oauth.remote_apps['full'].authorize_url)\n"", ""self.mock_response(VAR_5='full')\n"", ""c.get(url_for('oauthclient.authorized', remote_app='full', code='test'))\n"", ""assert session['oauth_token_full'] == ('test_access_token', '')\n"", ""VAR_11 = RemoteToken.get(1, 'fullid')\n"", ""assert VAR_11.remote_account.client_id == 'fullid'\n"", ""assert VAR_11.access_token == 'test_access_token'\n"", ""assert RemoteToken.query.count() == 1\n"", ""self.mock_response(VAR_5='full', VAR_6={'access_token': 'new_access_token',\n    'scope': '', 'token_type': 'bearer'})\n"", ""c.get(url_for('oauthclient.authorized', remote_app='full', code='test'))\n"", ""VAR_11 = RemoteToken.get(1, 'fullid')\n"", ""assert VAR_11.access_token == 'new_access_token'\n"", ""assert RemoteToken.query.count() == 1\n"", ""VAR_12 = token_getter(oauth.remote_apps['full'])\n"", ""assert VAR_12 == ('new_access_token', '')\n"", ""VAR_10 = c.get(url_for('oauthclient.disconnect', remote_app='full'))\n"", ""assert VAR_10.status_code == 302\n"", ""assert VAR_10.location.endswith(url_for('oauthclient_settings.index'))\n"", ""VAR_11 = RemoteToken.get(1, 'fullid')\n"", ""assert VAR_11 is None\n""]",1
"[""from osv import osv\n"", ""from tools.translate import _\n"", ""import time\n"", ""VAR_0 = 'pos.open.statement'\n"", ""VAR_1 = 'Open Statements'\n"", ""def FUNC_0(self, VAR_2, VAR_3, VAR_4, VAR_5):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = []\n"", ""VAR_7 = self.pool.get('ir.model.data')\n"", ""VAR_8 = self.pool.get('res.users').browse(VAR_2, VAR_3, VAR_3).company_id.id\n"", ""VAR_9 = self.pool.get('account.bank.statement')\n"", ""VAR_10 = self.pool.get('ir.sequence')\n"", ""VAR_11 = self.pool.get('account.journal')\n"", ""VAR_2.execute(\n    'select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id'\n     % VAR_3)\n"", ""VAR_12 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""VAR_2.execute('string' % ','.join(map(lambda x: \""'\"" + str(x) + \""'\"", VAR_12)))\n"", ""VAR_13 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""for journal in VAR_11.browse(VAR_2, VAR_3, VAR_13):\n"", ""VAR_4 = VAR_9.search(VAR_2, VAR_3, [('state', '!=', 'confirm'), ('user_id',\n    '=', VAR_3), ('journal_id', '=', journal.id)])\n"", ""VAR_14 = self.pool.get('ir.model.data')\n"", ""if len(VAR_4):\n"", ""VAR_15 = VAR_14._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_tree')\n"", ""VAR_17 = ''\n"", ""VAR_16 = VAR_14._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_form2')\n"", ""if journal.sequence_id:\n"", ""if VAR_15:\n"", ""VAR_17 = VAR_10.get_id(VAR_2, VAR_3, journal.sequence_id.id)\n"", ""VAR_17 = VAR_10.get(VAR_2, VAR_3, 'account.bank.statement')\n"", ""VAR_15 = VAR_14.browse(VAR_2, VAR_3, VAR_15, VAR_5=context).res_id\n"", ""if VAR_16:\n"", ""VAR_18 = VAR_9.create(VAR_2, VAR_3, {'journal_id': journal.id, 'company_id':\n    VAR_8, 'user_id': VAR_3, 'state': 'open', 'name': VAR_17,\n    'starting_details_ids': VAR_9._get_cash_close_box_lines(VAR_2, VAR_3, [])})\n"", ""VAR_16 = VAR_14.browse(VAR_2, VAR_3, VAR_16, VAR_5=context).res_id\n"", ""return {'domain': \""[('state','=','open')]\"", 'name': 'Open Statement',\n    'view_type': 'form', 'view_mode': 'tree,form', 'res_model':\n    'account.bank.statement', 'views': [(VAR_15, 'tree'), (VAR_16, 'form')],\n    'type': 'ir.actions.act_window'}\n"", ""VAR_9.button_open(VAR_2, VAR_3, [VAR_18], VAR_5)\n""]",1
"[""@VAR_2.route('/data/platform/')...\n"", ""VAR_38 = request.args.get('platform')\n"", ""VAR_39 = request.args.get('build_system_type')\n"", ""VAR_24, VAR_23 = FUNC_4(request.args)\n"", ""VAR_40 = 'platform: %s startDate: %s endDate: %s' % (VAR_38, VAR_24.\n    strftime('%Y-%m-%d'), VAR_23.strftime('%Y-%m-%d'))\n"", ""VAR_2.logger.debug(VAR_40)\n"", ""VAR_28 = FUNC_0()\n"", ""VAR_32 = VAR_28.cursor()\n"", ""VAR_41 = 'string' % (VAR_38, VAR_24, VAR_23, VAR_39)\n"", ""VAR_32.execute(VAR_41)\n"", ""VAR_42 = VAR_32.fetchall()\n"", ""VAR_43 = []\n"", ""VAR_44 = {}\n"", ""VAR_6 = []\n"", ""VAR_34 = 'green orange blue red'.split()\n"", ""VAR_35 = {VAR_26: (0) for VAR_26 in VAR_34}\n"", ""for cset in VAR_42:\n"", ""VAR_17 = cset[0]\n"", ""VAR_32.close()\n"", ""VAR_68 = CLASS_0(VAR_17)\n"", ""VAR_28.close()\n"", ""VAR_41 = 'string' % (VAR_38, VAR_17, VAR_39)\n"", ""VAR_45 = sorted(VAR_44.keys())\n"", ""VAR_32.execute(VAR_41)\n"", ""VAR_45 += ['total', 'percentage']\n"", ""VAR_69 = VAR_32.fetchall()\n"", ""VAR_46 = Counter()\n"", ""for res, testtype, VAR_52 in VAR_69:\n"", ""VAR_47 = {}\n"", ""VAR_84 = VAR_44.setdefault(testtype, VAR_35.copy())\n"", ""VAR_43.append(VAR_68)\n"", ""for test in VAR_44:\n"", ""if res == 'success':\n"", ""VAR_46.update(VAR_44[test])\n"", ""VAR_48 = sum(VAR_46.values())\n"", ""VAR_68.green[testtype] += 1\n"", ""if res == 'testfailed':\n"", ""for VAR_70 in VAR_46:\n"", ""VAR_84['green'] += 1\n"", ""VAR_68.orange[testtype] += 1\n"", ""if res == 'retry':\n"", ""VAR_47[VAR_70] = round(100.0 * VAR_46[VAR_70] / VAR_48, 2)\n"", ""VAR_49 = FUNC_6(VAR_10=total['green'], VAR_11=total['blue'], VAR_12=test_count)\n"", ""VAR_6.append(VAR_52)\n"", ""VAR_84['orange'] += 1\n"", ""VAR_68.blue[testtype] += 1\n"", ""if res == 'exception' or res == 'busted':\n"", ""VAR_44['total'] = VAR_46\n"", ""VAR_84['blue'] += 1\n"", ""VAR_68.red[testtype] += 1\n"", ""if res == 'usercancel':\n"", ""VAR_44['percentage'] = VAR_47\n"", ""VAR_84['red'] += 1\n"", ""VAR_2.logger.debug('usercancel')\n"", ""VAR_2.logger.debug('UNRECOGNIZED RESULT: %s' % res)\n"", ""return {'testTypes': VAR_45, 'byRevision': VAR_43, 'byTest': VAR_44,\n    'failRates': VAR_49, 'dates': FUNC_3(VAR_6)}\n""]",1
"[""@VAR_2.route('/matches_at_date')...\n"", ""if VAR_0 == None:\n"", ""FUNC_16()\n"", ""VAR_5 = request.args.get('tag', default=None)\n"", ""VAR_19 = request.args.get('date', default=None)\n"", ""if VAR_5 and VAR_19:\n"", ""VAR_21, VAR_22, VAR_23 = VAR_19.split('-')\n"", ""return ''\n"", ""VAR_34 = '12' if VAR_22 == '01' else str(int(VAR_22) - 1)\n"", ""VAR_34 = VAR_34.zfill(2)\n"", ""VAR_35 = str(int(VAR_21) - 1) if VAR_22 == '01' else VAR_21\n"", ""VAR_36 = '{}-{}-{}'.format(VAR_35, VAR_34, VAR_23)\n"", ""VAR_8 = (\n    \""select * from matches where (player1='{}' or player2='{}') and date<='{}' and date>='{}'\""\n    .format(VAR_5, VAR_5, VAR_19, VAR_36))\n"", ""VAR_7 = VAR_0.exec(VAR_8)\n"", ""return json.dumps(VAR_7)\n""]",1
"[""def FUNC_46(self, VAR_16):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_56 = self.regex.search(VAR_16)\n"", ""if VAR_56 is not None:\n"", ""return VAR_56.group('value')\n""]",0
"[""def FUNC_12(self, VAR_16=None):...\n"", ""if not VAR_16:\n"", ""VAR_16 = self.path[-1:][0]\n"", ""return {'directories': VAR_0.select('directory', 'parent_directory_id = ' +\n    str(VAR_16) + ' AND user_id = ' + str(self.user_id)), 'files': VAR_0.\n    select('file', 'directory_id = ' + str(VAR_16) + ' AND user_id = ' +\n    str(self.user_id))}\n""]",1
"[""import logging\n"", ""from django.conf import settings\n"", ""from django.contrib.auth import REDIRECT_FIELD_NAME\n"", ""from django.contrib.auth.views import login as django_login\n"", ""from django.core.cache import cache\n"", ""from django.core.cache.utils import make_template_fragment_key\n"", ""from django.http.response import HttpResponseRedirect\n"", ""from django.shortcuts import resolve_url\n"", ""from django.template.loader import TemplateDoesNotExist, get_template\n"", ""from django.utils.http import is_safe_url\n"", ""from django.utils.translation import get_language\n"", ""from django.utils.translation import ugettext_lazy as _\n"", ""from lib.helpers import settings_text\n"", ""from authorization.permissions import ACCESS\n"", ""from .viewbase import UserProfileView\n"", ""VAR_0 = logging.getLogger('userprofile.views')\n"", ""def FUNC_0(VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if VAR_1.user.is_authenticated():\n"", ""VAR_5 = VAR_1.POST.get(REDIRECT_FIELD_NAME, VAR_1.GET.get(\n    REDIRECT_FIELD_NAME, ''))\n"", ""return django_login(VAR_1, VAR_4='userprofile/login.html', extra_context={\n    'shibboleth_login': 'shibboleth_login' in settings.INSTALLED_APPS,\n    'mooc_login': 'social_django' in settings.INSTALLED_APPS,\n    'login_title_text': settings_text('LOGIN_TITLE_TEXT'),\n    'login_body_text': settings_text('LOGIN_BODY_TEXT'),\n    'login_button_text': settings_text('LOGIN_BUTTON_TEXT'),\n    'shibboleth_title_text': settings_text('SHIBBOLETH_TITLE_TEXT'),\n    'shibboleth_body_text': settings_text('SHIBBOLETH_BODY_TEXT'),\n    'shibboleth_button_text': settings_text('SHIBBOLETH_BUTTON_TEXT'),\n    'mooc_title_text': settings_text('MOOC_TITLE_TEXT'), 'mooc_body_text':\n    settings_text('MOOC_BODY_TEXT')})\n"", ""if not is_safe_url(url=redirect_to, host=request.get_host()):\n"", ""VAR_5 = resolve_url(settings.LOGIN_REDIRECT_URL)\n"", ""return HttpResponseRedirect(VAR_5)\n""]",1
"[""\""\""\""string\""\""\""\n"", ""from __future__ import unicode_literals\n"", ""import mimetypes\n"", ""import os\n"", ""import posixpath\n"", ""import re\n"", ""import stat\n"", ""from django.http import FileResponse, Http404, HttpResponse, HttpResponseNotModified, HttpResponseRedirect\n"", ""from django.template import Context, Engine, TemplateDoesNotExist, loader\n"", ""from django.utils.http import http_date, parse_http_date\n"", ""from django.utils.six.moves.urllib.parse import unquote\n"", ""from django.utils.translation import ugettext as _, ugettext_lazy\n"", ""def FUNC_0(VAR_0, VAR_1, VAR_2=None, VAR_3=False):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = posixpath.normpath(unquote(VAR_1))\n"", ""VAR_1 = VAR_1.lstrip('/')\n"", ""VAR_10 = ''\n"", ""for VAR_18 in VAR_1.split('/'):\n"", ""if not VAR_18:\n"", ""if VAR_10 and VAR_1 != VAR_10:\n"", ""VAR_17, VAR_18 = os.path.splitdrive(VAR_18)\n"", ""return HttpResponseRedirect(VAR_10)\n"", ""VAR_6 = os.path.join(VAR_2, VAR_10)\n"", ""VAR_19, VAR_18 = os.path.split(VAR_18)\n"", ""if os.path.isdir(VAR_6):\n"", ""if VAR_18 in (os.curdir, os.pardir):\n"", ""if VAR_3:\n"", ""if not os.path.exists(VAR_6):\n"", ""VAR_10 = os.path.join(VAR_10, VAR_18).replace('\\\\', '/')\n"", ""return FUNC_1(VAR_10, VAR_6)\n"", ""VAR_11 = os.stat(VAR_6)\n"", ""if not FUNC_2(VAR_0.META.get('HTTP_IF_MODIFIED_SINCE'), VAR_11.st_mtime,\n"", ""return HttpResponseNotModified()\n"", ""VAR_12, VAR_13 = mimetypes.guess_type(VAR_6)\n"", ""VAR_12 = VAR_12 or 'application/octet-stream'\n"", ""VAR_14 = FileResponse(open(VAR_6, 'rb'), VAR_12=content_type)\n"", ""VAR_14['Last-Modified'] = http_date(VAR_11.st_mtime)\n"", ""if stat.S_ISREG(VAR_11.st_mode):\n"", ""VAR_14['Content-Length'] = VAR_11.st_size\n"", ""if VAR_13:\n"", ""VAR_14['Content-Encoding'] = VAR_13\n"", ""return VAR_14\n""]",1
"[""def FUNC_39(VAR_101):...\n"", ""if VAR_101.input:\n"", ""VAR_13.set_input(*VAR_101.input[0], **ruleinfo.input[1])\n"", ""if VAR_101.output:\n"", ""VAR_13.set_output(*VAR_101.output[0], **ruleinfo.output[1])\n"", ""if VAR_101.params:\n"", ""VAR_13.set_params(*VAR_101.params[0], **ruleinfo.params[1])\n"", ""if VAR_101.threads:\n"", ""if not isinstance(VAR_101.threads, int):\n"", ""if VAR_101.resources:\n"", ""VAR_13.resources['_cores'] = VAR_101.threads\n"", ""VAR_76, VAR_52 = VAR_101.resources\n"", ""if VAR_101.priority:\n"", ""if VAR_76:\n"", ""if not isinstance(VAR_101.priority, int) and not isinstance(VAR_101.\n"", ""if VAR_101.version:\n"", ""if not all(map(lambda r: isinstance(r, int), VAR_52.values())):\n"", ""VAR_13.priority = VAR_101.priority\n"", ""VAR_13.version = VAR_101.version\n"", ""if VAR_101.log:\n"", ""VAR_13.resources.update(VAR_52)\n"", ""VAR_13.set_log(*VAR_101.log[0], **ruleinfo.log[1])\n"", ""if VAR_101.message:\n"", ""VAR_13.message = VAR_101.message\n"", ""if VAR_101.benchmark:\n"", ""VAR_13.benchmark = VAR_101.benchmark\n"", ""VAR_13.norun = VAR_101.norun\n"", ""VAR_13.docstring = VAR_101.docstring\n"", ""VAR_13.run_func = VAR_101.func\n"", ""VAR_13.shellcmd = VAR_101.shellcmd\n"", ""VAR_101.func.__name__ = '__{}'.format(VAR_10)\n"", ""self.globals[VAR_101.func.__name__] = VAR_101.func\n"", ""setattr(VAR_86, VAR_10, VAR_13)\n"", ""return VAR_101.func\n""]",0
"[""def FUNC_26(self, VAR_32, VAR_17, VAR_18=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_48 = self._scheduler.product_request(FallibleExecuteProcessResult, [VAR_32]\n    )[0]\n"", ""workunit.output('stdout').write(VAR_48.stdout)\n"", ""workunit.output('stderr').write(VAR_48.stderr)\n"", ""workunit.set_outcome(WorkUnit.FAILURE if VAR_48.exit_code else WorkUnit.SUCCESS\n    )\n"", ""return VAR_48\n""]",0
"[""def FUNC_10(self):...\n"", ""self.run_test_case(self.scenario.upsert_load_balancer())\n""]",0
"[""def FUNC_15(VAR_1, VAR_10, VAR_11, **VAR_6):...\n"", ""VAR_51 = ''\n"", ""VAR_55 = VAR_10 + VAR_11\n"", ""if VAR_6.get('dir') == 'fullpath':\n"", ""VAR_55 = VAR_10\n"", ""VAR_37 = FUNC_8(VAR_1)\n"", ""VAR_51 = e\n"", ""VAR_74 = VAR_37.open_sftp()\n"", ""VAR_51 = e\n"", ""return VAR_51\n"", ""VAR_11 = VAR_74.put(VAR_11, VAR_55)\n"", ""VAR_74.close()\n"", ""VAR_37.close()\n""]",0
"[""from flask_restful import Resource\n"", ""from werkzeug.exceptions import BadRequest\n"", ""from flask import request, jsonify, g\n"", ""from datetime import datetime\n"", ""from sqlalchemy import exists, and_\n"", ""from sqlalchemy.orm.exc import NoResultFound\n"", ""from common.json_schema import User_Schema\n"", ""from common.utils import headers, is_logged_in, has_admin_privileges\n"", ""from common.utils import bad_request, unauthorized, forbidden, not_found, internal_server_error, unprocessable_entity, conflict\n"", ""def FUNC_0(self, VAR_0):...\n"", ""def FUNC_1(self, VAR_0):...\n"", ""def FUNC_2(self, VAR_0):...\n"", ""def FUNC_0(self):...\n"", ""def FUNC_3(self):...\n""]",0
"[""def FUNC_8(self):...\n"", ""self.misc_file_checks()\n"", ""self.check_helper_consistency()\n"", ""self.check_source_management()\n"", ""self.check_manifest()\n"", ""for script in self.scripts.values():\n"", ""if script.exists:\n"", ""script.analyze()\n""]",0
"[""def FUNC_24(self, VAR_7, VAR_17):...\n"", ""self.common.extend_volume(VAR_7, VAR_17)\n""]",0
"[""@api.public...\n"", ""FUNC_31(self, 'DELETE')\n""]",0
"[""def FUNC_10(self, VAR_16):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_11 = ['volume', 'select', VAR_16['name'], 'show']\n"", ""self._eql_execute(*VAR_11)\n"", ""if err.stdout.find('does not exist.\\n') > -1:\n"", ""VAR_0.debug(_('Volume %s does not exist, it may have already been deleted'),\n    VAR_16['name'])\n""]",0
"[""def FUNC_13(VAR_7, VAR_1, VAR_12=True):...\n"", ""\""\""\""docstring\""\""\""\n"", ""if isinstance(VAR_7, six.text_type):\n"", ""VAR_7 = import_string(VAR_7)\n"", ""@wraps(VAR_7)...\n"", ""if VAR_12:\n"", ""return VAR_7(VAR_8[0], VAR_1, *VAR_8[1:], **kwargs)\n"", ""return VAR_7(VAR_1, *VAR_8, **kwargs)\n""]",0
"[""@wraps(VAR_7)...\n"", ""if not app.config.get('USE_AUTH'):\n"", ""return VAR_7(*VAR_9, **kwargs)\n"", ""FUNC_0()\n"", ""return VAR_7(*VAR_9, **kwargs)\n"", ""logging.warning('require_logout(): calling log_out()')\n"", ""VAR_16 = VAR_1.log_out()\n"", ""if VAR_16.headers.get('Location') == url_for('goodbye'):\n"", ""return VAR_7(*VAR_9, **kwargs)\n"", ""return VAR_16\n""]",0
"[""def FUNC_2(VAR_0, VAR_2):...\n"", ""return os.chmod(VAR_0, VAR_2, follow_symlinks=os.chmod not in os.\n    supports_follow_symlinks)\n""]",0
"[""def FUNC_8(self, VAR_5=None, VAR_6=None, VAR_7=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_13 = iter(self.__entities)\n"", ""if not VAR_5 is None:\n"", ""VAR_13 = VAR_5(VAR_13)\n"", ""if not VAR_6 is None:\n"", ""VAR_13 = iter(VAR_6(VAR_13))\n"", ""if not VAR_7 is None:\n"", ""VAR_13 = islice(VAR_13, VAR_7.start, VAR_7.stop)\n"", ""return VAR_13\n""]",0
"[""def FUNC_7(self):...\n"", ""return self.content\n""]",0
"[""def FUNC_35(VAR_29):...\n"", ""VAR_40 = VAR_29.group('name')\n"", ""VAR_16 = VAR_11[VAR_40]\n"", ""if VAR_15:\n"", ""if VAR_13 and VAR_16 == VAR_14:\n"", ""return '{{{}}}'.format(VAR_40)\n"", ""if VAR_12:\n"", ""return str(VAR_16)\n"", ""return VAR_14\n""]",0
"[""import sys\n"", ""import logging\n"", ""from django.db import connection, DatabaseError\n"", ""from reviewus.settings import DEBUG\n"", ""VAR_0 = logging.getLogger(__name__)\n"", ""VAR_1 = None\n"", ""VAR_2 = None\n"", ""def __new__(VAR_3):...\n"", ""if CLASS_0.instance is None:\n"", ""CLASS_0.instance = object.__new__(VAR_3)\n"", ""return CLASS_0.instance\n""]",0
"[""@VAR_0.route('/delete_crawl', methods=['POST'])...\n"", ""VAR_7 = request.form['cid']\n"", ""VAR_28 = VAR_1.connection.cursor()\n"", ""VAR_29 = VAR_28.execute('DELETE FROM Crawls WHERE cid = %s' % VAR_7)\n"", ""VAR_1.connection.commit()\n"", ""VAR_28.close()\n"", ""flash('Crawl successfully removed', 'success')\n"", ""return redirect(url_for('dashboard'))\n""]",1
"[""@classmethod...\n"", ""assert engine\n"", ""VAR_9 = text(\n    'SELECT * FROM users WHERE username = :username AND expire_date is null')\n"", ""VAR_7 = engine.connect()\n"", ""VAR_10 = False if VAR_7.execute(VAR_9, VAR_1=username).fetchone(\n    ) is None else True\n"", ""VAR_7.close()\n"", ""return VAR_10\n""]",1
"[""@login_required()...\n"", ""VAR_3 = get_object_or_404(DataGroup, VAR_2=pk)\n"", ""VAR_18 = DataGroupForm(VAR_0.POST or None, instance=datagroup)\n"", ""VAR_16 = f'Update Data Group for Data Source \""{VAR_3.data_source}\""'\n"", ""if VAR_18.is_valid():\n"", ""if VAR_18.has_changed():\n"", ""VAR_18.referer = VAR_0.META.get('HTTP_REFERER', None)\n"", ""VAR_18.save()\n"", ""return redirect('data_group_detail', VAR_2=datagroup.id)\n"", ""if VAR_3.extracted_docs():\n"", ""VAR_18.fields['group_type'].disabled = True\n"", ""VAR_19 = GroupType.objects.all()\n"", ""for group in VAR_19:\n"", ""group.codes = DocumentType.objects.filter(group_type=group)\n"", ""return render(VAR_0, VAR_1, {'datagroup': VAR_3, 'form': VAR_18, 'header':\n    VAR_16, 'groups': VAR_19})\n""]",0
"[""def FUNC_3(self):...\n"", ""VAR_9 = \""select userid from users where name='%s';\"" % self.name\n"", ""VAR_5 = sql.queryDB(self.conn, VAR_9)\n"", ""return VAR_5[0][0]\n""]",1
"[""def FUNC_43(self, VAR_41, VAR_43):...\n"", ""self[VAR_41:VAR_41 + 1] = VAR_43\n"", ""VAR_55 = len(VAR_43) - 1\n"", ""for VAR_40, (i, j) in self._names.items():\n"", ""if i > VAR_41:\n"", ""self._names[VAR_40] = i + VAR_55, j + VAR_55\n"", ""if i == VAR_41:\n"", ""self.set_name(VAR_40, i, VAR_42=i + len(items))\n""]",0
"[""def FUNC_1(VAR_2, VAR_3, VAR_4=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_29, VAR_30 = [], {}\n"", ""if not VAR_2:\n"", ""return VAR_29\n"", ""if VAR_3:\n"", ""for VAR_64 in VAR_3:\n"", ""for VAR_6 in VAR_2:\n"", ""VAR_63 = VAR_3[VAR_64]\n"", ""VAR_50 = True\n"", ""return VAR_29\n"", ""if not isinstance(VAR_63, (tuple, list)):\n"", ""for VAR_64, VAR_63 in iteritems(VAR_30):\n"", ""if VAR_63 is True:\n"", ""VAR_30[VAR_64] = VAR_63\n"", ""if not VAR_54.compare(getattr(VAR_6, VAR_64, None), VAR_63[0], VAR_63[1]):\n"", ""if VAR_50:\n"", ""VAR_63 = 'not None', VAR_63\n"", ""if VAR_63 is False:\n"", ""VAR_50 = False\n"", ""VAR_29.append(VAR_6)\n"", ""VAR_63 = 'None', VAR_63\n"", ""if isinstance(VAR_63, string_types) and VAR_63.startswith('^'):\n"", ""if VAR_4 and len(VAR_29) - 1 == VAR_4:\n"", ""VAR_63 = '^', VAR_63[1:]\n"", ""VAR_63 = '=', VAR_63\n""]",0
"[""def FUNC_7(self, VAR_2, VAR_1=None):...\n"", ""self.filter_string = self.filter_func(VAR_2, VAR_1)\n"", ""print(self.filter_string)\n""]",1
"[""def FUNC_0(self, VAR_2, VAR_3, VAR_4, VAR_5):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = []\n"", ""VAR_7 = self.pool.get('ir.model.data')\n"", ""VAR_8 = self.pool.get('res.users').browse(VAR_2, VAR_3, VAR_3).company_id.id\n"", ""VAR_9 = self.pool.get('account.bank.statement')\n"", ""VAR_10 = self.pool.get('ir.sequence')\n"", ""VAR_11 = self.pool.get('account.journal')\n"", ""VAR_2.execute(\n    'select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id'\n     % VAR_3)\n"", ""VAR_12 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""VAR_2.execute('string' % ','.join(map(lambda x: \""'\"" + str(x) + \""'\"", VAR_12)))\n"", ""VAR_13 = map(lambda x1: x1[0], VAR_2.fetchall())\n"", ""for journal in VAR_11.browse(VAR_2, VAR_3, VAR_13):\n"", ""VAR_4 = VAR_9.search(VAR_2, VAR_3, [('state', '!=', 'confirm'), ('user_id',\n    '=', VAR_3), ('journal_id', '=', journal.id)])\n"", ""VAR_14 = self.pool.get('ir.model.data')\n"", ""if len(VAR_4):\n"", ""VAR_15 = VAR_14._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_tree')\n"", ""VAR_17 = ''\n"", ""VAR_16 = VAR_14._get_id(VAR_2, VAR_3, 'account', 'view_bank_statement_form2')\n"", ""if journal.sequence_id:\n"", ""if VAR_15:\n"", ""VAR_17 = VAR_10.get_id(VAR_2, VAR_3, journal.sequence_id.id)\n"", ""VAR_17 = VAR_10.get(VAR_2, VAR_3, 'account.bank.statement')\n"", ""VAR_15 = VAR_14.browse(VAR_2, VAR_3, VAR_15, VAR_5=context).res_id\n"", ""if VAR_16:\n"", ""VAR_18 = VAR_9.create(VAR_2, VAR_3, {'journal_id': journal.id, 'company_id':\n    VAR_8, 'user_id': VAR_3, 'state': 'open', 'name': VAR_17,\n    'starting_details_ids': VAR_9._get_cash_close_box_lines(VAR_2, VAR_3, [])})\n"", ""VAR_16 = VAR_14.browse(VAR_2, VAR_3, VAR_16, VAR_5=context).res_id\n"", ""return {'domain': \""[('state','=','open')]\"", 'name': 'Open Statement',\n    'view_type': 'form', 'view_mode': 'tree,form', 'res_model':\n    'account.bank.statement', 'views': [(VAR_15, 'tree'), (VAR_16, 'form')],\n    'type': 'ir.actions.act_window'}\n"", ""VAR_9.button_open(VAR_2, VAR_3, [VAR_18], VAR_5)\n""]",1
"[""def FUNC_2():...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_2 = 'string'\n"", ""VAR_3 = psycopg2.connect(database=DBNAME)\n"", ""VAR_4 = VAR_3.cursor()\n"", ""VAR_4.execute(VAR_2)\n"", ""VAR_5 = VAR_4.fetchall()\n"", ""VAR_3.close()\n"", ""return VAR_5\n""]",1
"[""def FUNC_7(self):...\n"", ""url_helper.urllib2.urlopen(mox.IgnoreArg(), mox.IgnoreArg(), timeout=mox.\n    IgnoreArg()).AndRaise(urllib2.URLError('url'))\n"", ""time.sleep(mox.IgnoreArg())\n"", ""VAR_2 = 'True'\n"", ""url_helper.urllib2.urlopen(mox.IgnoreArg(), mox.IgnoreArg(), timeout=mox.\n    IgnoreArg()).AndReturn(StringIO.StringIO(VAR_2))\n"", ""self._mox.ReplayAll()\n"", ""self.assertEqual(url_helper.UrlOpen('url', max_tries=2), VAR_2)\n"", ""self._mox.VerifyAll()\n""]",1
"[""import os\n"", ""import shutil\n"", ""import uuid\n"", ""from factotum import settings\n"", ""from pathlib import Path, PurePath\n"", ""from django.db import models\n"", ""from .common_info import CommonInfo\n"", ""from django.urls import reverse\n"", ""from django.db.models.signals import pre_save\n"", ""from django.dispatch import receiver\n"", ""from model_utils import FieldTracker\n"", ""from django.core.exceptions import ValidationError\n"", ""from .group_type import GroupType\n"", ""from .extracted_text import ExtractedText\n"", ""from .extracted_cpcat import ExtractedCPCat\n"", ""from .extracted_chemical import ExtractedChemical\n"", ""from .extracted_functional_use import ExtractedFunctionalUse\n"", ""from .extracted_list_presence import ExtractedListPresence\n"", ""def FUNC_0(VAR_0, VAR_1):...\n"", ""VAR_5 = VAR_0.name.replace(' ', '_')\n"", ""VAR_6 = '{0}/{0}_{1}'.format(VAR_5, VAR_1)\n"", ""return VAR_6\n""]",1
"[""def FUNC_11(self):...\n"", ""self.assertFalse(self.course_module.is_after_open(self.yesterday))\n"", ""self.assertTrue(self.course_module.is_after_open(self.today))\n"", ""self.assertTrue(self.course_module.is_after_open())\n"", ""self.assertTrue(self.course_module.is_after_open(self.tomorrow))\n"", ""self.assertTrue(self.course_module.is_after_open(self.two_days_from_now))\n""]",0
"[""def FUNC_0(self, VAR_2):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_9 = os.path.join(VAR_1, 'saml2_settings.py')\n"", ""VAR_2.update({'SAML2_LOGIN_REDIRECT_URL': '/', 'SAML2_LOGOUT_REDIRECT_URL':\n    '/logged-out', 'SAML2_SETTINGS_MODULE': VAR_9, 'TOKEN_LOGIN_SHARED_KEY':\n    'shared_secret', 'TOKEN_LOGIN_SUCCESS_REDIRECT_URL':\n    'http://test.localhost/success', 'TOKEN_LOGIN_FAILURE_REDIRECT_URL':\n    'http://test.localhost/failure'})\n"", ""return VAR_2\n""]",1
"[""def FUNC_23(self, VAR_14):...\n"", """"]",0
"[""@VAR_0.route('/statistics/<int:cid>')...\n"", ""VAR_28 = VAR_1.connection.cursor()\n"", ""VAR_29 = VAR_28.execute('SELECT * FROM Crawls WHERE cid = %s' % VAR_7)\n"", ""VAR_30 = VAR_28.fetchall()[0]\n"", ""VAR_28.close()\n"", ""print(VAR_10.get('stats', None))\n"", ""print(VAR_30['stats'])\n"", ""VAR_31 = json.loads(VAR_30['stats'])\n"", ""VAR_32 = json.loads(VAR_30['hierarchy'])\n"", ""VAR_33 = VAR_31.items()\n"", ""VAR_34 = sum([subdict['n_tables_pages'] for filename, subdict in VAR_33])\n"", ""VAR_35 = sum([subdict['n_table_rows'] for filename, subdict in VAR_33])\n"", ""VAR_36 = sum([subdict['table_sizes']['medium'] for filename, subdict in VAR_33]\n    )\n"", ""VAR_37 = sum([subdict['table_sizes']['small'] for filename, subdict in VAR_33])\n"", ""VAR_38 = sum([subdict['table_sizes']['large'] for filename, subdict in VAR_33])\n"", ""VAR_39 = [subdict['creation_date'] for filename, subdict in VAR_33]\n"", ""VAR_40 = list(map(lambda str: pdf_date_format_to_datetime(str), VAR_39))\n"", ""if len(VAR_40) > 0:\n"", ""VAR_50 = min(VAR_40)\n"", ""VAR_50 = 'None'\n"", ""VAR_51 = max(VAR_40)\n"", ""VAR_51 = 'None'\n"", ""return render_template('statistics.html', VAR_21=crawl['pdf_crawled'],\n    VAR_24=crawl['pdf_processed'], VAR_34=n_tables, VAR_35=n_rows, n_errors\n    =crawl['process_errors'], VAR_17=crawl['domain'], VAR_37=small_tables,\n    VAR_36=medium_tables, VAR_38=large_tables, VAR_22=json_stats, hierarchy\n    =json_hierarchy, end_time=crawl['crawl_date'], crawl_total_time=round(\n    crawl['crawl_total_time'] / 60.0, 1), VAR_27=round(crawl[\n    'proc_total_time'] / 60.0, 1), VAR_50=oldest_pdf, VAR_51=most_recent_pdf)\n""]",1
"[""def FUNC_19(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return self.cursor.execute('select storeid, storename from store')\n""]",0
"[""def FUNC_0(VAR_0, VAR_1):...\n"", ""if VAR_0.exception != 'None':\n"", ""return False\n"", ""VAR_2 = VAR_0.answer.split('.')[3]\n"", ""return VAR_2 in VAR_1\n""]",1
"[""def FUNC_7(*VAR_12):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = np.asarray(VAR_12[0])\n"", ""if VAR_1.shape[0] != VAR_1.shape[1]:\n"", ""if not np.allclose(VAR_1, VAR_1.conj().T, atol=tolerance):\n"", ""return VAR_1\n""]",0
"[""def FUNC_3(self):...\n"", ""self.handled_resp = 1\n"", ""self.handled_remote = 1\n"", ""self.handled_args = 1\n"", ""self.handled_kwargs = 1\n""]",0
"[""def FUNC_1(VAR_1, VAR_3):...\n"", """"]",0
"[""import numpy as np\n"", ""import matplotlib.pyplot as plt\n"", ""import pandas as pd\n"", ""VAR_0 = pd.read_csv('Churn_Modelling.csv')\n"", ""VAR_1 = VAR_0.iloc[:, 3:13].values\n"", ""VAR_2 = VAR_0.iloc[:, (13)].values\n"", ""from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n"", ""VAR_3 = LabelEncoder()\n"", ""VAR_1[:, (1)] = VAR_3.fit_transform(VAR_1[:, (1)])\n"", ""VAR_4 = LabelEncoder()\n"", ""VAR_1[:, (2)] = VAR_4.fit_transform(VAR_1[:, (2)])\n"", ""VAR_5 = OneHotEncoder(categorical_features=[1])\n"", ""VAR_1 = VAR_5.fit_transform(VAR_1).toarray()\n"", ""VAR_1 = VAR_1[:, 1:]\n"", ""from sklearn.model_selection import train_test_split\n"", ""VAR_6, VAR_7, VAR_8, VAR_9 = train_test_split(VAR_1, VAR_2, test_size=0.2,\n    random_state=0)\n"", ""from sklearn.preprocessing import StandardScaler\n"", ""VAR_10 = StandardScaler()\n"", ""VAR_6 = VAR_10.fit_transform(VAR_6)\n"", ""VAR_7 = VAR_10.transform(VAR_7)\n"", ""import keras\n"", ""from keras.models import Sequential\n"", ""from keras.layers import Dense\n"", ""VAR_11 = Sequential()\n"", ""VAR_11.add(Dense(units=6, kernel_initializer='uniform', activation='relu',\n    input_dim=11))\n"", ""VAR_11.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n"", ""VAR_11.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n"", ""VAR_11.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\n    'accuracy'])\n"", ""VAR_11.fit(VAR_6, VAR_8, batch_size=10, epochs=100)\n"", ""VAR_12 = VAR_11.predict(VAR_7)\n"", ""VAR_12 = VAR_12 > 0.5\n"", ""from sklearn.metrics import confusion_matrix\n"", ""VAR_13 = confusion_matrix(VAR_9, VAR_12)\n""]",1
"[""def __init__(self, VAR_0, VAR_1, VAR_2=False, VAR_3=True):...\n"", ""self.address = VAR_0.strip()\n"", ""self.local = False\n"", ""self.hostname = None\n"", ""self.config = VAR_1\n"", ""self.sos_path = None\n"", ""self.retrieved = False\n"", ""self.hash_retrieved = False\n"", ""self.sos_info = {'version': None, 'enabled': [], 'disabled': [], 'options':\n    [], 'presets': []}\n"", ""VAR_28 = ['localhost', '127.0.0.1', self.config['hostname']]\n"", ""self.logger = logging.getLogger('sos_collector')\n"", ""self.console = logging.getLogger('sos_collector_console')\n"", ""if self.address not in VAR_28 or VAR_2:\n"", ""self.connected = self.open_ssh_session()\n"", ""self.connected = True\n"", ""self.sftp = self.client.open_sftp()\n"", ""self.local = True\n"", ""if self.connected and VAR_3:\n"", ""self.host = self.determine_host()\n"", ""self._set_sos_prefix(self.host.set_sos_prefix())\n"", ""if not self.host:\n"", ""self.connected = False\n"", ""self.log_debug('Host facts found to be %s' % self.host.report_facts())\n"", ""self.close_ssh_session()\n"", ""self.get_hostname()\n"", ""return None\n"", ""self._load_sos_info()\n""]",0
"[""def FUNC_17(self, VAR_20=None, VAR_21=None, VAR_1=None, VAR_22=0, VAR_23=None):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_1 = FUNC_0(VAR_1)\n"", ""VAR_59 = ''\n"", ""if VAR_23:\n"", ""VAR_23 = [('*' if c == 'Default' else c) for c in VAR_23]\n"", ""if VAR_22:\n"", ""VAR_59 = \"" AND (CATEGORY = '\""\n"", ""VAR_59 += ' AND STATUS = \""Failed\""'\n"", ""VAR_60 = 'SELECT COUNT(*) FROM history WHERE name LIKE ?'\n"", ""VAR_59 += \""' OR CATEGORY = '\"".join(VAR_23)\n"", ""VAR_61 = self.execute(VAR_60 + VAR_59, (VAR_1,))\n"", ""VAR_59 += \""' )\""\n"", ""VAR_62 = -1\n"", ""if VAR_61:\n"", ""if not VAR_20:\n"", ""VAR_62 = self.c.fetchone().get('COUNT(*)')\n"", ""VAR_20 = 0\n"", ""if not VAR_21:\n"", ""VAR_21 = VAR_62\n"", ""VAR_58 = VAR_1, VAR_20, VAR_21\n"", ""VAR_60 = 'SELECT * FROM history WHERE name LIKE ?'\n"", ""VAR_57 = self.execute(VAR_60 + VAR_59 +\n    ' ORDER BY completed desc LIMIT ?, ?', VAR_58)\n"", ""if VAR_57:\n"", ""VAR_64 = self.c.fetchall()\n"", ""VAR_64 = []\n"", ""VAR_63 = len(VAR_64)\n"", ""VAR_64 = [FUNC_3(VAR_11) for VAR_11 in VAR_64]\n"", ""return VAR_64, VAR_63, VAR_62\n""]",1
"[""def FUNC_6(self):...\n"", ""VAR_83 = []\n"", ""if self.rate_user and VAR_101.user_is_loggedin:\n"", ""VAR_83.append('user' + VAR_100(VAR_101.user._id36))\n"", ""if self.rate_ip:\n"", ""VAR_83.append('ip' + VAR_100(VAR_102.ip))\n"", ""VAR_84 = cache.get_multi(VAR_83, self.prefix)\n"", ""if VAR_84:\n"", ""VAR_87 = VAR_55(VAR_84.values())\n"", ""VAR_99 = utils.timeuntil(VAR_87)\n"", ""VAR_101.errors.add(errors.RATELIMIT, {'time': VAR_99})\n""]",0
"[""def FUNC_5(self, VAR_5, VAR_1, VAR_6, VAR_7, VAR_8):...\n"", ""VAR_20 = 'string' % (VAR_1, VAR_6, VAR_7, VAR_8, VAR_5)\n"", ""self.c.execute(VAR_20)\n""]",1
"[""def FUNC_36(self, VAR_20):...\n"", ""return ''.join(FUNC_8(VAR_20)) == '*'\n""]",0
"[""def FUNC_6():...\n"", ""VAR_2.test_locals = dict()\n"", ""VAR_2.test_locals.update(VAR_8.__dict__)\n"", ""exec(VAR_3, VAR_2.test_locals)\n""]",0
"[""@VAR_0.route('/login', methods=['GET', 'POST'])...\n"", ""if request.method == 'POST':\n"", ""VAR_42 = request.form['username']\n"", ""return render_template('login.html')\n"", ""VAR_52 = request.form['password']\n"", ""VAR_28 = VAR_1.connection.cursor()\n"", ""VAR_29 = VAR_28.execute('SELECT * FROM Users WHERE username = %s', [VAR_42])\n"", ""if VAR_29 > 0:\n"", ""VAR_54 = VAR_28.fetchone()\n"", ""VAR_55 = 'Username not found'\n"", ""VAR_44 = VAR_54['password']\n"", ""return render_template('login.html', VAR_55=error)\n"", ""if sha256_crypt.verify(VAR_52, VAR_44):\n"", ""VAR_10['logged_in'] = True\n"", ""VAR_55 = 'Invalid login'\n"", ""VAR_10['username'] = VAR_42\n"", ""return render_template('login.html', VAR_55=error)\n"", ""flash('You are now logged in', 'success')\n"", ""return redirect(url_for('index'))\n""]",1
"[""def FUNC_15(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_9 = []\n"", ""for student in self.students:\n"", ""VAR_14 = [self.results[student.id][VAR_0.id] for VAR_0 in self.exercises]\n"", ""return VAR_9\n"", ""VAR_15 = sum(g for g in VAR_14 if g is not None)\n"", ""VAR_9.append((student, VAR_14, VAR_15))\n""]",0
"[""def FUNC_17(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7, VAR_12 = self.make_xsrf_handling_app(VAR_3='X-Some')\n"", ""VAR_17 = VAR_7.get('/request').body\n"", ""VAR_7.post('/request', VAR_20={'X-Some': token})\n"", ""self.assertEqual([('POST', True)], VAR_12)\n""]",0
"[""@classmethod...\n"", ""return [lambda _request: VAR_22]\n""]",0
"[""@utils.add_cmd...\n"", ""\""\""\""docstring\""\""\""\n"", ""permissions.checkPermissions(VAR_0, VAR_1, ['networks.disconnect'])\n"", ""VAR_5 = VAR_2[0]\n"", ""VAR_0.error('Not enough arguments (needs 1: network name (case sensitive)).')\n"", ""VAR_0.reply(\n    \""Done. If you want to reconnect this network, use the 'rehash' command.\"")\n"", ""VAR_4 = world.networkobjects[VAR_5]\n"", ""return\n"", ""control.remove_network(VAR_4)\n""]",0
"[""def FUNC_6(VAR_1):...\n"", ""VAR_6 = sqlite3.connect('database.db')\n"", ""VAR_7 = VAR_6.cursor()\n"", ""return VAR_7.execute(\n    \""SELECT Date FROM ChallengeRankings WHERE SubmissionID = '\"" + str(VAR_1\n    .id) + \""'\"").fetchone()[0]\n""]",1
"[""def __init__(self, VAR_25, VAR_10):...\n"", ""self.flag = VAR_25\n"", ""def FUNC_2():...\n"", ""super(CLASS_6, self).__init__(slideParser.parse(VAR_10, slideLexer))\n"", ""CLASS_2.parsingQ.insert(0, FUNC_2)\n""]",1
"[""def __init__(self, VAR_25, VAR_26):...\n"", ""self.fd = VAR_25\n"", ""self.backup = os.dup(VAR_25)\n"", ""VAR_44, VAR_47 = VAR_26\n"", ""self.newfd = VAR_26\n"", ""self.newfd = os.open(VAR_44, VAR_47)\n""]",1
"[""@staticmethod...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_11 = 'string'.format(VAR_1)\n"", ""VAR_9 = db.engine.execute(VAR_11)\n"", ""if VAR_9.rowcount == 0:\n"", ""VAR_12 = ProjectContributionsDTO()\n"", ""for row in VAR_9:\n"", ""VAR_2 = row[0] or row[3]\n"", ""return VAR_12\n"", ""VAR_26 = UserContribution()\n"", ""VAR_26.username = row[1] if row[1] else row[4]\n"", ""VAR_26.mapped = row[2] if row[2] else 0\n"", ""VAR_26.validated = row[5] if row[5] else 0\n"", ""VAR_12.user_contributions.append(VAR_26)\n""]",1
"[""def FUNC_8(VAR_15):...\n"", ""VAR_32 = VAR_15.to_dict()\n"", ""VAR_32['tags'] = AnnTag.get_ann_tags(VAR_15.id, self.sql_session)\n"", ""return VAR_32\n""]",0
"[""def FUNC_3(self, VAR_2, VAR_1):...\n"", ""VAR_4 = 'insert into post_like values(%d,%d);' % (VAR_2, VAR_1)\n"", ""VAR_5 = sql.insertDB(self.conn, VAR_4)\n"", ""return VAR_5\n""]",1
"[""@staticmethod...\n"", ""def FUNC_13(VAR_9, VAR_7, VAR_11, VAR_10):...\n"", ""if VAR_11 == 'POST':\n"", ""return CLASS_0.session.post(FUNC_2(VAR_7), VAR_9=ToUtf8Json(data), headers=\n    _HEADERS, VAR_10=timeout)\n"", ""if VAR_11 == 'GET':\n"", ""return CLASS_0.session.get(FUNC_2(VAR_7), headers=_HEADERS, VAR_10=timeout)\n"", ""@retries(5, delay=0.5, backoff=1.5)...\n"", ""if VAR_11 == 'POST':\n"", ""return requests.post(FUNC_2(VAR_7), VAR_9=ToUtf8Json(data), headers=_HEADERS)\n"", ""if VAR_11 == 'GET':\n"", ""return requests.get(FUNC_2(VAR_7), headers=_HEADERS)\n"", ""if not FUNC_3():\n"", ""return VAR_1.submit(FUNC_14, VAR_9, VAR_7, VAR_11)\n"", ""return FUNC_13(VAR_9, VAR_7, VAR_11, VAR_10)\n""]",1
"[""from django.http import HttpResponse, HttpResponseRedirect\n"", ""from django.shortcuts import get_object_or_404, render, redirect\n"", ""from django.views.generic import ListView, DetailView\n"", ""from django.views.generic.edit import CreateView, UpdateView\n"", ""from pure_pagination.mixins import PaginationMixin\n"", ""from django.db.models import Q, Count\n"", ""from .models import tweet, Hunt\n"", ""from .forms import HuntForm\n"", ""import csv\n"", ""from io import StringIO, BytesIO\n"", ""from codecs import BOM_UTF8\n"", ""from pytz import timezone\n"", ""from django.http import JsonResponse\n"", ""from urllib.parse import urlparse\n"", ""from http.client import HTTPSConnection\n"", ""VAR_3 = 'twitter_hunter/index.html'\n"", ""VAR_4 = 'hts'\n"", ""VAR_5 = 30\n"", ""def FUNC_6(self, **VAR_6):...\n"", ""VAR_19 = super().get_context_data(**kwargs)\n"", ""return VAR_19\n""]",1
"[""def FUNC_9(self, VAR_9: Message) ->CLASS_0:...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_7 = self.users.get(VAR_9.chat.id, None)\n"", ""if VAR_7:\n"", ""return VAR_7\n"", ""log.debug(\""Looking up the user in the database as it doesn't appear in cache\"")\n"", ""VAR_10 = (\n    f'SELECT first_name, nickname, last_name, language FROM users WHERE chat_id={VAR_9.chat.id}'\n    )\n"", ""VAR_19 = db.execute_query(VAR_10)\n"", ""log.error('Cannot lookup the user with chat_id %d in database', VAR_9.chat.id)\n"", ""if not VAR_19.rowcount:\n"", ""VAR_17 = VAR_9.from_user\n"", ""log.info('Adding totally new user to the system...')\n"", ""log.debug('User %d has been found in the database', VAR_9.chat.id)\n"", ""VAR_7 = self.add_new_one(VAR_9.chat.id, VAR_17.first_name, VAR_17.last_name,\n    VAR_17.username, VAR_4='en-US', VAR_8=False)\n"", ""VAR_17 = VAR_9.from_user\n"", ""VAR_21 = VAR_19.fetchall()[0]\n"", ""return VAR_7\n"", ""VAR_7 = self.add_new_one(VAR_9.chat.id, VAR_17.first_name, VAR_17.last_name,\n    VAR_17.username, VAR_4='en-US')\n"", ""VAR_7 = self.add_new_one(VAR_9.chat.id, *VAR_21, VAR_8=False)\n"", ""bot.send_message(config.MY_TELEGRAM, text=f'You have a new user! {user}')\n"", ""return VAR_7\n"", ""log.info('You have a new user! Welcome %s', VAR_7)\n""]",1
"[""@app.route('/json/politicians/all')...\n"", ""VAR_9 = Politician.all()\n"", ""VAR_7 = []\n"", ""for pol in VAR_9:\n"", ""VAR_23 = pol.name.title().split(' ')\n"", ""VAR_10 = Response(VAR_22=json.dumps(politicians), status=200, mimetype=\n    'application/json')\n"", ""VAR_2 = {'value': pol.name.title(), 'tokens': VAR_23, 'search_count': pol.\n    search_count}\n"", ""return VAR_10\n"", ""VAR_7.append(VAR_2)\n""]",0
"[""def FUNC_4(VAR_0):...\n"", ""VAR_9 = VAR_0.last_attempted_swarming_task_id\n"", ""VAR_10 = VAR_0.last_attempted_build_number\n"", ""VAR_11 = VAR_9 if VAR_9 and VAR_9.lower() not in (NO_TASK, NO_TASK_EXCEPTION\n    ) else None\n"", ""return {'task_id': VAR_11, 'build_number': VAR_10}\n""]",0
"[""def FUNC_3(self):...\n"", ""assert self.initialised, 'Initialise the map from a file first!'\n"", ""self.turningNodes = []\n"", ""for VAR_23 in range(self.mapHeight):\n"", ""for VAR_22 in range(self.mapWidth):\n"", ""if self.stateMap[VAR_22][VAR_23].isTraversable():\n"", ""self.stateMap[VAR_22][VAR_23].identifyTurning()\n"", ""if self.stateMap[VAR_22][VAR_23].isTurning():\n"", ""self.turningNodes.append([VAR_22, VAR_23])\n""]",0
"[""def FUNC_0(self, VAR_1):...\n"", ""\""\""\""docstring\""\""\""\n"", ""return database_utilities.execute_query(\n    f\""select * from users where user_id = '{VAR_1}'\"")\n""]",1
"[""@api.public...\n"", ""VAR_6.assertEqual(VAR_5, api.get_current_identity())\n"", ""self.response.write('OK')\n""]",0
"[""def FUNC_5(self, VAR_2, VAR_1, VAR_3):...\n"", ""self.cursor.execute('string' % (VAR_1, VAR_2, VAR_3))\n"", ""self.db.commit()\n""]",1
"[""def FUNC_0(*VAR_0, **VAR_1):...\n"", ""def FUNC_5(VAR_12):...\n"", ""def FUNC_9(self, *VAR_15, **VAR_75):...\n"", ""for validator in VAR_0:\n"", ""if VAR_102.method == 'POST' and hasattr(self, 'ajax_login_redirect'):\n"", ""return FUNC_9\n"", ""validator(VAR_75)\n"", ""VAR_16 = self.build_arg_list(VAR_12, VAR_75)\n"", ""return self.ajax_login_redirect('/')\n"", ""return self.intermediate_redirect('/login')\n"", ""for VAR_110, validator in VAR_1.iteritems():\n"", ""VAR_16[VAR_110] = validator(VAR_75)\n"", ""return VAR_12(self, *VAR_15, **kw)\n""]",0
"[""import sqlobject\n"", ""import vdm.sqlobject.base as vdmbase\n"", ""import vdm.base as vdmbase\n"", ""VAR_16 = 'name'\n"", ""from vdm.sqlobject.base import State\n"", ""from vdm.base import State\n"", ""VAR_0 = sqlobject.UnicodeCol(alternateID=True)\n"", ""VAR_1 = sqlobject.MultipleJoin('Package')\n"", ""VAR_2 = sqlobject.ForeignKey('Package', cascade=True)\n"", ""VAR_3 = sqlobject.UnicodeCol(default=None)\n"", ""VAR_4 = sqlobject.UnicodeCol(default=None)\n"", ""VAR_5 = sqlobject.UnicodeCol(default=None)\n"", ""VAR_6 = sqlobject.ForeignKey('License', default=None)\n"", ""VAR_7 = sqlobject.UnicodeCol(default=None)\n"", ""VAR_2 = sqlobject.ForeignKey('Tag', cascade=True)\n"", ""VAR_2 = sqlobject.ForeignKey('PackageTag', cascade=True)\n"", ""VAR_8 = CLASS_1\n"", ""VAR_9 = vdmbase.get_attribute_names(VAR_8)\n"", ""VAR_0 = sqlobject.UnicodeCol(alternateID=True)\n"", ""VAR_10 = [('tags', 'ckan.models.package', 'Tag', 'PackageTag')]\n"", ""def FUNC_0(self, VAR_11):...\n"", ""VAR_14 = self.revision.model.tags.get(VAR_11)\n"", ""VAR_14 = self.transaction.model.tags.create(VAR_0=tagname)\n"", ""self.tags.create(VAR_14=tag)\n"", ""VAR_8 = CLASS_2\n"", ""VAR_0 = sqlobject.UnicodeCol(alternateID=True)\n"", ""VAR_9 = vdmbase.get_attribute_names(VAR_8)\n"", ""VAR_10 = [('packages', 'ckan.models.package', 'Package', 'PackageTag')]\n"", ""@classmethod...\n"", ""VAR_17 = str(VAR_12)\n"", ""VAR_18 = \""UPPER(tag.name) LIKE UPPER('%%%s%%')\"" % VAR_17\n"", ""return self.select(VAR_18)\n""]",1
"[""def FUNC_22(VAR_48):...\n"", ""for VAR_29, VAR_51 in sorted(VAR_48.options.items()):\n"", ""if VAR_51 is None:\n"", ""VAR_46.append('unset(%s CACHE)\\n' % VAR_29)\n"", ""if isinstance(VAR_51, bool):\n"", ""VAR_79 = 'BOOL'\n"", ""VAR_79 = 'STRING'\n"", ""VAR_51 = 'ON' if VAR_51 else 'OFF'\n"", ""VAR_46.append('set(%s %s CACHE INTERNAL \""\"" FORCE)\\n' % (VAR_29, VAR_51))\n""]",0
"[""def FUNC_5(self):...\n"", ""VAR_15 = Hunt.objects.order_by('id')\n"", ""VAR_15 = VAR_15.annotate(count=Count('events'))\n"", ""return VAR_15\n""]",0
"[""def FUNC_3(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_6 = jc.Contract()\n"", ""return st.OperationContract(self.agent.make_create_app_operation(VAR_1=self\n    .bindings, application=self.TEST_APP), VAR_6=contract)\n""]",0
"[""def FUNC_20(self, VAR_6, VAR_7, VAR_8):...\n"", ""\""\""\""docstring\""\""\""\n"", ""for VAR_33 in self._cache.values():\n"", ""if VAR_6 and VAR_33.version < VAR_6:\n"", ""if VAR_7 and VAR_33.version > VAR_7:\n"", ""if VAR_8 and not VAR_33.jdk:\n"", ""return VAR_33\n""]",0
"[""def __eq__(self, VAR_22):...\n"", ""if isinstance(VAR_22, CLASS_3):\n"", ""return VAR_22._r_item_ == self._r_item_\n"", ""return VAR_22 == self._r_item_\n""]",1
"[""def FUNC_3(self):...\n"", ""self.assertTrue(self.client.login(VAR_1='autotest-1', VAR_2='password'))\n"", ""VAR_6 = self.client.get('/api/apps')\n"", ""VAR_8 = VAR_6.data['results'][0]['id']\n"", ""VAR_5 = '/api/apps/{}/perms'.format(VAR_8)\n"", ""VAR_7 = {'username': 'autotest-2'}\n"", ""VAR_6 = self.client.post(VAR_5, json.dumps(VAR_7), content_type=\n    'application/json')\n"", ""self.assertEqual(VAR_6.status_code, 201)\n"", ""self.assertTrue(self.client.login(VAR_1='autotest-2', VAR_2='password'))\n"", ""VAR_6 = self.client.get('/api/apps')\n"", ""self.assertEqual(VAR_6.status_code, 200)\n"", ""self.assertEqual(len(VAR_6.data['results']), 2)\n"", ""VAR_5 = '/api/apps/{}/perms/{}'.format(VAR_8, 'autotest-2')\n"", ""VAR_6 = self.client.delete(VAR_5, content_type='application/json')\n"", ""self.assertEqual(VAR_6.status_code, 403)\n"", ""self.assertIsNone(VAR_6.data)\n"", ""self.assertTrue(self.client.login(VAR_1='autotest-1', VAR_2='password'))\n"", ""VAR_6 = self.client.delete(VAR_5, content_type='application/json')\n"", ""self.assertEqual(VAR_6.status_code, 204)\n"", ""self.assertIsNone(VAR_6.data)\n"", ""self.assertTrue(self.client.login(VAR_1='autotest-2', VAR_2='password'))\n"", ""VAR_6 = self.client.get('/api/apps')\n"", ""self.assertEqual(len(VAR_6.data['results']), 1)\n"", ""self.assertTrue(self.client.login(VAR_1='autotest-1', VAR_2='password'))\n"", ""VAR_6 = self.client.delete(VAR_5, content_type='application/json')\n"", ""self.assertEqual(VAR_6.status_code, 404)\n""]",1
"[""def FUNC_0(VAR_1, VAR_2, VAR_3='text', VAR_4=bconfig....\n"", ""\""\""\""docstring\""\""\""\n"", ""def FUNC_30():...\n"", ""if VAR_3 == 'text':\n"", ""print('Input file: %s' % VAR_75)\n"", ""VAR_52 = FUNC_2(VAR_15, VAR_2, VAR_3=output_mode, VAR_4=output_limit, VAR_5\n    =spires, VAR_6=match_mode, VAR_7=no_cache, VAR_8=with_author_keywords,\n    VAR_9=rebuild_cache, VAR_10=only_core_tags, VAR_11=extract_acronyms)\n"", ""if VAR_12:\n"", ""return VAR_52\n"", ""if isinstance(VAR_52, dict):\n"", ""for VAR_84 in VAR_52:\n"", ""for entry in VAR_1:\n"", ""print(VAR_52[VAR_84])\n"", ""VAR_0.info('Trying to read input file %s.' % entry)\n"", ""VAR_15 = None\n"", ""VAR_75 = ''\n"", ""if os.path.isdir(entry):\n"", ""for VAR_40 in os.listdir(entry):\n"", ""if os.path.isfile(entry):\n"", ""if VAR_40.startswith('.'):\n"", ""VAR_15 = extractor.text_lines_from_local_file(entry)\n"", ""VAR_15 = extractor.text_lines_from_url(entry, user_agent=\n    make_user_agent_string('BibClassify'))\n"", ""VAR_40 = os.path.join(entry, VAR_40)\n"", ""if VAR_15:\n"", ""if VAR_15:\n"", ""if os.path.isfile(VAR_40):\n"", ""VAR_75 = os.path.basename(entry)\n"", ""VAR_75 = entry.split('/')[-1]\n"", ""VAR_15 = extractor.text_lines_from_local_file(VAR_40)\n"", ""FUNC_30()\n"", ""FUNC_30()\n"", ""if VAR_15:\n"", ""VAR_75 = VAR_40\n"", ""FUNC_30()\n""]",1
"[""def __init__(self, VAR_20, *VAR_5, **VAR_6):...\n"", ""super().__init__(*VAR_5, **kwargs)\n"", ""self.key_name = VAR_20\n""]",0
"[""from odoo import models\n"", ""from odoo.addons.base_crapo_workflow.mixins import crapo_automata_mixins\n"", ""\""\""\""string\""\""\""\n"", ""VAR_0 = 'crapo.business.object'\n"", ""VAR_1 = ['mail.thread', 'mail.activity.mixin']\n"", ""VAR_2 = \""\""\""\n    An object on which to  in a workflow, specific to a given model\n    \""\""\""\n"", ""VAR_3 = ''\n""]",1
"[""def FUNC_6(VAR_2):...\n"", ""VAR_2.cursor.execute('string')\n"", ""VAR_22 = VAR_2.cursor.fetchall()\n"", ""return [VAR_0(*VAR_27) for VAR_27 in VAR_22]\n""]",0
"[""@patch('invenio.ext.session.interface.SessionInterface.save_session')...\n"", ""from invenio.modules.oauthclient.models import RemoteToken\n"", ""from invenio.modules.oauthclient.handlers import token_getter\n"", ""from invenio.modules.oauthclient.client import oauth\n"", ""VAR_9 = MagicMock()\n"", ""VAR_9.get_id = MagicMock(return_value=1)\n"", ""VAR_9.is_authenticated = MagicMock(return_value=True)\n"", ""VAR_10 = c.get(url_for('oauthclient.login', remote_app='full'))\n"", ""assert VAR_10.status_code == 302\n"", ""assert VAR_10.location.startswith(oauth.remote_apps['full'].authorize_url)\n"", ""self.mock_response(VAR_5='full')\n"", ""c.get(url_for('oauthclient.authorized', remote_app='full', code='test'))\n"", ""assert session['oauth_token_full'] == ('test_access_token', '')\n"", ""VAR_11 = RemoteToken.get(1, 'fullid')\n"", ""assert VAR_11.remote_account.client_id == 'fullid'\n"", ""assert VAR_11.access_token == 'test_access_token'\n"", ""assert RemoteToken.query.count() == 1\n"", ""self.mock_response(VAR_5='full', VAR_6={'access_token': 'new_access_token',\n    'scope': '', 'token_type': 'bearer'})\n"", ""c.get(url_for('oauthclient.authorized', remote_app='full', code='test'))\n"", ""VAR_11 = RemoteToken.get(1, 'fullid')\n"", ""assert VAR_11.access_token == 'new_access_token'\n"", ""assert RemoteToken.query.count() == 1\n"", ""VAR_12 = token_getter(oauth.remote_apps['full'])\n"", ""assert VAR_12 == ('new_access_token', '')\n"", ""VAR_10 = c.get(url_for('oauthclient.disconnect', remote_app='full'))\n"", ""assert VAR_10.status_code == 302\n"", ""assert VAR_10.location.endswith(url_for('oauthclient_settings.index'))\n"", ""VAR_11 = RemoteToken.get(1, 'fullid')\n"", ""assert VAR_11 is None\n""]",1
"[""def FUNC_3(VAR_2, VAR_3, VAR_4, VAR_5):...\n"", ""\""\""\""docstring\""\""\""\n"", ""VAR_9 = StringIO.StringIO()\n"", ""VAR_10 = hashlib.sha1()\n"", ""for name, content in FUNC_2(VAR_2, VAR_3, VAR_4, VAR_5):\n"", ""zip_file.writestr(name, content)\n"", ""VAR_11 = VAR_9.getvalue()\n"", ""VAR_10.update(str(len(name)))\n"", ""VAR_12 = VAR_10.hexdigest()\n"", ""VAR_10.update(name)\n"", ""logging.info('get_swarming_bot_zip(%s) is %d bytes; %s', VAR_5.keys(), len(\n    VAR_11), VAR_12)\n"", ""VAR_10.update(str(len(content)))\n"", ""return VAR_11, VAR_12\n"", ""VAR_10.update(content)\n""]",0
"[""def FUNC_25(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.set('modified', now())\n"", ""VAR_54.db.set_value(self.doctype, self.name, 'modified', self.modified,\n    update_modified=False)\n""]",0
"[""def FUNC_2():...\n"", ""super(CLASS_5, self).__init__(slideParser.parse(VAR_10, slideLexer), self.\n    begin % (VAR_41, VAR_36), self.end % VAR_41)\n""]",1
"[""def __init__(self, VAR_0='cache', VAR_1=timedelta(days=30), VAR_2=True):...\n"", ""\""\""\""docstring\""\""\""\n"", ""self.cache_dir = VAR_0\n"", ""self.expires = VAR_1\n"", ""self.compress = VAR_2\n""]",0
"[""def FUNC_1(self, VAR_1):...\n"", ""if VAR_1.settings().get('traverse') == 'true':\n"", ""VAR_5 = VAR_1\n"", ""VAR_6 = VAR_1.window()\n"", ""VAR_7 = VAR_1.substr(VAR_1.line(VAR_1.sel()[0]))\n"", ""VAR_8 = re.findall('->\\\\s+([^\\\\|]+)', VAR_7)\n"", ""if len(VAR_8) > 0:\n"", ""VAR_9 = Urtext.get_path(VAR_1.window())\n"", ""VAR_6.focus_group(1)\n"", ""VAR_10 = VAR_6.open_file(os.path.join(VAR_9, VAR_8[0].strip()), sublime.\n    TRANSIENT)\n"", ""print('unable to open ' + VAR_8[0])\n"", ""self.return_to_left(VAR_10, VAR_5)\n"", ""VAR_10.set_scratch(True)\n""]",1
"[""def FUNC_2(self):...\n"", ""\""\""\""docstring\""\""\""\n"", ""while True:\n"", ""time.sleep(1)\n"", ""self.flush_profile_data()\n""]",1
"[""def FUNC_2(self, VAR_1):...\n"", ""VAR_2 = self.connect()\n"", ""VAR_3 = \""INSERT INTO crimes(description) VALUES ('{}');\"".format(VAR_1)\n"", ""VAR_2.close()\n"", ""cursor.execute(VAR_3)\n"", ""VAR_2.commit()\n""]",1
"[""import MELEE_SINGLES_BRACKETS\n"", ""import WIIU_BRACKETS\n"", ""import SMASH_5_BRACKETS\n"", ""VAR_0 = 'ec2-18-218-117-97.us-east-2.compute.amazonaws.com'\n"", ""VAR_1 = [['christmasmike', 'thanksgiving mike', 'christmas mike',\n    'christmas mike xmas', 'christmas mike late', 'halloween mike', 'im 12',\n    'im12'], ['circuits', 'circuits', 'jkelle', 'circuits xmas'], [\n    'gamepad', 'sms gamepad'], ['remo', 'su remo'], ['kuro', 'ss kuro'], [\n    'pixlsugr', 'pixlsug', 'pixlsugar'], ['b00', 'boo'], ['hnic',\n    'hnic xmas'], ['1111', '11 11', 'vuibol'], ['qmantra', 'qmantra xmas'],\n    ['megafox', 'su | megafox'], ['hakii', 'su l hakii', 'su | hakii',\n    'su redriot i hakii', 'hih | hakii', 'su | sleepyhakii', 'su|hakii',\n    'su | hakii $', 'su  redriot i hakii', 'hoh | hakii', 'su| hakii'], [\n    'lucy', 'ttn | lucy'], ['moist', 'f9moist', 'kuyamoist'], ['sassy',\n    'atx | sassy', 'f9sassy'], ['crump', 'donald crump', 'captain crump',\n    'abc | crump'], ['dragonite', 'datuglynigwhofkurmomin2ndgrade',\n    'tmg dragonite', 'su dragonite', 'su | dragonite', 'tpwn | dragonite',\n    'tpwn | dragonite_pr', 'tpwn| dragonite (gnw)', 'atx hoh | dragonite',\n    'dragonite_pr', 'hoh | dragonite', 'mega dragonite', 'tpwn|dragonite',\n    'armada | dragonite', 'aes | dragonite'], ['gallium', 's.e.s punk',\n    'ses punk'], ['mt', 'mt_'], ['wolf', ' wolf'], ['fx | albert', 'albert'\n    ], ['ul | jf', 'jf', 'ul| jf', 'ul i jf'], ['take a seat', 'take a \\\\_',\n    'take a \\\\_', 'takeaseat', 'take a seat xmas'], ['bobby big ballz',\n    'bobby big balls'], ['prof. cube', 'type r professor cube', 'prof cube',\n    'professor cube', 'profesor cube', 'cube', 'processorcube',\n    'prof cube $'], ['cashoo', 'hoh | cashoo', 'hoh l cashoo', 'cash00'], [\n    'ul | chandy', 'ul| chandy', 'cnb | chandy', 'chandy'], ['spankey',\n    'spanky'], ['jack the reaper', 'jackthereaper'], ['xlll', 'xiii'], [\n    'cheesedud6', '←/cheesedud6'], ['kj', 'go! kj', 'go kj'], ['jtag',\n    'tgl | jtag', 'sms | jtag', 'sms jtag', 'jtg', 'j tag'], ['jka',\n    'tgl | jka'], ['fcar', 'tgl | fcar'], ['resident', 'tgl | resident'], [\n    'minty!', 'tgl | minty!', 'tgl | minty', 'minty'], ['willow',\n    'willowette'], ['messiah', 'maple'], ['tenni', 'go! tenni'], ['cruzin',\n    'sa  cruzin'], ['christmasmitch', 'mitchell', 'mitchell slan'], ['jibs',\n    'sfu jibs'], ['trane', 'irn trane'], ['ninjafish', 'sa  ninjafish'], [\n    'mufin', 'sfu mufin'], ['jowii', 'jo wii'], ['gudlucifer',\n    'good lucifer', 'goodlucifer', 'gudlucifer wolf'], ['ehmon',\n    'tgl ehmon', 'tgl  ehmon', 'ah ehmon', 'sms ehmon', 'sms | ehmon',\n    'tgl | ehmon', 'ehhhmon'], ['pollo loco', 'pollo'], ['doombase',\n    'retiredbase'], ['majinmike', 'majin mike'], ['karonite', 'red velvet',\n    'aos redvelvet', 'redvelvet']]\n"", ""VAR_2 = 'austin', {'enumerated': ['http://challonge.com/heatwave###',\n    'https://challonge.com/NP9ATX###', 'http://challonge.com/hw###',\n    'https://challonge.com/alibaba###'], 'users': [\n    'https://challonge.com/users/kuya_mark96',\n    'https://austinsmash4.challonge.com']}\n"", ""VAR_3 = 'smashbrews', {'enumerated': ['https://challonge.com/Smashbrews###',\n    'https://challonge.com/smashbrewsS3W###',\n    'https://challonge.com/smashbrewsS4W###',\n    'https://challonge.com/smashbrewsS5W###']}\n"", ""VAR_4 = 'colorado', {'enumerated': [\n    'http://smashco.challonge.com/CSUWW###WUS',\n    'http://smascho.challonge.com/FCWUA###',\n    'http://smascho.challonge.com/FCWUIB###']}\n"", ""VAR_5 = 'colorado_doubles', {'enumerated': [\n    'http://smashco.challonge.com/CSUWW###WUD',\n    'http://smashco.challonge.com/FCWUDC###']}\n"", ""VAR_6 = 'colorado_both', {'enumerated': VAR_4 + VAR_5}\n"", ""VAR_7 = 'sms', {'enumerated': ['http://challonge.com/RAA_###',\n    'http://challonge.com/SMSH_###'], 'users': [\n    'https://challonge.com/users/yellocake']}\n"", ""VAR_8 = {'heatwave': 'Heatwave', 'NP9ATX': 'NP9', 'challonge.com/hw':\n    'Heatwave', 'challonge.com/atx': 'Smashpack', 'alibaba': 'Alibaba',\n    'Mothership': 'Mothership', 'atxfiles': 'ATX Files', 'ARFI': 'ARFI',\n    'arcadian': 'Arcadian', 'ooples': 'Ooples', 'challonge.com/mbh':\n    'Michaels Big House', 'challonge.com/sth': 'Smash The Halls',\n    'smashbrewsS3': 'Smashbrews S3', 'smashbrewsS4': 'Smashbrews S4',\n    'smashbrewsS5': 'Smashbrews S5', 'Smashbrews': 'Smashbrews', 'smashco':\n    'CSU', 'smascho': 'CSU', 'RAA': 'Reading At Alkek'}\n"", ""VAR_9 = MELEE_SINGLES_BRACKETS.MELEE_SINGLES\n"", ""VAR_10 = WIIU_BRACKETS.WII_U_BRACKETS\n"", ""VAR_11 = SMASH_5_BRACKETS.SMASH_5_BRACKETS\n"", ""VAR_12 = 10 * 60 * 6\n"", ""VAR_13 = 20\n"", ""VAR_14 = [('test1', ['https://challonge.com/smash_web_test_###']), ('test2',\n    ['https://challonge.com/smash_web_scene_two_###'])]\n"", ""\""\""\""string\""\""\""\n""]",1
"[""def FUNC_6(self, VAR_45):...\n"", """"]",0
"[""def FUNC_3():...\n"", ""populate_test_database()\n"", ""FUNC_1('first playlist')\n"", ""FUNC_1('second playlist')\n"", ""VAR_11 = VAR_3.get('/playlists')\n"", ""assert VAR_11.json['status'] == 'OK'\n"", ""assert VAR_11.json['data'] == [dict(id=1, VAR_8='first playlist'), dict(id=\n    2, VAR_8='second playlist')]\n""]",0
"[""def FUNC_3(VAR_3, VAR_4, VAR_0, VAR_1):...\n"", ""VAR_9 = []\n"", ""for table in VAR_4:\n"", ""VAR_2 = 'SELECT * FROM {} WHERE 1=0'.format(table)\n"", ""return VAR_9\n"", ""VAR_5 = FUNC_2(VAR_0, VAR_1, VAR_2)[0]\n"", ""VAR_15 = []\n"", ""for col in VAR_5:\n"", ""VAR_15.append(\""{} LIKE '%{}%'\"".format(col, VAR_3))\n"", ""VAR_15 = ' OR '.join(VAR_15)\n"", ""VAR_2 = 'SELECT * FROM {} WHERE {}'.format(table, VAR_15)\n"", ""VAR_16, VAR_17 = FUNC_2(VAR_0, VAR_1, VAR_2)\n"", ""VAR_9.append((table, VAR_16, VAR_17))\n""]",1
